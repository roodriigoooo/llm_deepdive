{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Introduction To NLP @ Esade BAIB\n",
    "\n",
    "# NGram Language Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:13.231943Z",
     "start_time": "2025-04-16T12:40:12.462400Z"
    }
   },
   "source": [
    "# pandas dataframes and utils for counting\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import logging"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:16.628973Z",
     "start_time": "2025-04-16T12:40:16.565943Z"
    }
   },
   "source": [
    "movie_reviews_df = pd.read_csv('../data/movie_reviews_text.csv')\n",
    "movie_reviews_df.sample(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                    text\n",
       "9911   cruel and inhuman cinematic punishment . . . s...\n",
       "9757   the pretensions -- and disposable story -- sin...\n",
       "10208  it has the right approach and the right openin...\n",
       "4071   \" brown sugar \" admirably aspires to be more t...\n",
       "6781   the adventure doesn't contain half the excitem...\n",
       "3791   a burst of color , music , and dance that only...\n",
       "2398   the ring is worth a look , if you don't demand...\n",
       "10483  is it really an advantage to invest such subtl...\n",
       "5173         smarter than its commercials make it seem .\n",
       "2435   with one exception , every blighter in this pa..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>cruel and inhuman cinematic punishment . . . s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>the pretensions -- and disposable story -- sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208</th>\n",
       "      <td>it has the right approach and the right openin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>\" brown sugar \" admirably aspires to be more t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>the adventure doesn't contain half the excitem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>a burst of color , music , and dance that only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>the ring is worth a look , if you don't demand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10483</th>\n",
       "      <td>is it really an advantage to invest such subtl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>smarter than its commercials make it seem .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>with one exception , every blighter in this pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Counting ngrams"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:21.253403Z",
     "start_time": "2025-04-16T12:40:20.641407Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt_tab')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\rsast\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:24.263975Z",
     "start_time": "2025-04-16T12:40:24.251980Z"
    }
   },
   "source": [
    "from typing import List, Dict \n",
    "start_symbol = \"_START_\"\n",
    "stop_symbol = \"_STOP_\"\n",
    "\n",
    "def count_ngrams_up_to(n_max: int, texts: List[str], tokenizer=nltk.word_tokenize) -> Dict[tuple, Counter]:\n",
    "    counts = {} # dict from context to a counter of next symbol\n",
    "    for text in texts:\n",
    "        tokens = tokenizer(text) + [stop_symbol]\n",
    "        for n in range(n_max):\n",
    "            starts = [start_symbol] * n\n",
    "            for ngram in ngrams(starts + tokens, n+1):\n",
    "                context = ngram[:-1]\n",
    "                end_symbol = ngram[-1]\n",
    "                counts.setdefault(context, Counter()).update([end_symbol])\n",
    "    return counts"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:32.137583Z",
     "start_time": "2025-04-16T12:40:29.141384Z"
    }
   },
   "source": [
    "mr_ngram_counts = count_ngrams_up_to(3, movie_reviews_df.text)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:33.287549Z",
     "start_time": "2025-04-16T12:40:33.264552Z"
    }
   },
   "source": [
    "print(\"Number of ngram contexts: \", len(mr_ngram_counts))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ngram contexts:  133415\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:35.258987Z",
     "start_time": "2025-04-16T12:40:35.233793Z"
    }
   },
   "source": [
    "# check most common words for \"empty\" context\n",
    "mr_ngram_counts[()].most_common(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 14010),\n",
       " ('_STOP_', 10662),\n",
       " ('the', 10113),\n",
       " (',', 10037),\n",
       " ('a', 7314),\n",
       " ('and', 6201),\n",
       " ('of', 6062),\n",
       " ('to', 4234),\n",
       " ('is', 3559),\n",
       " (\"'s\", 3537)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:36.843747Z",
     "start_time": "2025-04-16T12:40:36.831746Z"
    }
   },
   "source": [
    "# check most common words following \"steven\"\n",
    "mr_ngram_counts[('steven', )].most_common(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spielberg', 9),\n",
       " ('soderbergh', 8),\n",
       " ('seagal', 4),\n",
       " ('shainberg', 2),\n",
       " ('segal', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:38.036603Z",
     "start_time": "2025-04-16T12:40:38.024605Z"
    }
   },
   "source": [
    "mr_ngram_counts[('movie', )].most_common(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 164),\n",
       " ('is', 152),\n",
       " ('that', 133),\n",
       " (',', 127),\n",
       " (\"'s\", 64),\n",
       " ('with', 34),\n",
       " ('about', 27),\n",
       " ('in', 26),\n",
       " ('has', 25),\n",
       " ('of', 19)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGram Language Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:40.068735Z",
     "start_time": "2025-04-16T12:40:40.049736Z"
    }
   },
   "source": [
    "from typing import Dict, Set\n",
    "from collections import Counter \n",
    "from random import choices\n",
    "\n",
    "class NGramLanguageModel:\n",
    "    \"\"\" \n",
    "    An NGram Language model with Katz back-off discount. \n",
    "\n",
    "    n is the order of the ngram model, i.e n=3 for a trigram model\n",
    "\n",
    "    ngram_counts is a dictionary of word counts for each ngram context. \n",
    "\n",
    "    back_off_discount is the discount value for Katz back-off. A None value \n",
    "       indicates no-back off, the counts are used without any smoothing,. \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int, ngram_counts: Dict[tuple, Counter], back_off_discount: float):\n",
    "        self.n = n \n",
    "        self.back_off_discount = back_off_discount\n",
    "        self.ngram_counts = ngram_counts\n",
    "        self.vocab = set(self.ngram_counts.get((), {}).keys())\n",
    "    \n",
    "    def p_next_word(self, tokens: tuple, top: int = None, n=None, _vocab: Set[str] = None) -> dict[str, float]:\n",
    "        \"\"\"Returns the probability distribution over the next word given the tokens. \"\"\"\n",
    "        logger = logging.getLogger('p_next_word')\n",
    "        if n is None:\n",
    "            n = self.n \n",
    "        elif n == 0:\n",
    "            return {}\n",
    "        ctx_len = n-1   # len of context is the order of the ngram model minus one \n",
    "        if ctx_len == 0: \n",
    "            ctx = ()  # take empty context\n",
    "            ctx_counts = self.ngram_counts.get(ctx)   \n",
    "        else:\n",
    "            if len(tokens) < ctx_len:\n",
    "                starts = [start_symbol] * (ctx_len - len(tokens))\n",
    "                tokens = starts + list(tokens)            \n",
    "            ctx = tuple(tokens[-ctx_len:])\n",
    "            assert(len(ctx)==ctx_len)\n",
    "            ctx_counts = self.ngram_counts.get(ctx, Counter()) # take counts of context, or an empty Counter if context does not exist\n",
    "        total_count = sum(ctx_counts.values())\n",
    "        logger.debug(f\"context_length={ctx_len} context={ctx} total_count={total_count} observed_words={len(ctx_counts)}\")\n",
    "\n",
    "        if _vocab is None: \n",
    "            _vocab = self.vocab\n",
    "        if self.back_off_discount:\n",
    "            _vocab_observed = set(_vocab).intersection(set(ctx_counts.keys()))\n",
    "            _vocab_unobserved = set(_vocab).difference(_vocab_observed)\n",
    "            word_prob_observed = [(word, (ctx_counts.get(word, 0) - self.back_off_discount) / total_count) for word in _vocab_observed]\n",
    "            total_discount = self.back_off_discount*len(_vocab_observed)\n",
    "            if total_count == 0:\n",
    "                mass_discount = 1\n",
    "            else: \n",
    "                mass_discount = total_discount / total_count\n",
    "            logger.debug(f\"backing-off to context len {n-1} for {len(_vocab_unobserved)} unobserved words\")\n",
    "            word_prob_unobserved = [(w, p*mass_discount) for w, p in self.p_next_word(tokens, n=n-1, _vocab=_vocab_unobserved).items()]\n",
    "            word_prob = word_prob_observed + word_prob_unobserved\n",
    "        elif total_count == 0:\n",
    "            word_prob = [(word, 0) for word in _vocab]\n",
    "        else:\n",
    "            word_prob = [(word, ctx_counts.get(word, 0) / total_count) for word in _vocab]\n",
    "        word_prob = sorted(word_prob, key=lambda wp: wp[1], reverse=True)\n",
    "        if top is not None:\n",
    "            word_prob = word_prob[:top]\n",
    "        return {w: p for w, p in word_prob}\n",
    "\n",
    "def prob_text(ngram_model: NGramLanguageModel, text: str, tokenizer=nltk.word_tokenize) -> float:\n",
    "    logger = logging.getLogger('prob_text')\n",
    "    tokens = tokenizer(text) + [stop_symbol]\n",
    "    logger.debug(f\"Text tokens: {tokens}\")\n",
    "    p = 1\n",
    "    for i in range(len(tokens)):\n",
    "        p_next = ngram_model.p_next_word(tokens=tuple(tokens[:i]))\n",
    "        p_token = p_next.get(tokens[i], 0)\n",
    "        logger.debug(f\"p({tokens[i]} | {tokens[:i]}) = {p_token} \")\n",
    "        p = p*p_token\n",
    "    return p\n",
    "\n",
    "\n",
    "def text_generator(ngram_model: NGramLanguageModel, tokens: List[str] = None, randomize: bool = False, limit=1000):\n",
    "    logger = logging.getLogger('text_generator')\n",
    "    if tokens is None:\n",
    "        tokens = []\n",
    "    next = None\n",
    "    while (next != stop_symbol):\n",
    "        probs = ngram_model.p_next_word(tokens)\n",
    "        if randomize:\n",
    "            next = choices(list(probs.keys()), list(probs.values()), k=1)[0]\n",
    "        else:\n",
    "            next = list(probs.items())[0][0]  # take first item (most likely one), and take its first element (the word)\n",
    "        tokens.append(next)\n",
    "        if len(tokens) == limit:\n",
    "            logger.info(f\"Reached limit of {limit} tokens!\")\n",
    "            break\n",
    "    return tokens\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a few models with the ngram counts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:46.348844Z",
     "start_time": "2025-04-16T12:40:46.330802Z"
    }
   },
   "source": [
    "lm_bigram_smoothed = NGramLanguageModel(2, mr_ngram_counts, back_off_discount=0.1)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:47.170831Z",
     "start_time": "2025-04-16T12:40:47.152803Z"
    }
   },
   "source": [
    "lm_bigram_rough = NGramLanguageModel(2, mr_ngram_counts, back_off_discount=0)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:47.917805Z",
     "start_time": "2025-04-16T12:40:47.904805Z"
    }
   },
   "source": [
    "lm_trigram = NGramLanguageModel(3, mr_ngram_counts, back_off_discount=0.1)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:48.789049Z",
     "start_time": "2025-04-16T12:40:48.769057Z"
    }
   },
   "source": [
    "logging.getLogger(\"p_next_word\").setLevel(logging.DEBUG)\n",
    "lm_bigram_rough.p_next_word(('this',), top=10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 0.17117117117117117,\n",
       " 'movie': 0.08731808731808732,\n",
       " 'film': 0.07207207207207207,\n",
       " 'one': 0.03395703395703396,\n",
       " 'time': 0.013167013167013167,\n",
       " 'year': 0.012474012474012475,\n",
       " '.': 0.011088011088011088,\n",
       " 'story': 0.009009009009009009,\n",
       " ',': 0.009009009009009009,\n",
       " 'picture': 0.007623007623007623}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:50.336715Z",
     "start_time": "2025-04-16T12:40:50.261721Z"
    }
   },
   "source": [
    "lm_bigram_smoothed.p_next_word(('steven',), top=10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.37083333333333335,\n",
       " 'soderbergh': 0.32916666666666666,\n",
       " 'seagal': 0.1625,\n",
       " 'shainberg': 0.07916666666666666,\n",
       " 'segal': 0.0375,\n",
       " '.': 0.0012120766958466913,\n",
       " '_STOP_': 0.0009224220389473043,\n",
       " 'the': 0.0008749249043482111,\n",
       " ',': 0.0008683497090303039,\n",
       " 'a': 0.0006327673820479172}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:51.933825Z",
     "start_time": "2025-04-16T12:40:51.841829Z"
    }
   },
   "source": [
    "lm_trigram.p_next_word(('a', 'movie', 'of', 'steven',), top=10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'soderbergh': 0.475,\n",
       " 'spielberg': 0.475,\n",
       " 'seagal': 0.008125,\n",
       " 'shainberg': 0.003958333333333334,\n",
       " 'segal': 0.001875,\n",
       " '.': 3.636230087540075e-05,\n",
       " '_STOP_': 2.7672661168419136e-05,\n",
       " 'the': 2.624774713044634e-05,\n",
       " ',': 2.6050491270909125e-05,\n",
       " 'a': 1.8983021461437524e-05}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hack: reverse the language! "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:58.120199Z",
     "start_time": "2025-04-16T12:40:53.290013Z"
    }
   },
   "source": [
    "reversed_ngram_counts = count_ngrams_up_to(3, [' '.join(reversed(nltk.word_tokenize(t))) for t in movie_reviews_df.text])"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:58.151001Z",
     "start_time": "2025-04-16T12:40:58.131004Z"
    }
   },
   "source": [
    "reversed_ngram_counts[('spielberg', 'steven')]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'of': 2,\n",
       "         'even': 2,\n",
       "         'like': 1,\n",
       "         ',': 1,\n",
       "         '_STOP_': 1,\n",
       "         'movie': 1,\n",
       "         'realizing': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:58.571005Z",
     "start_time": "2025-04-16T12:40:58.559005Z"
    }
   },
   "source": [
    "reversed_lm = NGramLanguageModel(n=3, ngram_counts=reversed_ngram_counts, back_off_discount=0)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:58.991008Z",
     "start_time": "2025-04-16T12:40:58.963001Z"
    }
   },
   "source": [
    "reversed_lm.p_next_word(('soderbergh', 'steven'), top=10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': 0.25,\n",
       " '_STOP_': 0.25,\n",
       " 'if': 0.125,\n",
       " 'and': 0.125,\n",
       " 'in': 0.125,\n",
       " ',': 0.125,\n",
       " 'fruit': 0.0,\n",
       " 'carlin': 0.0,\n",
       " 'sharply': 0.0,\n",
       " 'cheeky': 0.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:40:59.442004Z",
     "start_time": "2025-04-16T12:40:59.417008Z"
    }
   },
   "source": [
    "reversed_lm.p_next_word(('spielberg', 'steven'), top=10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': 0.2222222222222222,\n",
       " 'even': 0.2222222222222222,\n",
       " 'like': 0.1111111111111111,\n",
       " 'movie': 0.1111111111111111,\n",
       " '_STOP_': 0.1111111111111111,\n",
       " ',': 0.1111111111111111,\n",
       " 'realizing': 0.1111111111111111,\n",
       " 'fruit': 0.0,\n",
       " 'carlin': 0.0,\n",
       " 'sharply': 0.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:41:01.103340Z",
     "start_time": "2025-04-16T12:41:01.028157Z"
    }
   },
   "source": [
    "lm_trigram.p_next_word(('and', 'steven'), top=10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'soderbergh': 0.9,\n",
       " 'spielberg': 0.037083333333333336,\n",
       " 'seagal': 0.01625,\n",
       " 'shainberg': 0.007916666666666667,\n",
       " 'segal': 0.00375,\n",
       " '.': 9.696613566773531e-05,\n",
       " '_STOP_': 7.379376311578435e-05,\n",
       " 'the': 6.999399234785689e-05,\n",
       " ',': 6.946797672242431e-05,\n",
       " 'a': 5.062139056383338e-05}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:41:02.918570Z",
     "start_time": "2025-04-16T12:41:02.845567Z"
    }
   },
   "source": [
    "lm_trigram.p_next_word(('even', 'steven'), top=10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.95,\n",
       " 'soderbergh': 0.016458333333333335,\n",
       " 'seagal': 0.008125,\n",
       " 'shainberg': 0.003958333333333334,\n",
       " 'segal': 0.001875,\n",
       " '.': 4.8483067833867656e-05,\n",
       " '_STOP_': 3.6896881557892176e-05,\n",
       " 'the': 3.4996996173928444e-05,\n",
       " ',': 3.4733988361212156e-05,\n",
       " 'a': 2.531069528191669e-05}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computations with LMs\n",
    "\n",
    "### Compute p(x)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:41:06.784102Z",
     "start_time": "2025-04-16T12:41:06.616105Z"
    }
   },
   "source": [
    "logging.getLogger(\"p_next_word\").setLevel(logging.INFO)\n",
    "logging.getLogger(\"prob_text\").setLevel(logging.DEBUG)\n",
    "\n",
    "prob_text(ngram_model=lm_bigram_rough, text=\"i like this movie, woody\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:41:07.745082Z",
     "start_time": "2025-04-16T12:41:07.389082Z"
    }
   },
   "source": [
    "prob_text(ngram_model=lm_bigram_smoothed, text=\"i like this movie, woody\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.030024504174122e-16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completing a text"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:41:09.145442Z",
     "start_time": "2025-04-16T12:41:08.987445Z"
    }
   },
   "source": [
    "text_generator(ngram_model=lm_bigram_rough)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'film', 'is', 'a', 'movie', '.', '_STOP_']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:41:10.217427Z",
     "start_time": "2025-04-16T12:41:09.816429Z"
    }
   },
   "source": [
    "text_generator(ngram_model=lm_bigram_smoothed)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'film', 'is', 'a', 'movie', '.', '_STOP_']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:03.769939Z",
     "start_time": "2025-04-16T12:41:11.338946Z"
    }
   },
   "source": [
    "text_generator(ngram_model=lm_trigram)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'film',\n",
       " 'is',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'not',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'sign',\n",
       " 'when',\n",
       " 'you']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:04.019943Z",
     "start_time": "2025-04-16T12:42:03.819123Z"
    }
   },
   "source": [
    "text_generator(ngram_model=lm_bigram_rough, tokens=['the', 'movie', 'by', 'steven'], randomize=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'movie',\n",
       " 'by',\n",
       " 'steven',\n",
       " 'seagal',\n",
       " 'pessimists',\n",
       " ':',\n",
       " 'two',\n",
       " 'hours',\n",
       " 'represents',\n",
       " 'two',\n",
       " 'literary',\n",
       " 'purists',\n",
       " 'might',\n",
       " 'otherwise',\n",
       " 'calculated',\n",
       " '.',\n",
       " '_STOP_']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:26.886941Z",
     "start_time": "2025-04-16T12:42:04.381942Z"
    }
   },
   "source": [
    "logging.getLogger(\"prob_text\").setLevel(logging.INFO)\n",
    "for i in range(10):\n",
    "    text = text_generator(lm_trigram, tokens=['i', 'like', 'movies', 'by', 'steven'], randomize=True)\n",
    "    prob = prob_text(lm_trigram, ' '.join(text))\n",
    "    print(prob, text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.882028267321108e-34 ['i', 'like', 'movies', 'by', 'steven', 'spielberg', 'brings', 'us', 'right', 'into', 'ideas', 'and', 'fanciful', 'sexist', 'or', 'mean-spirited', '.', '_STOP_']\n",
      "2.02277078940983e-21 ['i', 'like', 'movies', 'by', 'steven', 'spielberg', \"'s\", '1993', 'classic', '.', '_STOP_']\n",
      "1.2303750683239652e-20 ['i', 'like', 'movies', 'by', 'steven', 'segal', '.', '_STOP_']\n",
      "1.7095953781368685e-42 ['i', 'like', 'movies', 'by', 'steven', 'soderbergh', \"'s\", 'solaris', 'so', 'much', 'that', 'is', 'life', 'affirming', 'and', 'heartbreaking', 'to', 'witness', 'the', 'conflict', 'from', 'the', 'french', 'revolution', 'from', 'stark', 'desert', 'to', 'gorgeous', 'beaches', '.', 'the', 'interviews', 'that', 'follow', ',', 'iwai', \"'s\", 'vaunted', 'empathy', '.', '_STOP_']\n",
      "1.2303750683239652e-20 ['i', 'like', 'movies', 'by', 'steven', 'segal', '.', '_STOP_']\n",
      "5.8471700181716176e-62 ['i', 'like', 'movies', 'by', 'steven', 'spielberg', 'has', 'dreamed', 'up', 'such', 'blatant', 'and', 'sickening', 'product', 'placement', ',', 'some', 'of', 'the', 'most', 'heinous', 'man', 'who', 'wrote', 'rocky', 'does', 'not', 'want', 'to', 'be', 'a', 'comedy', ',', 'scotland', ',', 'puts', 'a', 'small', 'screen', '.', '.', '.', 'brings', 'an', 'irresistible', 'blend', 'of', 'a', 'young', 'woman', \"'s\", 'broken', 'heart', 'outweighs', 'all', 'the', 'way', 'on', 'hedonistic', 'gusto', '.', '_STOP_']\n",
      "5.803959139438146e-26 ['i', 'like', 'movies', 'by', 'steven', 'seagal', ',', 'but', 'it', 'has', 'been', 'properly', 'digested', '.', '_STOP_']\n",
      "8.900117179733562e-40 ['i', 'like', 'movies', 'by', 'steven', 'shainberg', ',', 'the', 'screenplay', 'is', ',', 'aptly', 'enough', ',', 'but', 'it', \"'s\", 'a', 'much', 'needed', 'kick', ',', 'and', 'the', 'human', 'condition', '_STOP_']\n",
      "4.033746996957213e-23 ['i', 'like', 'movies', 'by', 'steven', 'spielberg', \"'s\", 'work', 'and', 'food', '.', '_STOP_']\n",
      "3.5523721327608126e-27 ['i', 'like', 'movies', 'by', 'steven', 'spielberg', \"'s\", 'achievement', 'extends', 'to', 'his', 'people', 'are', 'readily', 'apparent', '.', '_STOP_']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fill in the gap\n",
    "\n",
    "We now implement a prediction method to fill in the gap: the input is a sentence with a gap to be filled with a word. We represent it by a prefix, a suffix, and a list of words to choose from. The method will return a distribution over the words of choice. \n",
    "\n",
    "This implementation is very slow whenever the number of choices is very large. More efficient implementations are possible, but are significantly more involved to code. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:27.290938Z",
     "start_time": "2025-04-16T12:42:27.261936Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "def fill_in_the_gap(ngram_model: NGramLanguageModel, prefix: str, suffix: str, choices: List[str] = None, top=None):\n",
    "    if choices is None: \n",
    "        choices = ngram_model.vocab\n",
    "    word_prob = []\n",
    "    for word in tqdm(choices):\n",
    "        p_text = prob_text(ngram_model=ngram_model, text = prefix + \" \" + word + \" \" + suffix)\n",
    "        word_prob.append((word, p_text))\n",
    "    sum_probs = sum([wp[1] for wp in word_prob])\n",
    "    word_prob = sorted(word_prob, key=lambda wp: wp[1], reverse=True)\n",
    "    if top:\n",
    "        word_prob = word_prob[:10]\n",
    "    return {w: p/sum_probs for w, p in word_prob}\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:29.576938Z",
     "start_time": "2025-04-16T12:42:27.698941Z"
    }
   },
   "source": [
    "fill_in_the_gap(lm_bigram_smoothed, prefix='steven', suffix='was director of the movie.', choices=['spielberg', 'allen', 'segal', 'soderbergh'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.48654978137336197,\n",
       " 'soderbergh': 0.4201293954119751,\n",
       " 'segal': 0.09137451752918674,\n",
       " 'allen': 0.0019463056854763252}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:30.105934Z",
     "start_time": "2025-04-16T12:42:30.029937Z"
    }
   },
   "source": [
    "p_next_steven = lm_trigram.p_next_word(tokens=['steven'], top=10)\n",
    "p_next_steven"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'soderbergh': 0.6333333333333333,\n",
       " 'spielberg': 0.3,\n",
       " 'seagal': 0.010833333333333334,\n",
       " 'shainberg': 0.005277777777777777,\n",
       " 'segal': 0.0025,\n",
       " '.': 4.848306783386766e-05,\n",
       " '_STOP_': 3.6896881557892176e-05,\n",
       " 'the': 3.499699617392845e-05,\n",
       " ',': 3.473398836121216e-05,\n",
       " 'a': 2.5310695281916696e-05}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:34.303592Z",
     "start_time": "2025-04-16T12:42:30.530938Z"
    }
   },
   "source": [
    "fill_in_the_gap(lm_bigram_smoothed, prefix='steven', suffix='was director of the movie.', choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.33773583108484606,\n",
       " 'soderbergh': 0.2916304887079038,\n",
       " 'seagal': 0.17784465394770904,\n",
       " 'shainberg': 0.1071213486715338,\n",
       " 'segal': 0.06342711434498713,\n",
       " '_STOP_': 0.015601751503639159,\n",
       " ',': 0.004368837561037187,\n",
       " '.': 0.0013558499704477795,\n",
       " 'the': 0.0004953282869056742,\n",
       " 'a': 0.00041879592099058855}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more data \n",
    "\n",
    "In this section we add additional texts and recompute the counts and recreate the language models. \n",
    "\n",
    "We want to show that ngram language models can remember textual patterns as long as these are within the window of \"n\" words of the ngram model. \n",
    "\n",
    "We will show that simple LMs are able to remember which movie director directed what movie, by first adding this data to the text collection, then pose questions in the form of fill-in-the-gap. \n",
    "\n",
    "We will see that bigram, trigram, or even six-gram models can remember or not the textual patterns."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:34.722562Z",
     "start_time": "2025-04-16T12:42:34.709394Z"
    }
   },
   "source": [
    "# here the \"knowledge\" between the last name of director and movie title is within 3 words\n",
    "more_texts = [\n",
    "    'steven spielberg directed jaws',\n",
    "    'steven spielberg directed et',\n",
    "    'steven spielberg directed ai',\n",
    "    'steven soderbergh directed traffic'\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:41.671390Z",
     "start_time": "2025-04-16T12:42:38.687395Z"
    }
   },
   "source": [
    "new_ngram_counts = count_ngrams_up_to(3, more_texts + list(movie_reviews_df.text))\n",
    "new_trigram_model = NGramLanguageModel(n=3, ngram_counts=new_ngram_counts, back_off_discount=0.5)\n",
    "new_bigram_model = NGramLanguageModel(n=2, ngram_counts=new_ngram_counts, back_off_discount=0.5)"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:45.387803Z",
     "start_time": "2025-04-16T12:42:42.328394Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=new_trigram_model, prefix=\"steven\", suffix=\"directed ai\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.994923484739286,\n",
       " 'soderbergh': 0.005076140228261662,\n",
       " 'seagal': 2.16764651023116e-07,\n",
       " 'shainberg': 9.024487511982789e-08,\n",
       " '_STOP_': 3.996722567478841e-08,\n",
       " ',': 1.5098132993922466e-08,\n",
       " 'the': 6.342054757884297e-09,\n",
       " 'a': 5.362073048926721e-09,\n",
       " '.': 1.2534395821493066e-09,\n",
       " 'segal': 0.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:49.008803Z",
     "start_time": "2025-04-16T12:42:46.027805Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=new_trigram_model, prefix=\"steven\", suffix=\"directed traffic\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'soderbergh': 0.9552232786929382,\n",
       " 'spielberg': 0.04477609118873148,\n",
       " 'seagal': 3.6420149559667644e-07,\n",
       " 'shainberg': 1.5162674510555511e-07,\n",
       " '_STOP_': 6.715173944138865e-08,\n",
       " ',': 2.5367432333409817e-08,\n",
       " 'the': 1.065573107550253e-08,\n",
       " 'a': 9.009195063403056e-09,\n",
       " '.': 2.105991767127051e-09,\n",
       " 'segal': 0.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:51.683800Z",
     "start_time": "2025-04-16T12:42:49.568803Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=new_bigram_model, prefix=\"steven\", suffix=\"directed traffic\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.8365228375749165,\n",
       " 'soderbergh': 0.1630062288238869,\n",
       " 'seagal': 0.00022019780264424577,\n",
       " 'shainberg': 0.00011667623828422371,\n",
       " ',': 5.6933766430629166e-05,\n",
       " 'segal': 4.861509928509321e-05,\n",
       " '_STOP_': 2.1530426428643396e-05,\n",
       " 'the': 3.4164779032233527e-06,\n",
       " 'a': 2.8885597470367713e-06,\n",
       " '.': 6.752304732334426e-07}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:54.321800Z",
     "start_time": "2025-04-16T12:42:52.218804Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=new_bigram_model, prefix=\"steven\", suffix=\"directed ai\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.8365228375749169,\n",
       " 'soderbergh': 0.16300622882388696,\n",
       " 'seagal': 0.00022019780264424585,\n",
       " 'shainberg': 0.00011667623828422374,\n",
       " ',': 5.693376643062918e-05,\n",
       " 'segal': 4.861509928509323e-05,\n",
       " '_STOP_': 2.1530426428643402e-05,\n",
       " 'the': 3.4164779032233535e-06,\n",
       " 'a': 2.8885597470367718e-06,\n",
       " '.': 6.752304732334427e-07}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:42:55.393809Z",
     "start_time": "2025-04-16T12:42:55.381801Z"
    }
   },
   "source": [
    "# here the \"knowledge\" between the last name of director and movie title is within 6 words\n",
    "even_more_texts = [\n",
    "    'steven spielberg was the director of jaws',\n",
    "    'steven spielberg was the director of et',\n",
    "    'steven spielberg was the director of ai',\n",
    "    'steven soderbergh was the director of traffic'\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:43:00.759020Z",
     "start_time": "2025-04-16T12:42:56.000221Z"
    }
   },
   "source": [
    "ngram_counts_v3 = count_ngrams_up_to(6, more_texts + even_more_texts + list(movie_reviews_df.text))\n",
    "trigram_model_v3 = NGramLanguageModel(n=3, ngram_counts=ngram_counts_v3, back_off_discount=0.1)\n",
    "sixgram_model = NGramLanguageModel(n=6, ngram_counts=ngram_counts_v3, back_off_discount=0.1)"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:43:09.600017Z",
     "start_time": "2025-04-16T12:43:02.273022Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=sixgram_model, prefix=\"steven\", suffix=\"was the director of ai\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.9817584686104596,\n",
       " 'soderbergh': 0.018241531389540364,\n",
       " 'seagal': 0.0,\n",
       " 'shainberg': 0.0,\n",
       " 'segal': 0.0,\n",
       " '.': 0.0,\n",
       " '_STOP_': 0.0,\n",
       " 'the': 0.0,\n",
       " ',': 0.0,\n",
       " 'a': 0.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:43:18.827024Z",
     "start_time": "2025-04-16T12:43:11.360020Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=sixgram_model, prefix=\"steven\", suffix=\"was the director of traffic\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'soderbergh': 0.9083374655992839,\n",
       " 'spielberg': 0.09166253440071612,\n",
       " 'seagal': 0.0,\n",
       " 'shainberg': 0.0,\n",
       " 'segal': 0.0,\n",
       " '.': 0.0,\n",
       " '_STOP_': 0.0,\n",
       " 'the': 0.0,\n",
       " ',': 0.0,\n",
       " 'a': 0.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:43:24.636024Z",
     "start_time": "2025-04-16T12:43:20.438021Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=trigram_model_v3, prefix=\"steven\", suffix=\"was the director of traffic\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.8032306918578586,\n",
       " 'soderbergh': 0.19676930328121087,\n",
       " 'seagal': 2.0496918378130644e-09,\n",
       " '_STOP_': 1.6962856196816857e-09,\n",
       " 'shainberg': 9.70037309323985e-10,\n",
       " 'the': 5.381371959803274e-11,\n",
       " 'a': 4.549904935505647e-11,\n",
       " ',': 3.111745503040745e-11,\n",
       " '.': 1.4485752752514247e-11,\n",
       " 'segal': 0.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:43:30.343025Z",
     "start_time": "2025-04-16T12:43:26.147023Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=trigram_model_v3, prefix=\"steven\", suffix=\"was the director of ai\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.8032306918578586,\n",
       " 'soderbergh': 0.19676930328121087,\n",
       " 'seagal': 2.0496918378130644e-09,\n",
       " '_STOP_': 1.6962856196816857e-09,\n",
       " 'shainberg': 9.70037309323985e-10,\n",
       " 'the': 5.381371959803274e-11,\n",
       " 'a': 4.549904935505647e-11,\n",
       " ',': 3.111745503040745e-11,\n",
       " '.': 1.4485752752514247e-11,\n",
       " 'segal': 0.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:43:39.263020Z",
     "start_time": "2025-04-16T12:43:31.991029Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=sixgram_model, prefix=\"steven\", suffix=\"was the director of ai\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.9817584686104596,\n",
       " 'soderbergh': 0.018241531389540364,\n",
       " 'seagal': 0.0,\n",
       " 'shainberg': 0.0,\n",
       " 'segal': 0.0,\n",
       " '.': 0.0,\n",
       " '_STOP_': 0.0,\n",
       " 'the': 0.0,\n",
       " ',': 0.0,\n",
       " 'a': 0.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:43:48.235684Z",
     "start_time": "2025-04-16T12:43:40.898499Z"
    }
   },
   "source": [
    "fill_in_the_gap(ngram_model=sixgram_model, prefix=\"steven\", suffix=\"was the director of ai\", choices=list(p_next_steven.keys()))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spielberg': 0.9817584686104596,\n",
       " 'soderbergh': 0.018241531389540364,\n",
       " 'seagal': 0.0,\n",
       " 'shainberg': 0.0,\n",
       " 'segal': 0.0,\n",
       " '.': 0.0,\n",
       " '_STOP_': 0.0,\n",
       " 'the': 0.0,\n",
       " ',': 0.0,\n",
       " 'a': 0.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esade-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
