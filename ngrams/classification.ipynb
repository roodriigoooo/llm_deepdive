{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# Classification of Movie Reviews\n",
    "\n",
    "\n",
    "This notebook trains classifiers that take a movie review and decide if it is positive or negative. This is an instance of sentence classification, i.e. classifying an input sentence into a predefined set of categories. In turn, it is an instance of text classification. For our movie reviews, texts are one-sentence reviews, and the categories (or labels) are either positive or negative. \n",
    "\n",
    "This is a simplified task. In general, these labels are not exclusive: a sentence can be both positive and negative (\"I love the script but hate the main actor.\"), or simply be neutral, which means that a sentence is neither positive nor negative (\"I went to the movies.\"). \n",
    "\n",
    "Text classification is a wide area. You'll find plenty of background on it. It is a \"simple\" task in NLP, also studied in Information Retrieval and used as testbed of machine learning algorithms.\n",
    "\n",
    "Here is a paper using Convolutional Neural Networks for sentence classification: https://arxiv.org/pdf/1408.5882.pdf .  This notebook uses one of the datasets used in that paper. However, the results are not directly comparable (because the split into train and test is not exactly the same). In any case, we can see that many models get a test accuracy in between 75% and 82%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:58:44.304166Z",
     "start_time": "2025-03-18T17:58:36.046442Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import sys\n",
    "import argparse\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Movie Reviews with Positive/Negative Label\n",
    "\n",
    "This section loads the \"train\" portion of the movie reviews. In addition to the text, there's two more columns:\n",
    "* `label` is either `positive` or `negative`, indicating the sentiment of the review\n",
    "* `label_int` is simply 0 for negative reviews and 1 for positive reviews, it will be useful to use with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:09.023963Z",
     "start_time": "2025-03-18T17:59:08.984961Z"
    }
   },
   "outputs": [],
   "source": "mr_train_df = pd.read_csv('../data/movie_reviews_train.csv')"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:13.941055Z",
     "start_time": "2025-03-18T17:59:13.922625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the entire movie is so formulaic and forgettable that it's hardly over before it begins to fade from memory .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the whole mess boils down to a transparently hypocritical work that feels as though it's trying to set the women's liberation movement back 20 years .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smart , provocative and blisteringly funny .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'wouldn't it be nice if all guys got a taste of what it's like on the other side of the bra ? '</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>too loud , too long and too frantic by half , die another day suggests that the bond franchise has run into a creative wall that 007 cannot fly over , tunnel under or barrel through .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>an indispensable peek at the art and the agony of making people laugh .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9591</th>\n",
       "      <td>this insufferable movie is meant to make you think about existential suffering . instead , it'll only put you to sleep .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9592</th>\n",
       "      <td>breen's script is sketchy with actorish notations on the margin of acting .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9593</th>\n",
       "      <td>it's plotless , shapeless -- and yet , it must be admitted , not entirely humorless . indeed , the more outrageous bits achieve a shock-you-into-laughter intensity of almost dadaist proportions .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9594</th>\n",
       "      <td>a relative letdown .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9595 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                     text     label  label_int  split\n",
       "0                                                                                           the entire movie is so formulaic and forgettable that it's hardly over before it begins to fade from memory .  negative          0  train\n",
       "1                                                  the whole mess boils down to a transparently hypocritical work that feels as though it's trying to set the women's liberation movement back 20 years .  negative          0  train\n",
       "2                                                                                                                                                            smart , provocative and blisteringly funny .  positive          1  train\n",
       "3                                                                                                         'wouldn't it be nice if all guys got a taste of what it's like on the other side of the bra ? '  negative          0  train\n",
       "4                 too loud , too long and too frantic by half , die another day suggests that the bond franchise has run into a creative wall that 007 cannot fly over , tunnel under or barrel through .  negative          0  train\n",
       "...                                                                                                                                                                                                   ...       ...        ...    ...\n",
       "9590                                                                                                                              an indispensable peek at the art and the agony of making people laugh .  positive          1  train\n",
       "9591                                                                             this insufferable movie is meant to make you think about existential suffering . instead , it'll only put you to sleep .  negative          0  train\n",
       "9592                                                                                                                          breen's script is sketchy with actorish notations on the margin of acting .  negative          0  train\n",
       "9593  it's plotless , shapeless -- and yet , it must be admitted , not entirely humorless . indeed , the more outrageous bits achieve a shock-you-into-laughter intensity of almost dadaist proportions .  positive          1  train\n",
       "9594                                                                                                                                                                                 a relative letdown .  negative          0  train\n",
       "\n",
       "[9595 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels in this dataset were artificially balanced by the original authors. There's roughly 50% of positive reviews and 50% of negative reviews. The `df.describe` function confirms this (the mean of `label_int` is near 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:22.656650Z",
     "start_time": "2025-03-18T17:59:22.638522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.496821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label_int\n",
       "count  9595.000000\n",
       "mean      0.496821\n",
       "std       0.500016\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:29.143519Z",
     "start_time": "2025-03-18T17:59:29.133438Z"
    }
   },
   "outputs": [],
   "source": "mr_test_df = pd.read_csv('../data/movie_reviews_test.csv')"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:31.779412Z",
     "start_time": "2025-03-18T17:59:31.770145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what really surprises about wisegirls is its low-key quality and genuine tenderness .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ultimately , it ponders the reasons we need stories so much .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offers a breath of the fresh air of true sophistication .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scores a few points for doing what it does with a dedicated and good-hearted professionalism .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>the hanukkah spirit seems fried in pork .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>doesn't come close to justifying the hype that surrounded its debut at the sundance film festival two years ago .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>the film didn't move me one way or the other , but it was an honest effort and if you want to see a flick about telemarketers this one will due .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>as saccharine as it is disposable .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>the attempt to build up a pressure cooker of horrified awe emerges from the simple fact that the movie has virtually nothing to show .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1067 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   text     label  label_int split\n",
       "0                                                                                                                        effective but too-tepid biopic  positive          1  test\n",
       "1                                                                 what really surprises about wisegirls is its low-key quality and genuine tenderness .  positive          1  test\n",
       "2                                                                                         ultimately , it ponders the reasons we need stories so much .  positive          1  test\n",
       "3                                                                                             offers a breath of the fresh air of true sophistication .  positive          1  test\n",
       "4                                                        scores a few points for doing what it does with a dedicated and good-hearted professionalism .  positive          1  test\n",
       "...                                                                                                                                                 ...       ...        ...   ...\n",
       "1062                                                                                                          the hanukkah spirit seems fried in pork .  negative          0  test\n",
       "1063                                  doesn't come close to justifying the hype that surrounded its debut at the sundance film festival two years ago .  negative          0  test\n",
       "1064  the film didn't move me one way or the other , but it was an honest effort and if you want to see a flick about telemarketers this one will due .  negative          0  test\n",
       "1065                                                                                                                as saccharine as it is disposable .  negative          0  test\n",
       "1066             the attempt to build up a pressure cooker of horrified awe emerges from the simple fact that the movie has virtually nothing to show .  negative          0  test\n",
       "\n",
       "[1067 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check that the test data has the same distribution of labels. \n",
    "\n",
    "It is important to note that here we run a check of our files. In real experimental work, it is very important not to gather statistics\n",
    "about the test data: measuring the distribution of labels on the test is cheating. This is because machine learning _is about_ inducing the\n",
    "true distribution of test labels using separate data to develop the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:34.202133Z",
     "start_time": "2025-03-18T17:59:34.192285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1067.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.528585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label_int\n",
       "count  1067.000000\n",
       "mean      0.528585\n",
       "std       0.499416\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "This section uses the `sklearn` function to evaluate classifiers. There are several metrics of interest. Let's first focus on accuracy, i.e. the portion of correct predictions in the test. Later we will see precision and recall. The `sklearn.metrics.classification_report` gets as input the list of correct labels (as integers) and the list of predictions, and computes the metrics. \n",
    "\n",
    "To try it, let's define two dummy classifiers, one that always predicts \"positive\" (i.e. 1) and another that always predicts \"negative\" (i.e. 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:37.453443Z",
     "start_time": "2025-03-18T17:59:37.449827Z"
    }
   },
   "outputs": [],
   "source": [
    "def dummy_positive(text):\n",
    "    return 1\n",
    "\n",
    "def dummy_negative(text):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's eval the dummy positive (and check it gives the dataset mean of `label_int`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T17:59:47.299678Z",
     "start_time": "2025-03-18T17:59:47.280556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: predict always positive\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       503\n",
      "    positive       0.53      1.00      0.69       564\n",
      "\n",
      "    accuracy                           0.53      1067\n",
      "   macro avg       0.26      0.50      0.35      1067\n",
      "weighted avg       0.28      0.53      0.37      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Baseline: predict always positive')\n",
    "print(classification_report(mr_test_df.label_int, \n",
    "                            [dummy_positive(text) for text in mr_test_df.text],\n",
    "                            target_names=['negative', 'positive'], \n",
    "                            zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's eval the dummy negative classifier (which should have accuracy equal to 1 minus the mean of label_int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:00:06.708413Z",
     "start_time": "2025-03-18T18:00:06.692459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: predict always negative\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      1.00      0.64       503\n",
      "    positive       0.00      0.00      0.00       564\n",
      "\n",
      "    accuracy                           0.47      1067\n",
      "   macro avg       0.24      0.50      0.32      1067\n",
      "weighted avg       0.22      0.47      0.30      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Baseline: predict always negative')\n",
    "print(classification_report(mr_test_df.label_int, \n",
    "                           [dummy_negative(text) for text in mr_test_df.text],\n",
    "                            target_names=['negative', 'positive'], \n",
    "                            zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Bag-of-words classifiers using Scikit-Learn"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:00:35.652101Z",
     "start_time": "2025-03-18T18:00:35.071983Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def make_sklearn_naive_bayes():\n",
    "    classifier = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    return classifier\n",
    "\n",
    "def make_sklearn_sgd():\n",
    "    classifier = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                              alpha=1e-3, random_state=42,\n",
    "                              max_iter=5, tol=None)),\n",
    "        ])\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model\n",
    "\n",
    "Let's start training a Naive Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:00:54.874515Z",
     "start_time": "2025-03-18T18:00:54.599653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie reviews naive bayes model\n",
    "mr_naivebayes = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])\n",
    "mr_naivebayes.fit(mr_train_df.text, mr_train_df.label_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do predictions. The `predict` function receives a list of texts, and computes a label (integer) for each input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:01.280970Z",
     "start_time": "2025-03-18T18:01:01.274055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: the story is horrible                     prediction_int: 0   prediction: negative\n",
      "Text: the story is not great                    prediction_int: 1   prediction: positive\n",
      "Text:  awesome!                                 prediction_int: 1   prediction: positive\n",
      "Text: i liked the movie                         prediction_int: 1   prediction: positive\n",
      "Text: i enjoyed it a lot                        prediction_int: 1   prediction: positive\n",
      "Text: I didn't like it at all                   prediction_int: 0   prediction: negative\n"
     ]
    }
   ],
   "source": [
    "input_texts = ['the story is horrible', \n",
    "               'the story is not great',\n",
    "               ' awesome!', \n",
    "               'i liked the movie', \n",
    "               'i enjoyed it a lot', \n",
    "               \"I didn't like it at all\"]\n",
    "predictions = mr_naivebayes.predict(input_texts)\n",
    "for text, pred_int in zip(input_texts, predictions):\n",
    "    print('Text: {:40s}  prediction_int: {}   prediction: {}'.format(text, pred_int, 'positive' if pred_int==1 else 'negative'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make predictions on the test set and check how many of them are correct (simple accuracy calculation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:04.646561Z",
     "start_time": "2025-03-18T18:01:04.618930Z"
    }
   },
   "outputs": [],
   "source": [
    "mr_test_naivebayes = mr_naivebayes.predict(mr_test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:14.172080Z",
     "start_time": "2025-03-18T18:01:14.168382Z"
    }
   },
   "outputs": [],
   "source": [
    "diff = mr_test_naivebayes == mr_test_df.label_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:16.992937Z",
     "start_time": "2025-03-18T18:01:16.987664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.781630740393627"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(diff)[True]/len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation using `sklearn` metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:19.452298Z",
     "start_time": "2025-03-18T18:01:19.437910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.78      0.77       503\n",
      "    positive       0.80      0.78      0.79       564\n",
      "\n",
      "    accuracy                           0.78      1067\n",
      "   macro avg       0.78      0.78      0.78      1067\n",
      "weighted avg       0.78      0.78      0.78      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(mr_test_df.label_int, \n",
    "                            mr_test_naivebayes, \n",
    "                            target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD classifiers\n",
    "\n",
    "Let's now train an SGD classifier using the Hinge loss. \n",
    "\n",
    "The alpha parameter controls the regularization: lower values of alpha mean that the model is less regularized. It's worth trying several values of alpha, and see how the results change. Try it by orders of magnitude: 0.1, 0.01, 0.001, ..., 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:22.554547Z",
     "start_time": "2025-03-18T18:01:22.108116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.76      0.75       503\n",
      "    positive       0.78      0.77      0.77       564\n",
      "\n",
      "    accuracy                           0.76      1067\n",
      "   macro avg       0.76      0.76      0.76      1067\n",
      "weighted avg       0.76      0.76      0.76      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Movie Reviews SGD classifier\n",
    "mr_sgd = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                              alpha=1e-5, random_state=42,\n",
    "                              max_iter=100, tol=None)),\n",
    "        ])\n",
    "mr_sgd.fit(mr_train_df.text, mr_train_df.label_int)\n",
    "\n",
    "# eval\n",
    "print(classification_report(mr_test_df.label_int, \n",
    "                            mr_sgd.predict(mr_test_df.text), \n",
    "                            target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect weights of the SGD model\n",
    "\n",
    "We will now look at what the SGD model learned. The following funtion \"extracts\" an array of the learned parameters of the model. Each parameter is a tuple `(word, weight)`. The parameters are sorted by its weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:25.692711Z",
     "start_time": "2025-03-18T18:01:25.688272Z"
    }
   },
   "outputs": [],
   "source": [
    "def sort_feature_weights(sk_pipe, fkey='vect', wkey='clf'):\n",
    "    F = sk_pipe[fkey].get_feature_names_out()\n",
    "    W = sk_pipe[wkey].coef_[0]\n",
    "    return sorted(zip(F, W), key=lambda fw: fw[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will list the n=20 words with most positive/negative weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:27.712086Z",
     "start_time": "2025-03-18T18:01:27.684215Z"
    }
   },
   "outputs": [],
   "source": [
    "mr_sgd_weights = sort_feature_weights(mr_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:29.801325Z",
     "start_time": "2025-03-18T18:01:29.794958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words most correlated with negative:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('unless', -5.174220295766207),\n",
       " ('wasn', -4.534456220992281),\n",
       " ('boldface', -4.414331942151835),\n",
       " ('flounders', -4.231376877158802),\n",
       " ('choppy', -4.053364380278769),\n",
       " ('pie', -3.9540375889065498),\n",
       " ('routine', -3.9326019277673345),\n",
       " ('mindless', -3.9177859183940202),\n",
       " ('benigni', -3.8614558325045545),\n",
       " ('bore', -3.833627528455997),\n",
       " ('conscientious', -3.8003476141605605),\n",
       " ('fishing', -3.7101439726858456),\n",
       " ('worst', -3.706579507951898),\n",
       " ('stupid', -3.687113895359782),\n",
       " ('eyre', -3.681220544220409),\n",
       " ('fails', -3.6665962191953865),\n",
       " ('poorly', -3.663973372343812),\n",
       " ('badly', -3.618171978602017),\n",
       " ('superficial', -3.6158750649068603),\n",
       " ('laughable', -3.5829910560447455)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=20\n",
    "print('words most correlated with negative:')\n",
    "mr_sgd_weights[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:34.959804Z",
     "start_time": "2025-03-18T18:01:34.953980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words most correlated with positive:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('marching', 3.6253398297753674),\n",
       " ('glorious', 3.6789064707746797),\n",
       " ('conscience', 3.6992191236368503),\n",
       " ('count', 3.71738091906613),\n",
       " ('marvel', 3.7224536363623435),\n",
       " ('accurate', 3.7353839524116457),\n",
       " ('unexpected', 3.756394750413514),\n",
       " ('frailty', 3.7785329948196975),\n",
       " ('smarter', 3.7986128472505185),\n",
       " ('astounds', 3.8293024903841055),\n",
       " ('ingenious', 3.883784639804631),\n",
       " ('weirder', 3.8984195639886456),\n",
       " ('grown', 3.960459031849739),\n",
       " ('moodiness', 3.9731458202187864),\n",
       " ('provides', 4.0087893658843265),\n",
       " ('apocalypse', 4.3145944004051175),\n",
       " ('caved', 4.404622794910473),\n",
       " ('taut', 4.433143482033556),\n",
       " ('engrossing', 4.715143819649762),\n",
       " ('liberating', 5.667985777757326)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('words most correlated with positive:')\n",
    "mr_sgd_weights[-n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the predictions on hand-picked textual examples ... To fully understand the prediction score, we need to consider that the model has a bias (intercept) term too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:37.372210Z",
     "start_time": "2025-03-18T18:01:37.367319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2639657872619253"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_sgd_bias = mr_sgd['clf'].intercept_[0]\n",
    "mr_sgd_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:39.258012Z",
     "start_time": "2025-03-18T18:01:39.251663Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction_score_breakdown(sk_model, text):\n",
    "    \"\"\"Computes the prediction score for a text, breaking down into the individual scores for each word of the text.\"\"\"\n",
    "    X = [text]\n",
    "    for step_name, model in sk_model.steps[:-1]:\n",
    "        X = model.transform(X)\n",
    "    nzrows, nzcolumns = X.nonzero()\n",
    "    \n",
    "    F = sk_model.steps[0][1].get_feature_names_out()\n",
    "    W = sk_model.steps[-1][1].coef_[0]\n",
    "    bias = sk_model.steps[-1][1].intercept_[0]\n",
    "    total_score = bias\n",
    "    print('prediction_score={:.3f}   bias={}'.format(total_score, bias))\n",
    "    for i,j in zip(nzrows, nzcolumns):\n",
    "        f = F[j]\n",
    "        v = X[i,j]\n",
    "        w = W[j]\n",
    "        s = w*v\n",
    "        total_score += s\n",
    "        print('prediction_score={:.3f}   fdim={:5d}, fword=\"{:s}\", value={:.4f}, weight={:.4f}, score={:.4f}'.format(total_score, j, f, v, w, s))\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:42.577015Z",
     "start_time": "2025-03-18T18:01:42.569747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.09841544])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_sgd.decision_function(['marvel marching glorious'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:44.198389Z",
     "start_time": "2025-03-18T18:01:44.180738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_score=-0.264   bias=-0.2639657872619253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.2639657872619253"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score_breakdown(mr_sgd, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:45.646892Z",
     "start_time": "2025-03-18T18:01:45.627481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_score=-0.264   bias=-0.2639657872619253\n",
      "prediction_score=3.415   fdim= 6616, fword=\"glorious\", value=1.0000, weight=3.6789, score=3.6789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4149406835127545"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score_breakdown(mr_sgd, 'glorious!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:46.821032Z",
     "start_time": "2025-03-18T18:01:46.802492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_score=-0.264   bias=-0.2639657872619253\n",
      "prediction_score=-0.076   fdim=  325, fword=\"actors\", value=0.5376, weight=0.3488, score=0.1875\n",
      "prediction_score=-0.928   fdim= 1239, fword=\"bad\", value=0.4641, weight=-1.8350, score=-0.8516\n",
      "prediction_score=-1.040   fdim= 2152, fword=\"but\", value=0.2761, weight=-0.4063, score=-0.1122\n",
      "prediction_score=-0.022   fdim= 6666, fword=\"good\", value=0.4064, weight=2.5060, score=1.0184\n",
      "prediction_score=-0.847   fdim=13493, fword=\"script\", value=0.5042, weight=-1.6363, score=-0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.8468562666086891"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score_breakdown(mr_sgd, 'good script but bad actors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:48.770656Z",
     "start_time": "2025-03-18T18:01:48.752702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_score=-0.264   bias=-0.2639657872619253\n",
      "prediction_score=-0.076   fdim=  325, fword=\"actors\", value=0.5376, weight=0.3488, score=0.1875\n",
      "prediction_score=-0.928   fdim= 1239, fword=\"bad\", value=0.4641, weight=-1.8350, score=-0.8516\n",
      "prediction_score=-1.040   fdim= 2152, fword=\"but\", value=0.2761, weight=-0.4063, score=-0.1122\n",
      "prediction_score=-0.022   fdim= 6666, fword=\"good\", value=0.4064, weight=2.5060, score=1.0184\n",
      "prediction_score=-0.847   fdim=13493, fword=\"script\", value=0.5042, weight=-1.6363, score=-0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.8468562666086891"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score_breakdown(mr_sgd, 'bad script but good actors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bag-of-ngrams (and Grid-Search in sklearn)\n",
    "\n",
    "A simple bag-of-words model has clearly many limitations. It completely ignores word order, and can shuffle meaning. Under a pure bag-of-words, \"I love the script, I hate the music\" is equivalent to \"I hate the script, I love the music.\". \n",
    "\n",
    "A simple generalization of words are n-grams. If a sentence is a sequence of words, then an n-gram is a subsequence of size n. As such, a word is a 1-gram (unigram), while two consecutive words are a 2-gram (bigram). \n",
    "\n",
    "This is very popular in NLP and information retrieval. It is one of the foundations of statistical NLP!!! \n",
    "\n",
    "Let's play with it. We first define a convenience function to create an `sklearn` text analyzer, that extracts n-grams, up to a given n. The resulting representation is a bag-of-ngrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:51.267044Z",
     "start_time": "2025-03-18T18:01:51.263243Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_sklearn_analyzer(n=1):\n",
    "    \"\"\"Creates a text analyzer from sklearn that extracts n-grams.\"\"\"\n",
    "    vect = CountVectorizer(stop_words=[], ngram_range=(1,n))\n",
    "    analyzer = vect.build_analyzer()\n",
    "    return analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:54.174319Z",
     "start_time": "2025-03-18T18:01:54.170665Z"
    }
   },
   "outputs": [],
   "source": [
    "unigram_analyzer = make_sklearn_analyzer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:55.323054Z",
     "start_time": "2025-03-18T18:01:55.318013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'the', 'script', 'hate', 'the', 'music']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I love the script, I hate the music\"\n",
    "unigram_analyzer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:56.511020Z",
     "start_time": "2025-03-18T18:01:56.505884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate', 'the', 'script', 'love', 'the', 'music']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I hate the script, I love the music\"\n",
    "unigram_analyzer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:57.857810Z",
     "start_time": "2025-03-18T18:01:57.852594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate',\n",
       " 'the',\n",
       " 'script',\n",
       " 'love',\n",
       " 'the',\n",
       " 'music',\n",
       " 'hate the',\n",
       " 'the script',\n",
       " 'script love',\n",
       " 'love the',\n",
       " 'the music']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_analyzer = make_sklearn_analyzer(2)\n",
    "bigram_analyzer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:01:59.676436Z",
     "start_time": "2025-03-18T18:01:59.671163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate',\n",
       " 'the',\n",
       " 'script',\n",
       " 'love',\n",
       " 'the',\n",
       " 'music',\n",
       " 'hate the',\n",
       " 'the script',\n",
       " 'script love',\n",
       " 'love the',\n",
       " 'the music',\n",
       " 'hate the script',\n",
       " 'the script love',\n",
       " 'script love the',\n",
       " 'love the music']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_analyzer = make_sklearn_analyzer(3)\n",
    "trigram_analyzer(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Grid-search in `sklearn`\n"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:02:02.938631Z",
     "start_time": "2025-03-18T18:02:02.932613Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def crossvalidation_report_df(grid_cv): \n",
    "    \"\"\"Convenience  function. \n",
    "    \n",
    "    Creates a simple dataframe that reports the results of a \n",
    "    cros-validation experiment. The input grid_cv must be fit. \n",
    "    \n",
    "    Returns a dataframe, sorted by rank of experiment. \n",
    "    \"\"\"\n",
    "    # pick columns that define each experiment (start with param)\n",
    "    # and the columns that report mean_test and rank_test results\n",
    "    cols = [c for c in grid_cv.cv_results_ if (c.startswith('param') or \n",
    "                                               c in ['mean_test_score', 'rank_test_score'])]\n",
    "\n",
    "    # sort original df by rank, and select columns\n",
    "    return pd.DataFrame(grid_cv.cv_results_).sort_values(by='rank_test_score')[cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define one grid-search for SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:02:05.633355Z",
     "start_time": "2025-03-18T18:02:05.628507Z"
    }
   },
   "outputs": [],
   "source": [
    "# this defines the base sklearn pipeline we want tot tune\n",
    "sgd_grid_estimator = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', random_state=42, max_iter=100, tol=None)),\n",
    "])\n",
    "\n",
    "# this defines the configurations\n",
    "sgd_grid_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1,3)],\n",
    "    'clf__alpha': (1e-3, 1e-6, 1e-9, 1e-12)\n",
    "}\n",
    "\n",
    "# we create the grid\n",
    "sgd_grid= GridSearchCV(sgd_grid_estimator, sgd_grid_parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Attention* the cell below will start grid search, which trains many models. It can take some time ... be patient, or reduce the combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:00.878238Z",
     "start_time": "2025-03-18T18:02:11.990751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        SGDClassifier(max_iter=100,\n",
       "                                                      random_state=42,\n",
       "                                                      tol=None))]),\n",
       "             param_grid={&#x27;clf__alpha&#x27;: (0.001, 1e-06, 1e-09, 1e-12),\n",
       "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        SGDClassifier(max_iter=100,\n",
       "                                                      random_state=42,\n",
       "                                                      tol=None))]),\n",
       "             param_grid={&#x27;clf__alpha&#x27;: (0.001, 1e-06, 1e-09, 1e-12),\n",
       "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]},\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer(ngram_range=(1, 2))),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 SGDClassifier(alpha=1e-06, max_iter=100, random_state=42,\n",
       "                               tol=None))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SGDClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(alpha=1e-06, max_iter=100, random_state=42, tol=None)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        SGDClassifier(max_iter=100,\n",
       "                                                      random_state=42,\n",
       "                                                      tol=None))]),\n",
       "             param_grid={'clf__alpha': (0.001, 1e-06, 1e-09, 1e-12),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_grid.fit(mr_train_df.text, mr_train_df.label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:10.283699Z",
     "start_time": "2025-03-18T18:03:10.255432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}</td>\n",
       "      <td>0.773111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}</td>\n",
       "      <td>0.770401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'clf__alpha': 1e-09, 'vect__ngram_range': (1, 3)}</td>\n",
       "      <td>0.755185</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 1e-09, 'vect__ngram_range': (1, 2)}</td>\n",
       "      <td>0.755081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 1e-12, 'vect__ngram_range': (1, 2)}</td>\n",
       "      <td>0.754247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'clf__alpha': 1e-12, 'vect__ngram_range': (1, 3)}</td>\n",
       "      <td>0.751016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 1e-09, 'vect__ngram_range': (1, 1)}</td>\n",
       "      <td>0.735591</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}</td>\n",
       "      <td>0.733507</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 1e-12, 'vect__ngram_range': (1, 1)}</td>\n",
       "      <td>0.733403</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}</td>\n",
       "      <td>0.726733</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}</td>\n",
       "      <td>0.714018</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}</td>\n",
       "      <td>0.683898</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_clf__alpha param_vect__ngram_range                                              params  mean_test_score  rank_test_score\n",
       "4       1.000000e-06                  (1, 2)  {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.773111                1\n",
       "5       1.000000e-06                  (1, 3)  {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.770401                2\n",
       "8       1.000000e-09                  (1, 3)  {'clf__alpha': 1e-09, 'vect__ngram_range': (1, 3)}         0.755185                3\n",
       "7       1.000000e-09                  (1, 2)  {'clf__alpha': 1e-09, 'vect__ngram_range': (1, 2)}         0.755081                4\n",
       "10      1.000000e-12                  (1, 2)  {'clf__alpha': 1e-12, 'vect__ngram_range': (1, 2)}         0.754247                5\n",
       "11      1.000000e-12                  (1, 3)  {'clf__alpha': 1e-12, 'vect__ngram_range': (1, 3)}         0.751016                6\n",
       "6       1.000000e-09                  (1, 1)  {'clf__alpha': 1e-09, 'vect__ngram_range': (1, 1)}         0.735591                7\n",
       "3       1.000000e-06                  (1, 1)  {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.733507                8\n",
       "9       1.000000e-12                  (1, 1)  {'clf__alpha': 1e-12, 'vect__ngram_range': (1, 1)}         0.733403                9\n",
       "0       1.000000e-03                  (1, 1)  {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.726733               10\n",
       "1       1.000000e-03                  (1, 2)  {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.714018               11\n",
       "2       1.000000e-03                  (1, 3)  {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.683898               12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossvalidation_report_df(sgd_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:13.057625Z",
     "start_time": "2025-03-18T18:03:12.995148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.79      0.79       503\n",
      "    positive       0.81      0.82      0.82       564\n",
      "\n",
      "    accuracy                           0.81      1067\n",
      "   macro avg       0.80      0.80      0.80      1067\n",
      "weighted avg       0.80      0.81      0.80      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_best = sgd_grid.best_estimator_\n",
    "print('BEST PARAMS:', sgd_grid.best_params_)\n",
    "# eval\n",
    "print(classification_report(mr_test_df.label_int, \n",
    "                            sgd_best.predict(mr_test_df.text), \n",
    "                            target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:15.695972Z",
     "start_time": "2025-03-18T18:03:15.490178Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd_best_weights = sort_feature_weights(sgd_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:17.361592Z",
     "start_time": "2025-03-18T18:03:17.307804Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd_best_weights = sorted(sgd_best_weights, key=lambda fw: fw[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:18.934934Z",
     "start_time": "2025-03-18T18:03:18.927469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights associated with positive reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('still', 3.7400963405321797),\n",
       " ('cinema', 3.6505771877913635),\n",
       " ('works', 3.486407496281639),\n",
       " ('beautiful', 3.340373551322183),\n",
       " ('solid', 3.2654964163731997),\n",
       " ('enjoyable', 3.231271598317809),\n",
       " ('and', 3.13840199399024),\n",
       " ('funny', 3.097583408112965),\n",
       " ('unexpected', 3.0756243905833607),\n",
       " ('entertaining', 3.0388488684385977),\n",
       " ('powerful', 3.0310451255398365),\n",
       " ('wonderful', 2.755236206884593),\n",
       " ('honest', 2.747074885887034),\n",
       " ('fun', 2.746002319658066),\n",
       " ('world', 2.7132857354154445),\n",
       " ('warm', 2.6909739770486394),\n",
       " ('hilarious', 2.6757404051761666),\n",
       " ('glorious', 2.6629359820420597),\n",
       " ('heart', 2.6439902559341997),\n",
       " ('refreshing', 2.5902746930342855),\n",
       " ('delivers', 2.5876519425596096),\n",
       " ('human', 2.5634164612763484),\n",
       " ('remarkable', 2.532848746783074),\n",
       " ('treat', 2.5126389139003296),\n",
       " ('delightful', 2.501287149013983),\n",
       " ('with', 2.4918319971083065),\n",
       " ('beautifully', 2.4565293520733484),\n",
       " ('unique', 2.4532179978438955),\n",
       " ('provides', 2.4493178929629256),\n",
       " ('mesmerizing', 2.448059284947121),\n",
       " ('flaws', 2.4442920903951175),\n",
       " ('brilliant', 2.428471323390296),\n",
       " ('never fails', 2.421654710232767),\n",
       " ('masterpiece', 2.4213252158352288),\n",
       " ('inventive', 2.4110346015475907),\n",
       " ('fascinating', 2.403737388066626),\n",
       " ('rich', 2.4006799224322912),\n",
       " ('rare', 2.3654480580750747),\n",
       " ('portrait', 2.3374638908582637),\n",
       " ('thoughtful', 2.3299820854997457),\n",
       " ('never once', 2.325947158454947),\n",
       " ('once predictable', 2.325947158454947),\n",
       " ('moving', 2.3202666815745014),\n",
       " ('is more', 2.310968549462901),\n",
       " ('family', 2.307378444350652),\n",
       " ('sweet', 2.3055466572764445),\n",
       " ('performances', 2.2994750245033746),\n",
       " ('polished', 2.289726549282961),\n",
       " ('us', 2.2831827828603903),\n",
       " ('chilling', 2.2628499933042456)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model weights associated with positive reviews')\n",
    "sgd_best_weights[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:21.434943Z",
     "start_time": "2025-03-18T18:03:21.428302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights associated with negative reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('an action', -2.17167335556074),\n",
       " ('out of', -2.195339841885952),\n",
       " ('suffers', -2.20799606099705),\n",
       " ('cartoon', -2.229898184661163),\n",
       " ('stale', -2.250471062152165),\n",
       " ('ill', -2.251795482238586),\n",
       " ('superficial', -2.262962863599115),\n",
       " ('unimaginative', -2.265947747287026),\n",
       " ('for movie', -2.2969557601492347),\n",
       " ('dreary', -2.311856778778193),\n",
       " ('video', -2.32086830190218),\n",
       " ('seagal', -2.330044204028073),\n",
       " ('to one', -2.35897924090565),\n",
       " ('bland', -2.3809052946878078),\n",
       " ('lame', -2.415737660977717),\n",
       " ('disappointment', -2.422366530090093),\n",
       " ('incoherent', -2.4621134875392516),\n",
       " ('john', -2.5121980187496193),\n",
       " ('plodding', -2.534879066055758),\n",
       " ('unfunny', -2.552586778859063),\n",
       " ('mediocre', -2.5623583255315223),\n",
       " ('then', -2.575409944997356),\n",
       " ('feels', -2.6090055893820043),\n",
       " ('barely', -2.6403657879476152),\n",
       " ('mildly', -2.654315725890339),\n",
       " ('thin', -2.655794388267386),\n",
       " ('junk', -2.683132978523542),\n",
       " ('the problem', -2.6882280892584465),\n",
       " ('no', -2.6921228276460534),\n",
       " ('pretentious', -2.6948201407759775),\n",
       " ('fails', -2.7102197365136003),\n",
       " ('only', -2.7132984695729356),\n",
       " ('routine', -2.7191928158060716),\n",
       " ('so', -2.721377424283802),\n",
       " ('doesn', -2.7829217710032723),\n",
       " ('stupid', -2.7961070790804032),\n",
       " ('neither', -2.7980578098752296),\n",
       " ('bore', -2.8500191214721107),\n",
       " ('has all', -2.8590256229049587),\n",
       " ('tv', -2.9795320132015894),\n",
       " ('script', -2.9834082983757373),\n",
       " ('the worst', -3.060903547545085),\n",
       " ('flat', -3.064603242471335),\n",
       " ('badly', -3.0671851275964173),\n",
       " ('worst', -3.0774200968848704),\n",
       " ('lacks', -3.1024956671923016),\n",
       " ('bad', -3.2056838599241684),\n",
       " ('boring', -3.621733278851767),\n",
       " ('too', -4.456458654316024),\n",
       " ('dull', -4.459836707900093)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model weights associated with negative reviews')\n",
    "sgd_best_weights[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:23.098638Z",
     "start_time": "2025-03-18T18:03:23.095095Z"
    }
   },
   "outputs": [],
   "source": [
    "# convenience function: given a feature ngram, returns the number of \"grams\"\n",
    "# i.e. 1 for unigrams, 2 for bigrams, ....\n",
    "# simply counts the number of elements separated by space (this is how sklearn encodes unigrams)\n",
    "def ngram_order(f):\n",
    "    \"\"\"Returns the ngram order of a feature. \"\"\"\n",
    "    return len(f.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:24.824393Z",
     "start_time": "2025-03-18T18:03:24.762180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram weights associated with positive reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('never fails', 2.421654710232767),\n",
       " ('never once', 2.325947158454947),\n",
       " ('once predictable', 2.325947158454947),\n",
       " ('is more', 2.310968549462901),\n",
       " ('ever made', 2.25305862380259),\n",
       " ('better than', 2.199851565938953),\n",
       " ('it is', 2.18959488744057),\n",
       " ('but that', 2.1753026417629346),\n",
       " ('what makes', 2.1465030243795518),\n",
       " ('not only', 2.115111336482161),\n",
       " ('the best', 2.0777014860200054),\n",
       " ('up for', 2.064731074877175),\n",
       " ('may not', 2.0646655396326787),\n",
       " ('weird rewarding', 2.0358547574927757),\n",
       " ('never feels', 2.0282079456568),\n",
       " ('make it', 2.0206240674610148),\n",
       " ('but it', 1.974511157341453),\n",
       " ('for its', 1.9630177498857377),\n",
       " ('to resist', 1.9338122772751158),\n",
       " ('bad journey', 1.9130748822367378)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Bigram weights associated with positive reviews')\n",
    "[fw for fw in sgd_best_weights if ngram_order(fw[0])==2][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:26.541502Z",
     "start_time": "2025-03-18T18:03:26.489430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram weights associated with negative reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('enough for', -1.8693035793360577),\n",
       " ('case of', -1.9056559238005584),\n",
       " ('it exactly', -1.9058241605858),\n",
       " ('lacks the', -1.9121895251720191),\n",
       " ('first film', -1.9596079611178208),\n",
       " ('should have', -1.9687219250792547),\n",
       " ('at best', -1.9964359053054412),\n",
       " ('least moore', -2.027041064654314),\n",
       " ('work but', -2.0399780292395224),\n",
       " ('fact that', -2.0642072908849554),\n",
       " ('plays like', -2.0681409027681465),\n",
       " ('my own', -2.0949191323289402),\n",
       " ('you see', -2.127080873324575),\n",
       " ('an action', -2.17167335556074),\n",
       " ('out of', -2.195339841885952),\n",
       " ('for movie', -2.2969557601492347),\n",
       " ('to one', -2.35897924090565),\n",
       " ('the problem', -2.6882280892584465),\n",
       " ('has all', -2.8590256229049587),\n",
       " ('the worst', -3.060903547545085)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Bigram weights associated with negative reviews')\n",
    "[fw for fw in sgd_best_weights if len(fw[0].split())==2][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:28.302739Z",
     "start_time": "2025-03-18T18:03:28.296549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90613591])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_best.decision_function(['this marvel movie is not memorable at all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:29.471305Z",
     "start_time": "2025-03-18T18:03:29.360771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_score=-0.182   bias=-0.1823518644722022\n",
      "prediction_score=-0.346   fdim= 2779, fword=\"all\", value=0.1971, weight=-0.8289, score=-0.1634\n",
      "prediction_score=-0.458   fdim=10054, fword=\"at\", value=0.1952, weight=-0.5751, score=-0.1123\n",
      "prediction_score=-0.699   fdim=10069, fword=\"at all\", value=0.3673, weight=-0.6560, score=-0.2409\n",
      "prediction_score=-0.602   fdim=50770, fword=\"is\", value=0.1186, weight=0.8184, score=0.0971\n",
      "prediction_score=-0.763   fdim=51432, fword=\"is not\", value=0.2984, weight=-0.5387, score=-0.1607\n",
      "prediction_score=0.069   fdim=60448, fword=\"marvel\", value=0.4082, weight=2.0376, score=0.8317\n",
      "prediction_score=0.790   fdim=61346, fword=\"memorable\", value=0.3417, weight=2.1092, score=0.7208\n",
      "prediction_score=0.637   fdim=63855, fword=\"movie\", value=0.1597, weight=-0.9552, score=-0.1526\n",
      "prediction_score=0.578   fdim=64033, fword=\"movie is\", value=0.2720, weight=-0.2173, score=-0.0591\n",
      "prediction_score=0.354   fdim=66825, fword=\"not\", value=0.1882, weight=-1.1934, score=-0.2246\n",
      "prediction_score=1.015   fdim=66975, fword=\"not memorable\", value=0.4917, weight=1.3447, score=0.6612\n",
      "prediction_score=0.906   fdim=100654, fword=\"this\", value=0.1579, weight=-0.6883, score=-0.1087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9061359136690519"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score_breakdown(sgd_best, 'this marvel movie is not memorable at all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:33.400217Z",
     "start_time": "2025-03-18T18:03:33.278033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_score=-0.182   bias=-0.1823518644722022\n",
      "prediction_score=-0.282   fdim=26395, fword=\"did\", value=0.3925, weight=-0.2549, score=-0.1001\n",
      "prediction_score=-0.233   fdim=26411, fword=\"did not\", value=0.5407, weight=0.0917, score=0.0496\n",
      "prediction_score=0.216   fdim=31002, fword=\"enjoy\", value=0.3730, weight=1.2036, score=0.4489\n",
      "prediction_score=0.117   fdim=31019, fword=\"enjoy the\", value=0.5102, weight=-0.1932, score=-0.0986\n",
      "prediction_score=-0.058   fdim=63855, fword=\"movie\", value=0.1835, weight=-0.9552, score=-0.1753\n",
      "prediction_score=-0.316   fdim=66825, fword=\"not\", value=0.2162, weight=-1.1934, score=-0.2580\n",
      "prediction_score=-0.302   fdim=96572, fword=\"the\", value=0.0925, weight=0.1456, score=0.0135\n",
      "prediction_score=-0.727   fdim=98305, fword=\"the movie\", value=0.2555, weight=-1.6639, score=-0.4250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.7273216140615937"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score_breakdown(sgd_best, 'I did not enjoy the movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:37.428646Z",
     "start_time": "2025-03-18T18:03:37.310906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_score=-0.182   bias=-0.1823518644722022\n",
      "prediction_score=-0.251   fdim=10054, fword=\"at\", value=0.1185, weight=-0.5751, score=-0.0682\n",
      "prediction_score=-0.010   fdim=10225, fword=\"at the\", value=0.1649, weight=1.4575, score=0.2404\n",
      "prediction_score=0.650   fdim=19570, fword=\"cinema\", value=0.1808, weight=3.6506, score=0.6600\n",
      "prediction_score=0.597   fdim=26395, fword=\"did\", value=0.2075, weight=-0.2549, score=-0.0529\n",
      "prediction_score=0.623   fdim=26411, fword=\"did not\", value=0.2858, weight=0.0917, score=0.0262\n",
      "prediction_score=0.860   fdim=31002, fword=\"enjoy\", value=0.1971, weight=1.2036, score=0.2373\n",
      "prediction_score=0.808   fdim=31019, fword=\"enjoy the\", value=0.2697, weight=-0.1932, score=-0.0521\n",
      "prediction_score=0.985   fdim=50770, fword=\"is\", value=0.2160, weight=0.8184, score=0.1768\n",
      "prediction_score=0.900   fdim=51289, fword=\"is it\", value=0.4355, weight=-0.1953, score=-0.0851\n",
      "prediction_score=1.009   fdim=52030, fword=\"it\", value=0.2215, weight=0.4933, score=0.1093\n",
      "prediction_score=1.656   fdim=52434, fword=\"it is\", value=0.2954, weight=2.1896, score=0.6469\n",
      "prediction_score=1.564   fdim=63855, fword=\"movie\", value=0.0970, weight=-0.9552, score=-0.0926\n",
      "prediction_score=1.858   fdim=64263, fword=\"movie with\", value=0.2084, weight=1.4111, score=0.2940\n",
      "prediction_score=1.721   fdim=66825, fword=\"not\", value=0.1143, weight=-1.1934, score=-0.1364\n",
      "prediction_score=2.321   fdim=91252, fword=\"still\", value=0.1603, weight=3.7401, score=0.5995\n",
      "prediction_score=2.399   fdim=91366, fword=\"still works\", value=0.2985, weight=0.2624, score=0.0783\n",
      "prediction_score=2.413   fdim=96572, fword=\"the\", value=0.0978, weight=0.1456, score=0.0142\n",
      "prediction_score=2.552   fdim=97022, fword=\"the cinema\", value=0.2591, weight=0.5364, score=0.1390\n",
      "prediction_score=2.328   fdim=98305, fword=\"the movie\", value=0.1350, weight=-1.6639, score=-0.2247\n",
      "prediction_score=2.562   fdim=112258, fword=\"with\", value=0.0939, weight=2.4918, score=0.2339\n",
      "prediction_score=3.192   fdim=113564, fword=\"works\", value=0.1808, weight=3.4864, score=0.6303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1918144987220827"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score_breakdown(sgd_best, 'I did not enjoy the movie with still works at the cinema it is it is it bla bla is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Precision and recall\n",
    "\n",
    "This section looks at precision and recall metrics. They are an alternative to accuracy, and very often they are much more difficult. Accuracy only cares about right or wrong, but there is more. \n",
    "\n",
    "Consider the label \"positive\". There are truly positive examples, and if a classifier predicts \"negative\" for a positive example, it is making a \"false negative\" mistake, because the example is not negative. Now consider a truly negative example, if our classifier predicts \"positive\" it will make a \"false positive\" mistake. False positives and false negatives are all mistakes, and normal accuracy does not distinguish. Precision and recall specifically look at each of the sides of mistakes. \n",
    "\n",
    "Precision looks at \"false positive\" mistakes. Specifically, it is the fraction of true positives out of the total number of examples where a classifier predicts \"positive\". A precision of 100% means that every time a classifier says \"positive\" the example is truly positive. Lower precision means that there are false positives among our predictions. \n",
    "\n",
    "Recall looks at \"false negative\" mistakes. Out of all truly positive examples, it is the fraction that is correctly labeled as \"positive\". A recall of 100% means that our classifier will identify all truly positive examples in the data, probably at the expense of making precision mistakes. An extreme case is a dumb classifier that always predicts \"positive\", it will have recall at 100%, but precision will be the fraction of true positives in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:41.417998Z",
     "start_time": "2025-03-18T18:03:41.368723Z"
    }
   },
   "outputs": [],
   "source": [
    "mr_test_df['score_sgd_best'] = sgd_best.decision_function(mr_test_df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and let's visualize the data sorted by the prediction score ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:42.440174Z",
     "start_time": "2025-03-18T18:03:42.436084Z"
    }
   },
   "outputs": [],
   "source": [
    "mr_test_df.sort_values(by='score_sgd_best', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:43.406987Z",
     "start_time": "2025-03-18T18:03:43.398098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>split</th>\n",
       "      <th>score_sgd_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>bad company . bad movie . just plain bad .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-3.456775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>the plot is nothing but boilerplate clichs from start to finish , and the script assumes that not only would subtlety be lost on the target audience , but that it's also too stupid to realize that they've already seen this exact same movie a hundred times</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-3.192490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>generic thriller junk . teens only .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-3.131216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>it's supposed to be post-feminist breezy but ends up as tedious as the chatter of parrots raised on oprah .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.994342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>a tired , predictable , bordering on offensive , waste of time , money and celluloid .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-2.987306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                 text     label  label_int split  \\\n",
       "595                                                                                                                                                                                                                        bad company . bad movie . just plain bad .  negative          0  test   \n",
       "573   the plot is nothing but boilerplate clichs from start to finish , and the script assumes that not only would subtlety be lost on the target audience , but that it's also too stupid to realize that they've already seen this exact same movie a hundred times  negative          0  test   \n",
       "741                                                                                                                                                                                                                              generic thriller junk . teens only .  negative          0  test   \n",
       "1037                                                                                                                                                      it's supposed to be post-feminist breezy but ends up as tedious as the chatter of parrots raised on oprah .  negative          0  test   \n",
       "1045                                                                                                                                                                           a tired , predictable , bordering on offensive , waste of time , money and celluloid .  negative          0  test   \n",
       "\n",
       "      score_sgd_best  \n",
       "595        -3.456775  \n",
       "573        -3.192490  \n",
       "741        -3.131216  \n",
       "1037       -2.994342  \n",
       "1045       -2.987306  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:48.169327Z",
     "start_time": "2025-03-18T18:03:48.160614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>split</th>\n",
       "      <th>score_sgd_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>scott delivers a terrific performance in this fascinating portrait of a modern lothario .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>3.139697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>a wonderful , ghastly film .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>3.149427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>an entertaining , colorful , action-filled crime story with an intimate heart .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>3.193826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>jones has delivered a solidly entertaining and moving family drama .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>3.222283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[a] rare , beautiful film .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>3.391656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          text     label  label_int split  score_sgd_best\n",
       "367  scott delivers a terrific performance in this fascinating portrait of a modern lothario .  positive          1  test        3.139697\n",
       "425                                                               a wonderful , ghastly film .  positive          1  test        3.149427\n",
       "170            an entertaining , colorful , action-filled crime story with an intimate heart .  positive          1  test        3.193826\n",
       "480                       jones has delivered a solidly entertaining and moving family drama .  positive          1  test        3.222283\n",
       "23                                                                 [a] rare , beautiful film .  positive          1  test        3.391656"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_test_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T15:41:17.592732Z",
     "start_time": "2025-02-20T15:41:17.590602Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:50.969540Z",
     "start_time": "2025-03-18T18:03:50.954704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_int</th>\n",
       "      <th>split</th>\n",
       "      <th>score_sgd_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>none of this has the suavity or classical familiarity of bond , but much of it is good for a laugh . the problem with \" xxx \" is that its own action isn't very effective .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.001593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>no worse than a lot of the crap we've been offered this summer , and slightly better than men in black 2 as far as slapdash extraterrestrial comedies go .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>that is essentially what's missing from blackboards -- the sense of something bigger , some ultimate point .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.982993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>slow , silly and unintentionally hilarious .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.978434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>predictably melodramatic .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.969477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>the plot plummets into a comedy graveyard before janice comes racing to the rescue in the final reel .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.966050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>hollywood's answer to an air ball .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.962204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>like so many other allegedly scary movies , it gets so tangled up in the twist that it chokes the energy right out of the very audience it seeks to frighten .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.943751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>burns' fifth beer-soaked film feels in almost every possible way -- from the writing and direction to the soggy performances -- tossed off .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.943511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>a less-than-thrilling thriller .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.939905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>. . . there's a choppy , surface-effect feeling to the whole enterprise .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.936890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>half submarine flick , half ghost story , all in one criminally neglected film</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.936812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>[t]his slop doesn't even have potential as a cult film , as it's too loud to shout insults at the screen .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.934394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>despite modest aspirations its occasional charms are not to be dismissed .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.933047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>an unremarkable , modern action/comedy buddy movie whose only nod to nostalgia is in the title .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.933039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>while the humor is recognizably plympton , he has actually bothered to construct a real story this time .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.932718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>gaping plot holes sink this 'sub'-standard thriller and drag audience enthusiasm to crush depth .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.928147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>the picture is a primer on what happens when lack of know-how mixes with lack of give-a-damn .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.920219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>at some point , all this visual trickery stops being clever and devolves into flashy , vaguely silly overkill .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.919572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>ever see one of those comedies that just seem like a bad idea from frame one ?</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.918146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>it takes a certain kind of horror movie to qualify as 'worse than expected , ' but ghost ship somehow manages to do exactly that .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.915990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>by the time we learn that andrew's turnabout is fair play is every bit as awful as borchardt's coven , we can enjoy it anyway .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.915653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>it's hampered by a lifetime-channel kind of plot and a lead actress who is out of her depth .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.915244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>the film tries to touch on spousal abuse but veers off course and becomes just another revenge film .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.913179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>the misery of these people becomes just another voyeuristic spectacle , to be consumed and forgotten .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.913030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>[a] mess .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.911556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>it's not the least of afghan tragedies that this noble warlord would be consigned to the dustbin of history .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.911171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>represents the depths to which the girls-behaving-badly film has fallen .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.908816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>there isn't one moment in the film that surprises or delights .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.904951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>far too clever by half , howard's film is really a series of strung-together moments , with all the spaces in between filled with fantasies , daydreams , memories and one fantastic visual trope after another .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.904172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>dull , if not devoid of wit , this shaggy dog longs to frisk through the back alleys of history , but scarcely manages more than a modest , snoozy charm .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.903381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>presents nothing special and , until the final act , nothing overtly disagreeable .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.900653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>don't hate el crimen del padre amaro because it's anti-catholic . hate it because it's lousy .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.900211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>like the excruciating end of days , collateral damage presents schwarzenegger as a tragic figure , but sympathy really belongs with any viewer forced to watch him try out so many complicated facial expressions .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.897112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>so devoid of pleasure or sensuality that it cannot even be dubbed hedonistic .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.895771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>an achingly enthralling premise , the film is hindered by uneven dialogue and plot lapses .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.894497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>the pairing does sound promising in theory . . . but their lack of chemistry makes eddie murphy and robert deniro in showtime look like old , familiar vaudeville partners .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.894287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>it all plays out . . . like a high-end john hughes comedy , a kind of elder bueller's time out .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.890738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>if you saw it on tv , you'd probably turn it off , convinced that you had already seen that movie .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.877502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>rubbo runs through a remarkable amount of material in the film's short 90 minutes .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.874667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>if the film fails to fulfill its own ambitious goals , it nonetheless sustains interest during the long build-up of expository material .</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.871789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>all prints of this film should be sent to and buried on pluto .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.869896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>an impenetrable and insufferable ball of pseudo-philosophic twaddle .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.864988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>partway through watching this saccharine , easter-egg-colored concoction , you realize that it is made up of three episodes of a rejected tv show .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.861359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>it's hard to imagine any recent film , independent or otherwise , that makes as much of a mess as this one .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.861061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>a film with a great premise but only a great premise .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.849351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>jonathan parker's bartleby should have been the be-all-end-all of the modern-office anomie films .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.848369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>offers very little genuine romance and even fewer laughs . . . a sad sitcom of a movie , largely devoid of charm .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.826322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>it comes off as so silly that you wouldn't be surprised if ba , murdock and rest of the a-team were seen giving chase in a black and red van .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.825595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>i kept thinking over and over again , 'i should be enjoying this . ' but i wasn't .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>-0.824251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                     text     label  label_int split  score_sgd_best\n",
       "1021                                          none of this has the suavity or classical familiarity of bond , but much of it is good for a laugh . the problem with \" xxx \" is that its own action isn't very effective .  negative          0  test       -1.001593\n",
       "819                                                            no worse than a lot of the crap we've been offered this summer , and slightly better than men in black 2 as far as slapdash extraterrestrial comedies go .  negative          0  test       -1.000973\n",
       "774                                                                                                          that is essentially what's missing from blackboards -- the sense of something bigger , some ultimate point .  negative          0  test       -0.982993\n",
       "1020                                                                                                                                                                         slow , silly and unintentionally hilarious .  negative          0  test       -0.978434\n",
       "1023                                                                                                                                                                                           predictably melodramatic .  negative          0  test       -0.969477\n",
       "590                                                                                                                the plot plummets into a comedy graveyard before janice comes racing to the rescue in the final reel .  negative          0  test       -0.966050\n",
       "1002                                                                                                                                                                                  hollywood's answer to an air ball .  negative          0  test       -0.962204\n",
       "783                                                        like so many other allegedly scary movies , it gets so tangled up in the twist that it chokes the energy right out of the very audience it seeks to frighten .  negative          0  test       -0.943751\n",
       "1031                                                                         burns' fifth beer-soaked film feels in almost every possible way -- from the writing and direction to the soggy performances -- tossed off .  negative          0  test       -0.943511\n",
       "804                                                                                                                                                                                      a less-than-thrilling thriller .  negative          0  test       -0.939905\n",
       "682                                                                                                                                             . . . there's a choppy , surface-effect feeling to the whole enterprise .  negative          0  test       -0.936890\n",
       "126                                                                                                                                        half submarine flick , half ghost story , all in one criminally neglected film  positive          1  test       -0.936812\n",
       "932                                                                                                            [t]his slop doesn't even have potential as a cult film , as it's too loud to shout insults at the screen .  negative          0  test       -0.934394\n",
       "465                                                                                                                                            despite modest aspirations its occasional charms are not to be dismissed .  positive          1  test       -0.933047\n",
       "632                                                                                                                      an unremarkable , modern action/comedy buddy movie whose only nod to nostalgia is in the title .  negative          0  test       -0.933039\n",
       "351                                                                                                             while the humor is recognizably plympton , he has actually bothered to construct a real story this time .  positive          1  test       -0.932718\n",
       "1050                                                                                                                    gaping plot holes sink this 'sub'-standard thriller and drag audience enthusiasm to crush depth .  negative          0  test       -0.928147\n",
       "807                                                                                                                        the picture is a primer on what happens when lack of know-how mixes with lack of give-a-damn .  negative          0  test       -0.920219\n",
       "667                                                                                                       at some point , all this visual trickery stops being clever and devolves into flashy , vaguely silly overkill .  negative          0  test       -0.919572\n",
       "688                                                                                                                                        ever see one of those comedies that just seem like a bad idea from frame one ?  negative          0  test       -0.918146\n",
       "734                                                                                    it takes a certain kind of horror movie to qualify as 'worse than expected , ' but ghost ship somehow manages to do exactly that .  negative          0  test       -0.915990\n",
       "146                                                                                       by the time we learn that andrew's turnabout is fair play is every bit as awful as borchardt's coven , we can enjoy it anyway .  positive          1  test       -0.915653\n",
       "755                                                                                                                         it's hampered by a lifetime-channel kind of plot and a lead actress who is out of her depth .  negative          0  test       -0.915244\n",
       "871                                                                                                                 the film tries to touch on spousal abuse but veers off course and becomes just another revenge film .  negative          0  test       -0.913179\n",
       "627                                                                                                                the misery of these people becomes just another voyeuristic spectacle , to be consumed and forgotten .  negative          0  test       -0.913030\n",
       "881                                                                                                                                                                                                            [a] mess .  negative          0  test       -0.911556\n",
       "341                                                                                                         it's not the least of afghan tragedies that this noble warlord would be consigned to the dustbin of history .  positive          1  test       -0.911171\n",
       "914                                                                                                                                             represents the depths to which the girls-behaving-badly film has fallen .  negative          0  test       -0.908816\n",
       "971                                                                                                                                                       there isn't one moment in the film that surprises or delights .  negative          0  test       -0.904951\n",
       "885     far too clever by half , howard's film is really a series of strung-together moments , with all the spaces in between filled with fantasies , daydreams , memories and one fantastic visual trope after another .  negative          0  test       -0.904172\n",
       "789                                                            dull , if not devoid of wit , this shaggy dog longs to frisk through the back alleys of history , but scarcely manages more than a modest , snoozy charm .  negative          0  test       -0.903381\n",
       "1006                                                                                                                                  presents nothing special and , until the final act , nothing overtly disagreeable .  negative          0  test       -0.900653\n",
       "1046                                                                                                                       don't hate el crimen del padre amaro because it's anti-catholic . hate it because it's lousy .  negative          0  test       -0.900211\n",
       "642   like the excruciating end of days , collateral damage presents schwarzenegger as a tragic figure , but sympathy really belongs with any viewer forced to watch him try out so many complicated facial expressions .  negative          0  test       -0.897112\n",
       "622                                                                                                                                        so devoid of pleasure or sensuality that it cannot even be dubbed hedonistic .  negative          0  test       -0.895771\n",
       "582                                                                                                                           an achingly enthralling premise , the film is hindered by uneven dialogue and plot lapses .  negative          0  test       -0.894497\n",
       "874                                          the pairing does sound promising in theory . . . but their lack of chemistry makes eddie murphy and robert deniro in showtime look like old , familiar vaudeville partners .  negative          0  test       -0.894287\n",
       "437                                                                                                                      it all plays out . . . like a high-end john hughes comedy , a kind of elder bueller's time out .  positive          1  test       -0.890738\n",
       "1008                                                                                                                  if you saw it on tv , you'd probably turn it off , convinced that you had already seen that movie .  negative          0  test       -0.877502\n",
       "330                                                                                                                                   rubbo runs through a remarkable amount of material in the film's short 90 minutes .  positive          1  test       -0.874667\n",
       "458                                                                             if the film fails to fulfill its own ambitious goals , it nonetheless sustains interest during the long build-up of expository material .  positive          1  test       -0.871789\n",
       "809                                                                                                                                                       all prints of this film should be sent to and buried on pluto .  negative          0  test       -0.869896\n",
       "979                                                                                                                                                 an impenetrable and insufferable ball of pseudo-philosophic twaddle .  negative          0  test       -0.864988\n",
       "758                                                                   partway through watching this saccharine , easter-egg-colored concoction , you realize that it is made up of three episodes of a rejected tv show .  negative          0  test       -0.861359\n",
       "594                                                                                                          it's hard to imagine any recent film , independent or otherwise , that makes as much of a mess as this one .  negative          0  test       -0.861061\n",
       "624                                                                                                                                                                a film with a great premise but only a great premise .  negative          0  test       -0.849351\n",
       "619                                                                                                                    jonathan parker's bartleby should have been the be-all-end-all of the modern-office anomie films .  negative          0  test       -0.848369\n",
       "760                                                                                                    offers very little genuine romance and even fewer laughs . . . a sad sitcom of a movie , largely devoid of charm .  negative          0  test       -0.826322\n",
       "577                                                                        it comes off as so silly that you wouldn't be surprised if ba , murdock and rest of the a-team were seen giving chase in a black and red van .  negative          0  test       -0.825595\n",
       "782                                                                                                                                   i kept thinking over and over again , 'i should be enjoying this . ' but i wasn't .  negative          0  test       -0.824251"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_test_df[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By varying the threshold of the classifier we can alter the precision and recall of a trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:03:57.432781Z",
     "start_time": "2025-03-18T18:03:57.329082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics with threshold=-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.11      0.20       503\n",
      "    positive       0.56      1.00      0.72       564\n",
      "\n",
      "    accuracy                           0.58      1067\n",
      "   macro avg       0.78      0.55      0.46      1067\n",
      "weighted avg       0.77      0.58      0.47      1067\n",
      "\n",
      "\n",
      "Metrics with threshold=-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.37      0.53       503\n",
      "    positive       0.64      0.98      0.77       564\n",
      "\n",
      "    accuracy                           0.69      1067\n",
      "   macro avg       0.78      0.67      0.65      1067\n",
      "weighted avg       0.77      0.69      0.66      1067\n",
      "\n",
      "\n",
      "Metrics with threshold=0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.79      0.79       503\n",
      "    positive       0.81      0.82      0.82       564\n",
      "\n",
      "    accuracy                           0.81      1067\n",
      "   macro avg       0.80      0.80      0.80      1067\n",
      "weighted avg       0.80      0.81      0.80      1067\n",
      "\n",
      "\n",
      "Metrics with threshold=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.97      0.74       503\n",
      "    positive       0.94      0.43      0.59       564\n",
      "\n",
      "    accuracy                           0.68      1067\n",
      "   macro avg       0.77      0.70      0.66      1067\n",
      "weighted avg       0.78      0.68      0.66      1067\n",
      "\n",
      "\n",
      "Metrics with threshold=2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      1.00      0.66       503\n",
      "    positive       0.98      0.10      0.18       564\n",
      "\n",
      "    accuracy                           0.52      1067\n",
      "   macro avg       0.74      0.55      0.42      1067\n",
      "weighted avg       0.75      0.52      0.41      1067\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the scores are computed once the model is fit\n",
    "test_scores = sgd_best.decision_function(mr_test_df.text)\n",
    "\n",
    "# and afterwards we can alter the threshold\n",
    "for threshold in [-2, -1, 0, 1, 2]:\n",
    "    print(\"Metrics with threshold={}\".format(threshold))\n",
    "    print(classification_report(mr_test_df.label_int, \n",
    "                               [1 if s>threshold else 0 for s in test_scores], \n",
    "                               target_names=['negative', 'positive']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` has a nice function that computes a curve of precision-recall-threshold values ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:04:00.112293Z",
     "start_time": "2025-03-18T18:04:00.061470Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_sgd_best = sklearn.metrics.precision_recall_curve(mr_test_df.label_int, \n",
    "                                                     sgd_best.decision_function(mr_test_df.text), \n",
    "                                                     pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:04:01.664616Z",
     "start_time": "2025-03-18T18:04:01.635184Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_sgd_uni = sklearn.metrics.precision_recall_curve(mr_test_df.label_int, \n",
    "                                                    mr_sgd.decision_function(mr_test_df.text), \n",
    "                                                    pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:04:04.468163Z",
     "start_time": "2025-03-18T18:04:03.015149Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T18:04:07.315323Z",
     "start_time": "2025-03-18T18:04:06.938810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x137e24050>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "plt.scatter(y=pr_sgd_best[0], x=pr_sgd_best[1], label='ngrams')\n",
    "plt.scatter(y=pr_sgd_uni[0], x=pr_sgd_uni[1], label='unigrams')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"ag_news_train.csv\" and \"ag_news_test.csv\" files on the NLP Lab Folder. Each text in the collection is labeled with one of four classes: \"science\", \"sports\", \"world\", \"business\". There's roughly 110K training examples and 10K test examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Training set shape: (109999, 7)\n",
      "Test set shape: (10000, 7)\n",
      "\n",
      "Sample training data:\n",
      "                                                                                                                                                                                                                                           text     label  label_int  science_int  sports_int  world_int  \\\n",
      "0                           John Souza, a volunteer with the Boone County chapter of the American Red Cross, is the second Columbia resident to join efforts to assist people who were affected by Tropical Storm Bonnie and Hurricane Charley.  Business          3            0           0          0   \n",
      "1        Spain needs only to beat an under-strength French team to secure its place in the Davis Cup tennis final, while Britain looks to the experience of Tim Henman and Greg Rusedski in its World Group play-off with Austria this weekend.    Sports          1            0           1          0   \n",
      "2                                           PANAMA CITY, Panama -- When the United States gave Panama control over its canal, many observers predicted that the international waterway would be plagued by problems at best and chaos at worst.     World          2            0           0          1   \n",
      "3                                                                                                            Gilbert Arenas, Jarvis Hayes and Anthony Peeler return from minor injuries to play in the Wizards' 97-85 victory over the Bobcats.    Sports          1            0           1          0   \n",
      "4  MEMPHIS, Tenn. -- Kobe Bryant had his worst shooting night of the season Wednesday in the Lakers #39; 110-87 loss to the Grizzlies, and worse yet, he needed nearly 45 minutes of postgame treatment for plantar fasciitis in his left foot.    Sports          1            0           1          0   \n",
      "\n",
      "   business_int  \n",
      "0             1  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n",
      "\n",
      "Verifying science_int column...\n",
      "Science class distribution in training set: science_int\n",
      "0    82537\n",
      "1    27462\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib\n",
    "\n",
    "# Determine if running in IPython/Jupyter\n",
    "is_jupyter = False\n",
    "try:\n",
    "    # This will raise an exception if not in IPython\n",
    "    ipy_str = str(type(get_ipython()))\n",
    "    if 'zmqshell' in ipy_str:\n",
    "        is_jupyter = True\n",
    "        # In a Jupyter notebook, use interactive matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    else:\n",
    "        # Use non-interactive backend for IPython but not notebook\n",
    "        matplotlib.use('Agg')\n",
    "        import matplotlib.pyplot as plt\n",
    "except:\n",
    "    # Use non-interactive backend for standard python\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "agnews_train_df = pd.read_csv('../data/agnews_train.csv')\n",
    "agnews_test_df = pd.read_csv('../data/agnews_test.csv')\n",
    "\n",
    "print(f\"Training set shape: {agnews_train_df.shape}\")\n",
    "print(f\"Test set shape: {agnews_test_df.shape}\")\n",
    "\n",
    "# Check a few samples\n",
    "print(\"\\nSample training data:\")\n",
    "print(agnews_train_df.head())\n",
    "\n",
    "# Verify science_int column exists\n",
    "print(\"\\nVerifying science_int column...\")\n",
    "if 'science_int' not in agnews_train_df.columns:\n",
    "    print(\"Error: science_int column not found!\")\n",
    "else:\n",
    "    print(f\"Science class distribution in training set: {agnews_train_df['science_int'].value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Science class distribution in training: science_int\n",
      "0    82537\n",
      "1    27462\n",
      "Name: count, dtype: int64\n",
      "Science class distribution in testing: science_int\n",
      "0    7463\n",
      "1    2537\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Learning Curve Experiment ===\n",
      "Training set sizes to evaluate: [500, 1000, 2000, 4000, 8000, 16000, 32000, 64000, 109999]\n",
      "\n",
      "--- Training with 500 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.580797                1\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.573099                2\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.568390                3\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.552320                4\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.533050                5\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.514355                6\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.477124                7\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.452926                8\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.369186                9\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.228432               10\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.217062               11\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.096825               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}\n",
      "Best F1 score: 0.5808\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.84      0.95      0.90      7463\n",
      "     Science       0.78      0.48      0.59      2537\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.81      0.72      0.74     10000\n",
      "weighted avg       0.83      0.83      0.82     10000\n",
      "\n",
      "F1 Score: 0.5938\n",
      "\n",
      "--- Training with 1000 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.688844                1\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.684043                2\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.681208                3\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.676722                4\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.671695                5\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.667920                6\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.644400                7\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.643366                8\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.620780                9\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.611066               10\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.601580               11\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.540745               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}\n",
      "Best F1 score: 0.6888\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.87      0.95      0.91      7463\n",
      "     Science       0.81      0.59      0.68      2537\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.84      0.77      0.80     10000\n",
      "weighted avg       0.86      0.86      0.85     10000\n",
      "\n",
      "F1 Score: 0.6841\n",
      "\n",
      "--- Training with 2000 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.740156                1\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.737747                2\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.735374                3\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.731548                4\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.730671                5\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.729605                6\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.727759                7\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.713396                8\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.711514                9\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.664207               10\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.543978               11\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.449834               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}\n",
      "Best F1 score: 0.7402\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.91      0.96      0.93      7463\n",
      "     Science       0.85      0.71      0.77      2537\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.88      0.83      0.85     10000\n",
      "weighted avg       0.89      0.90      0.89     10000\n",
      "\n",
      "F1 Score: 0.7740\n",
      "\n",
      "--- Training with 4000 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.798974                1\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.794646                2\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.791426                3\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.791011                4\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.790156                5\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.783335                6\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.781494                7\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.764017                8\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.758063                9\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.625829               10\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.389856               11\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.219202               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}\n",
      "Best F1 score: 0.7990\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.91      0.96      0.94      7463\n",
      "     Science       0.86      0.73      0.79      2537\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.89      0.85      0.86     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "F1 Score: 0.7910\n",
      "\n",
      "--- Training with 8000 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.810124                1\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.809800                2\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.806032                3\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.803379                4\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.800970                5\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.800844                6\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.798133                7\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.779805                8\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.769780                9\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.551203               10\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.232186               11\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.089359               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}\n",
      "Best F1 score: 0.8101\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.92      0.97      0.94      7463\n",
      "     Science       0.88      0.76      0.82      2537\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.90      0.86      0.88     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "F1 Score: 0.8188\n",
      "\n",
      "--- Training with 16000 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.845639                1\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.843347                2\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.840873                3\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.837758                4\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.834852                5\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.834706                6\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.831470                7\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.814235                8\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.801748                9\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.515938               10\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.136129               11\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.050035               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}\n",
      "Best F1 score: 0.8456\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.94      0.96      0.95      7463\n",
      "     Science       0.87      0.82      0.85      2537\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.91      0.89      0.90     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "F1 Score: 0.8454\n",
      "\n",
      "--- Training with 32000 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.857117                1\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.856813                2\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.854093                3\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.851176                4\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.838923                5\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.836306                6\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.829884                7\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.821496                8\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.812259                9\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.507135               10\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.097480               11\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.034278               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}\n",
      "Best F1 score: 0.8571\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.95      0.96      0.95      7463\n",
      "     Science       0.88      0.84      0.86      2537\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.91      0.90      0.91     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "F1 Score: 0.8618\n",
      "\n",
      "--- Training with 64000 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.873076                1\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.872096                2\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.869173                3\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.863522                4\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.862362                5\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.832998                6\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.830162                7\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.818315                8\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.797979                9\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.483079               10\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.068976               11\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.031082               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}\n",
      "Best F1 score: 0.8731\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.96      0.96      0.96      7463\n",
      "     Science       0.89      0.87      0.88      2537\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.93      0.92      0.92     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "F1 Score: 0.8840\n",
      "\n",
      "--- Training with 109999 examples ---\n",
      "Training SGD classifier with cross-validation (3 folds)...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Cross-validation results:\n",
      "   param_clf__alpha param_vect__ngram_range                                               params  mean_test_score  rank_test_score\n",
      "11          0.00001                  (1, 3)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}         0.882204                1\n",
      "10          0.00001                  (1, 2)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 2)}         0.882137                2\n",
      "14         0.000001                  (1, 3)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 3)}         0.879860                3\n",
      "13         0.000001                  (1, 2)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 2)}         0.875141                4\n",
      "9           0.00001                  (1, 1)   {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 1)}         0.873135                5\n",
      "12         0.000001                  (1, 1)   {'clf__alpha': 1e-06, 'vect__ngram_range': (1, 1)}         0.846262                6\n",
      "6            0.0001                  (1, 1)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 1)}         0.834703                7\n",
      "7            0.0001                  (1, 2)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 2)}         0.809878                8\n",
      "8            0.0001                  (1, 3)  {'clf__alpha': 0.0001, 'vect__ngram_range': (1, 3)}         0.781384                9\n",
      "3             0.001                  (1, 1)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 1)}         0.472399               10\n",
      "4             0.001                  (1, 2)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 2)}         0.059353               11\n",
      "5             0.001                  (1, 3)   {'clf__alpha': 0.001, 'vect__ngram_range': (1, 3)}         0.027567               12\n",
      "0              0.01                  (1, 1)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}         0.000000               13\n",
      "1              0.01                  (1, 2)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}         0.000000               13\n",
      "2              0.01                  (1, 3)    {'clf__alpha': 0.01, 'vect__ngram_range': (1, 3)}         0.000000               13\n",
      "\n",
      "Best parameters: {'clf__alpha': 1e-05, 'vect__ngram_range': (1, 3)}\n",
      "Best F1 score: 0.8822\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Science       0.96      0.97      0.96      7463\n",
      "     Science       0.90      0.87      0.88      2537\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.93      0.92      0.92     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "F1 Score: 0.8840\n",
      "\n",
      "Results Summary:\n",
      "   train_size  f1_score  best_alpha best_ngram_range\n",
      "0         500  0.593842    0.000001           (1, 1)\n",
      "1        1000  0.684127    0.000010           (1, 1)\n",
      "2        2000  0.773971    0.000100           (1, 2)\n",
      "3        4000  0.790965    0.000010           (1, 2)\n",
      "4        8000  0.818798    0.000100           (1, 3)\n",
      "5       16000  0.845449    0.000010           (1, 3)\n",
      "6       32000  0.861812    0.000010           (1, 3)\n",
      "7       64000  0.883971    0.000010           (1, 3)\n",
      "8      109999  0.883991    0.000010           (1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/zn80hp1x1xq2fg_1g7n3nn880000gp/T/ipykernel_2744/2595450078.py:191: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROI Analysis Summary:\n",
      "Initial F1 score with 500 examples: 0.5938\n",
      "Final F1 score with 109999 examples: 0.8840\n",
      "Total improvement: 0.2901\n",
      "Total labeling cost: 1833.3 hours\n",
      "\n",
      "Recommended sweet spot: 2000 examples\n",
      "F1 score at sweet spot: 0.7740\n",
      "Labeling cost at sweet spot: 33.3 hours\n",
      "Additional improvement after sweet spot: 0.1100\n",
      "Additional cost after sweet spot: 1800.0 hours\n",
      "\n",
      "Experiment complete! Total time: 328.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/zn80hp1x1xq2fg_1g7n3nn880000gp/T/ipykernel_2744/2595450078.py:364: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Define helper function for cross-validation reporting\n",
    "def crossvalidation_report_df(grid_cv):\n",
    "    \"\"\"Creates a dataframe that reports the results of a cross-validation experiment.\n",
    "    \n",
    "    Args:\n",
    "        grid_cv: A fitted GridSearchCV object\n",
    "        \n",
    "    Returns:\n",
    "        A pandas DataFrame, sorted by rank of experiment\n",
    "    \"\"\"\n",
    "    # Select columns that define each experiment and results\n",
    "    cols = [c for c in grid_cv.cv_results_ if (c.startswith('param') or \n",
    "                                               c in ['mean_test_score', 'rank_test_score'])]\n",
    "\n",
    "    # Sort by rank and select columns\n",
    "    return pd.DataFrame(grid_cv.cv_results_).sort_values(by='rank_test_score')[cols]\n",
    "\n",
    "# Define function to train SGD classifier with cross-validation\n",
    "def train_sgd_classifier(X_train, y_train, cv=5):\n",
    "    \"\"\"Trains an SGD classifier with cross-validation to find optimal hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features (text)\n",
    "        y_train: Training labels\n",
    "        cv: Number of cross-validation folds\n",
    "        \n",
    "    Returns:\n",
    "        The best model after cross-validation\n",
    "    \"\"\"\n",
    "    print(f\"Training SGD classifier with cross-validation ({cv} folds)...\")\n",
    "    \n",
    "    # Define the pipeline\n",
    "    sgd_pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty='l2', random_state=42, max_iter=1000, tol=1e-3)),\n",
    "    ])\n",
    "    \n",
    "    # Define hyperparameter grid\n",
    "    param_grid = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],  # Unigrams, bigrams, trigrams\n",
    "        'clf__alpha': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],   # Regularization strength\n",
    "    }\n",
    "    \n",
    "    # Create and fit GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        sgd_pipeline, \n",
    "        param_grid, \n",
    "        cv=cv, \n",
    "        scoring='f1',\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Report results\n",
    "    print(\"\\nCross-validation results:\")\n",
    "    cv_results = crossvalidation_report_df(grid_search)\n",
    "    print(cv_results)\n",
    "    \n",
    "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best F1 score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "# Function to evaluate model on test set\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluates a trained model on test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained classifier\n",
    "        X_test: Test features\n",
    "        y_test: Test labels\n",
    "        \n",
    "    Returns:\n",
    "        F1 score on test set\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Not Science', 'Science']))\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Function to perform learning curve experiment with different training set sizes\n",
    "def learning_curve_experiment(X_train, y_train, X_test, y_test, cv=5):\n",
    "    \"\"\"Trains models with increasing training set sizes to analyze learning curve.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Full training features\n",
    "        y_train: Full training labels\n",
    "        X_test: Test features\n",
    "        y_test: Test labels\n",
    "        cv: Number of cross-validation folds\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Learning Curve Experiment ===\")\n",
    "    \n",
    "    # Determine number of examples to start with and how many steps to take\n",
    "    start_size = min(500, len(X_train) // 4)  # Start with 500 examples or 1/4 of dataset if smaller\n",
    "    sizes = []\n",
    "    current_size = start_size\n",
    "    \n",
    "    while current_size <= len(X_train):\n",
    "        sizes.append(current_size)\n",
    "        current_size *= 2  # Double the size each time\n",
    "    \n",
    "    # If the last size isn't the full dataset, add it\n",
    "    if sizes[-1] < len(X_train):\n",
    "        sizes.append(len(X_train))\n",
    "    \n",
    "    # Only keep sizes that are <= total dataset size\n",
    "    sizes = [s for s in sizes if s <= len(X_train)]\n",
    "    \n",
    "    # Make sure we have at least one size\n",
    "    if not sizes:\n",
    "        sizes = [len(X_train)]\n",
    "    \n",
    "    print(f\"Training set sizes to evaluate: {sizes}\")\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = {\n",
    "        'train_size': [],\n",
    "        'f1_score': [],\n",
    "        'best_alpha': [],\n",
    "        'best_ngram_range': []\n",
    "    }\n",
    "    \n",
    "    # For each training set size\n",
    "    for size in sizes:\n",
    "        print(f\"\\n--- Training with {size} examples ---\")\n",
    "        \n",
    "        # Sample the training set\n",
    "        indices = np.random.choice(len(X_train), size=size, replace=False)\n",
    "        X_sample = X_train.iloc[indices]\n",
    "        y_sample = y_train.iloc[indices]\n",
    "        \n",
    "        # Train model with cross-validation\n",
    "        model, best_params, best_score = train_sgd_classifier(X_sample, y_sample, cv=cv)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        print(f\"\\nEvaluating on test set...\")\n",
    "        f1 = evaluate_model(model, X_test, y_test)\n",
    "        \n",
    "        # Store results\n",
    "        results['train_size'].append(size)\n",
    "        results['f1_score'].append(f1)\n",
    "        results['best_alpha'].append(best_params['clf__alpha'])\n",
    "        results['best_ngram_range'].append(str(best_params['vect__ngram_range']))\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(results_df)\n",
    "    \n",
    "    # Plot learning curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df['train_size'], results_df['f1_score'], marker='o')\n",
    "    plt.xscale('log')  # Log scale for x-axis since we're doubling\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Learning Curve: F1 Score vs Training Set Size')\n",
    "    \n",
    "    # Add best hyperparameters as annotations\n",
    "    for i, (size, f1, alpha, ngram) in enumerate(zip(\n",
    "        results_df['train_size'], \n",
    "        results_df['f1_score'],\n",
    "        results_df['best_alpha'],\n",
    "        results_df['best_ngram_range']\n",
    "    )):\n",
    "        plt.annotate(\n",
    "            f\"Î±={alpha}, ngram={ngram}\", \n",
    "            (size, f1),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(0,10), \n",
    "            ha='center'\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('agnews_science_learning_curve.png')\n",
    "    \n",
    "    # Determine if we're in a Jupyter notebook\n",
    "    try:\n",
    "        ipy_str = str(type(get_ipython()))\n",
    "        if 'zmqshell' in ipy_str:\n",
    "            # We're in a Jupyter notebook, display the plot\n",
    "            plt.show()\n",
    "    except:\n",
    "        # We're not in a Jupyter notebook\n",
    "        pass\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def analyze_roi(learning_curve_results, labeling_time_per_example=1.0):\n",
    "    \"\"\"Analyzes the return on investment (ROI) for adding more training examples.\n",
    "    \n",
    "    Args:\n",
    "        learning_curve_results: DataFrame with learning curve experiment results\n",
    "        labeling_time_per_example: Time in minutes it takes to label one example\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with ROI analysis\n",
    "    \"\"\"\n",
    "    results = learning_curve_results.copy()\n",
    "    \n",
    "    # Calculate the labeling cost in minutes\n",
    "    results['labeling_cost_minutes'] = results['train_size'] * labeling_time_per_example\n",
    "    \n",
    "    # Calculate the labeling cost in hours\n",
    "    results['labeling_cost_hours'] = results['labeling_cost_minutes'] / 60.0\n",
    "    \n",
    "    # Calculate the absolute improvement in F1 score from previous size\n",
    "    results['f1_improvement'] = results['f1_score'].diff()\n",
    "    results.loc[0, 'f1_improvement'] = results.loc[0, 'f1_score']  # Set first improvement\n",
    "    \n",
    "    # Calculate the cost of each improvement in hours per 0.01 F1 gain\n",
    "    results['hours_per_0.01_f1_gain'] = float('nan')  # Initialize with NaN\n",
    "    for i in range(1, len(results)):\n",
    "        if results.loc[i, 'f1_improvement'] > 0:\n",
    "            additional_hours = results.loc[i, 'labeling_cost_hours'] - results.loc[i-1, 'labeling_cost_hours']\n",
    "            f1_gain = results.loc[i, 'f1_improvement']\n",
    "            # Cost in hours to achieve a 0.01 gain in F1\n",
    "            results.loc[i, 'hours_per_0.01_f1_gain'] = (additional_hours / f1_gain) * 0.01\n",
    "    \n",
    "    # Calculate the rate of improvement (first derivative)\n",
    "    results['improvement_rate'] = float('nan')  # Initialize with NaN\n",
    "    for i in range(1, len(results)):\n",
    "        additional_examples = results.loc[i, 'train_size'] - results.loc[i-1, 'train_size']\n",
    "        f1_diff = results.loc[i, 'f1_score'] - results.loc[i-1, 'f1_score']\n",
    "        # We multiply by 1000 to make the number more readable\n",
    "        results.loc[i, 'improvement_rate'] = (f1_diff / additional_examples) * 1000\n",
    "    \n",
    "    # Calculate the second derivative to identify diminishing returns\n",
    "    results['improvement_acceleration'] = results['improvement_rate'].diff()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to visualize the ROI analysis\n",
    "def visualize_roi(roi_results):\n",
    "    \"\"\"Creates visualizations for ROI analysis.\n",
    "    \n",
    "    Args:\n",
    "        roi_results: DataFrame with ROI analysis\n",
    "    \"\"\"\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Learning curve with sweet spot annotation\n",
    "    axs[0, 0].plot(roi_results['train_size'], roi_results['f1_score'], marker='o')\n",
    "    axs[0, 0].set_xscale('log')\n",
    "    axs[0, 0].grid(True, which=\"both\", ls=\"--\")\n",
    "    axs[0, 0].set_xlabel('Training Set Size')\n",
    "    axs[0, 0].set_ylabel('F1 Score')\n",
    "    axs[0, 0].set_title('Learning Curve: F1 Score vs Training Size')\n",
    "    \n",
    "    # Find the \"sweet spot\" (where diminishing returns really kick in)\n",
    "    # This is a heuristic - we look for where the improvement rate drops significantly\n",
    "    # or the cost per improvement increases dramatically\n",
    "    sweet_spot_idx = None\n",
    "    \n",
    "    # If we have enough data points, find where the improvement rate drops below a threshold\n",
    "    if len(roi_results) > 2:\n",
    "        # First, try to find where the improvement rate drops significantly\n",
    "        improvement_rates = roi_results['improvement_rate'].dropna()\n",
    "        if not improvement_rates.empty:\n",
    "            # Find index where improvement rate drops to less than 25% of the maximum rate\n",
    "            max_rate = improvement_rates.iloc[0]  # Usually the first jump is largest\n",
    "            threshold = max_rate * 0.25\n",
    "            below_threshold = improvement_rates[improvement_rates < threshold]\n",
    "            if not below_threshold.empty:\n",
    "                sweet_spot_idx = below_threshold.index[0] - 1  # The point just before diminishing returns\n",
    "        \n",
    "        # If the above method doesn't find a sweet spot, try another approach\n",
    "        if sweet_spot_idx is None or sweet_spot_idx < 1:\n",
    "            # Look at cost per improvement\n",
    "            costs = roi_results['hours_per_0.01_f1_gain'].dropna()\n",
    "            if not costs.empty and len(costs) > 2:\n",
    "                # Find where cost increases dramatically (> 3x the minimum cost)\n",
    "                min_cost = costs.min()\n",
    "                high_cost_idx = costs[costs > min_cost * 3].index\n",
    "                if not high_cost_idx.empty:\n",
    "                    sweet_spot_idx = high_cost_idx[0] - 1  # The point just before high cost\n",
    "    \n",
    "    # If we found a sweet spot, annotate it\n",
    "    if sweet_spot_idx is not None and sweet_spot_idx > 0 and sweet_spot_idx < len(roi_results):\n",
    "        sweet_spot_size = roi_results.loc[sweet_spot_idx, 'train_size']\n",
    "        sweet_spot_f1 = roi_results.loc[sweet_spot_idx, 'f1_score']\n",
    "        axs[0, 0].scatter([sweet_spot_size], [sweet_spot_f1], color='red', s=100, zorder=10)\n",
    "        axs[0, 0].annotate(\n",
    "            f\"Sweet spot: {sweet_spot_size} examples\\nF1={sweet_spot_f1:.4f}\",\n",
    "            (sweet_spot_size, sweet_spot_f1),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(10, -20),\n",
    "            ha='left',\n",
    "            arrowprops=dict(arrowstyle=\"->\", color='red')\n",
    "        )\n",
    "    \n",
    "    # 2. Cost vs Performance plot\n",
    "    axs[0, 1].plot(roi_results['labeling_cost_hours'], roi_results['f1_score'], marker='o')\n",
    "    axs[0, 1].grid(True)\n",
    "    axs[0, 1].set_xlabel('Labeling Cost (hours)')\n",
    "    axs[0, 1].set_ylabel('F1 Score')\n",
    "    axs[0, 1].set_title('F1 Score vs Labeling Cost')\n",
    "    \n",
    "    # Add annotations for each point\n",
    "    for i, row in roi_results.iterrows():\n",
    "        axs[0, 1].annotate(\n",
    "            f\"{int(row['train_size'])}\",\n",
    "            (row['labeling_cost_hours'], row['f1_score']),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(0, 7),\n",
    "            ha='center'\n",
    "        )\n",
    "    \n",
    "    # 3. Improvement rate plot (first derivative)\n",
    "    improvement_rates = roi_results['improvement_rate'].dropna()\n",
    "    if not improvement_rates.empty:\n",
    "        sizes = roi_results.loc[improvement_rates.index, 'train_size']\n",
    "        axs[1, 0].plot(sizes, improvement_rates, marker='o')\n",
    "        axs[1, 0].set_xscale('log')\n",
    "        axs[1, 0].grid(True)\n",
    "        axs[1, 0].set_xlabel('Training Set Size')\n",
    "        axs[1, 0].set_ylabel('Improvement Rate (F1 gain per 1000 examples)')\n",
    "        axs[1, 0].set_title('Rate of Improvement vs Training Size')\n",
    "    else:\n",
    "        axs[1, 0].text(0.5, 0.5, 'Not enough data points', ha='center', va='center')\n",
    "    \n",
    "    # 4. Cost per improvement plot\n",
    "    cost_per_improvement = roi_results['hours_per_0.01_f1_gain'].dropna()\n",
    "    if not cost_per_improvement.empty:\n",
    "        sizes = roi_results.loc[cost_per_improvement.index, 'train_size']\n",
    "        axs[1, 1].plot(sizes, cost_per_improvement, marker='o')\n",
    "        axs[1, 1].set_xscale('log')\n",
    "        axs[1, 1].grid(True)\n",
    "        axs[1, 1].set_xlabel('Training Set Size')\n",
    "        axs[1, 1].set_ylabel('Hours needed per 0.01 F1 gain')\n",
    "        axs[1, 1].set_title('Cost of Improvement vs Training Size')\n",
    "        \n",
    "        # Add data labels\n",
    "        for i, (size, cost) in enumerate(zip(sizes, cost_per_improvement)):\n",
    "            if pd.notna(cost):  # Only label non-NaN values\n",
    "                axs[1, 1].annotate(\n",
    "                    f\"{cost:.1f}h\",\n",
    "                    (size, cost),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(0, 7),\n",
    "                    ha='center'\n",
    "                )\n",
    "    else:\n",
    "        axs[1, 1].text(0.5, 0.5, 'Not enough data points', ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('agnews_science_roi_analysis.png')\n",
    "    \n",
    "    # Determine if we're in a Jupyter notebook\n",
    "    try:\n",
    "        ipy_str = str(type(get_ipython()))\n",
    "        if 'zmqshell' in ipy_str:\n",
    "            # We're in a Jupyter notebook, display the plot\n",
    "            plt.show()\n",
    "    except:\n",
    "        # We're not in a Jupyter notebook\n",
    "        pass\n",
    "    \n",
    "    # Print a summary of the ROI analysis\n",
    "    print(\"\\nROI Analysis Summary:\")\n",
    "    print(f\"Initial F1 score with {roi_results['train_size'].iloc[0]} examples: {roi_results['f1_score'].iloc[0]:.4f}\")\n",
    "    print(f\"Final F1 score with {roi_results['train_size'].iloc[-1]} examples: {roi_results['f1_score'].iloc[-1]:.4f}\")\n",
    "    print(f\"Total improvement: {roi_results['f1_score'].iloc[-1] - roi_results['f1_score'].iloc[0]:.4f}\")\n",
    "    print(f\"Total labeling cost: {roi_results['labeling_cost_hours'].iloc[-1]:.1f} hours\")\n",
    "    \n",
    "    if sweet_spot_idx is not None and sweet_spot_idx > 0 and sweet_spot_idx < len(roi_results):\n",
    "        sweet_spot_size = roi_results.loc[sweet_spot_idx, 'train_size']\n",
    "        sweet_spot_f1 = roi_results.loc[sweet_spot_idx, 'f1_score']\n",
    "        sweet_spot_cost = roi_results.loc[sweet_spot_idx, 'labeling_cost_hours']\n",
    "        print(f\"\\nRecommended sweet spot: {sweet_spot_size} examples\")\n",
    "        print(f\"F1 score at sweet spot: {sweet_spot_f1:.4f}\")\n",
    "        print(f\"Labeling cost at sweet spot: {sweet_spot_cost:.1f} hours\")\n",
    "        print(f\"Additional improvement after sweet spot: {roi_results['f1_score'].iloc[-1] - sweet_spot_f1:.4f}\")\n",
    "        print(f\"Additional cost after sweet spot: {roi_results['labeling_cost_hours'].iloc[-1] - sweet_spot_cost:.1f} hours\")\n",
    "\n",
    "# Modified function to run the experiment with ROI analysis\n",
    "def run_experiment(sample_size=0, cv_folds=3, labeling_time_per_example=1.0):\n",
    "    \"\"\"Run the AG News science classification experiment.\n",
    "    \n",
    "    Args:\n",
    "        sample_size: Number of training examples to use (0 for full dataset)\n",
    "        cv_folds: Number of cross-validation folds\n",
    "        labeling_time_per_example: Time in minutes it takes to label one example\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    start_time = time()\n",
    "    \n",
    "    # Load datasets if not already loaded\n",
    "    if 'agnews_train_df' not in globals():\n",
    "        print(\"Loading datasets...\")\n",
    "        global agnews_train_df, agnews_test_df\n",
    "        agnews_train_df = pd.read_csv('../data/agnews_train.csv')\n",
    "        agnews_test_df = pd.read_csv('../data/agnews_test.csv')\n",
    "        \n",
    "        print(f\"Training set shape: {agnews_train_df.shape}\")\n",
    "        print(f\"Test set shape: {agnews_test_df.shape}\")\n",
    "        \n",
    "        # Check a few samples\n",
    "        print(\"\\nSample training data:\")\n",
    "        print(agnews_train_df.head())\n",
    "        \n",
    "        # Verify science_int column exists\n",
    "        print(\"\\nVerifying science_int column...\")\n",
    "        if 'science_int' not in agnews_train_df.columns:\n",
    "            print(\"Error: science_int column not found!\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Science class distribution in training set: {agnews_train_df['science_int'].value_counts()}\")\n",
    "    \n",
    "    # Focus on science classification\n",
    "    X_train = agnews_train_df['text']\n",
    "    y_train = agnews_train_df['science_int']\n",
    "    X_test = agnews_test_df['text']\n",
    "    y_test = agnews_test_df['science_int']\n",
    "    \n",
    "    # Use a sample if requested\n",
    "    if sample_size > 0:\n",
    "        print(f\"\\nUsing a sample of {sample_size} training examples for quick testing\")\n",
    "        # Sample while maintaining class distribution\n",
    "        train_indices = np.random.choice(len(X_train), size=min(sample_size, len(X_train)), replace=False)\n",
    "        X_train = X_train.iloc[train_indices]\n",
    "        y_train = y_train.iloc[train_indices]\n",
    "        \n",
    "        test_indices = np.random.choice(len(X_test), size=min(sample_size//10, len(X_test)), replace=False)\n",
    "        X_test = X_test.iloc[test_indices]\n",
    "        y_test = y_test.iloc[test_indices]\n",
    "    \n",
    "    print(f\"\\nScience class distribution in training: {y_train.value_counts()}\")\n",
    "    print(f\"Science class distribution in testing: {y_test.value_counts()}\")\n",
    "    \n",
    "    # Run learning curve experiment\n",
    "    results = learning_curve_experiment(X_train, y_train, X_test, y_test, cv=cv_folds)\n",
    "    \n",
    "    # Perform ROI analysis\n",
    "    roi_results = analyze_roi(results, labeling_time_per_example)\n",
    "    \n",
    "    # Visualize the ROI analysis\n",
    "    visualize_roi(roi_results)\n",
    "    \n",
    "    elapsed_time = time() - start_time\n",
    "    print(f\"\\nExperiment complete! Total time: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return roi_results\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Default parameters\n",
    "    sample_size = 0  # 0 means use full dataset\n",
    "    cv_folds = 3\n",
    "    \n",
    "    # Parse command line args only if not in Jupyter\n",
    "    if not is_jupyter:\n",
    "        import argparse\n",
    "        parser = argparse.ArgumentParser(description='AG News Science Classification')\n",
    "        parser.add_argument('--sample', type=int, default=0, \n",
    "                          help='Use a small sample of the dataset for faster testing (0 for full dataset)')\n",
    "        parser.add_argument('--cv', type=int, default=3,\n",
    "                          help='Number of cross-validation folds')\n",
    "        parser.add_argument('--labeling-time', type=float, default=1.0,\n",
    "                          help='Time in minutes it takes to label one example')\n",
    "        \n",
    "        # Only parse known args to avoid conflicts\n",
    "        args, unknown = parser.parse_known_args()\n",
    "        sample_size = args.sample\n",
    "        cv_folds = args.cv\n",
    "        labeling_time = args.labeling_time\n",
    "    else:\n",
    "        labeling_time = 1.0  # Default labeling time\n",
    "    \n",
    "    # Run the experiment with the configured parameters\n",
    "    results = run_experiment(sample_size=sample_size, cv_folds=cv_folds, labeling_time_per_example=labeling_time)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
