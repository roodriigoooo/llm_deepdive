{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:20.003290Z",
     "start_time": "2025-06-24T08:59:19.998880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import tiktoken\n",
    "\n",
    "project_root = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), os.pardir, os.pardir)\n",
    ")\n",
    "\n",
    "stage1_root = os.path.join(project_root, \"stage1\")\n",
    "sys.path.insert(0, stage1_root)\n",
    "\n",
    "# now 'src' is a top-level package\n",
    "from src.gpt2small import GPTModel, GPTConfig124, generate_text\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:21.340587Z",
     "start_time": "2025-06-24T08:59:20.052275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cfg_pt = GPTConfig124(vocab_size=50257, context_length=256, emb_dim=768,\n",
    "                   n_heads=12, n_layers=12, dropout=0.1, qkv_bias=False)\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(cfg_pt)\n",
    "model.eval()"
   ],
   "id": "6aee549c14b1461",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_form): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:21.822407Z",
     "start_time": "2025-06-24T08:59:21.368897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_token_ids(text, tokenizer, allowed_special):\n",
    "    \"\"\"\n",
    "    tensor.unsqueeze(dim) inserts a new axis (of size 1) at index dim.\n",
    "    x = torch.tensor([10, 20, 30])       shape: [3]\n",
    "    x0 = x.unsqueeze(0)                 shape: [1,3]\n",
    "    x1 = x.unsqueeze(1)                 shape: [3,1]\n",
    "    \"\"\"\n",
    "    allowed_special = allowed_special or ('<|endoftext|>')\n",
    "    token_list = tokenizer.encode(text, allowed_special=set(allowed_special))\n",
    "    ids = torch.tensor(token_list).unsqueeze(0)\n",
    "    #unsqueeze turns a 1D sequence of token IDs into a 2D batch of size 1.\n",
    "    #almost all pytorch nn.Modules (embeddings, transformers, etc.)\n",
    "    # expect inputs of shape (batch_size, seq_len, ...)\n",
    "    # even f we only have one example, we need to present it as a batch of size 1.\n",
    "    return ids\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    \"\"\"\n",
    "    tensor.squeeze(dim: optional) removes the axis at index dim if its size is 1.\n",
    "    y = torch.zeros(1, 5, 1)         shape: [1,5,1]\n",
    "    y0 = y.squeeze(0)               shape: [5,1]\n",
    "    y1 = y.squeeze(2)               shape: [1,5]\n",
    "    y2 = y.squeeze()               shape: [5] (all dims 1 are removed)\n",
    "    \"\"\"\n",
    "    flat = token_ids.squeeze(0)\n",
    "    #squeeze(0) just undoes the batch dimension we previously added,\n",
    "    # giving back the raw token sequence.\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "st_context = \"A man told me\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(st_context, tokenizer, allowed_special=None),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = cfg_pt.context_length\n",
    ")\n",
    "\n",
    "print('Output text: ', token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "7adedf932d6266c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:  A man told me accumulation thumbnail Flask 406 propensity Hat lush Tulsolk se\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Generation Loss\n",
    "\n",
    "As can be seen from the output above, our model is producing random, non-coherent text. This is because it has not yet undergone training (and because the input size is very limited). Training is done in order to increase the softmax probability of the index positions that correspond to the correct target token position. A non-trained model will simply return the argmax of a rather arbitrary softmax distribution (random vectors) across the vocab size, for each token. The goal with training is then to maximize the chance of selecting the correct token by increasing its selection probability relative to other tokens."
   ],
   "id": "3ebb7da82c95a3da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:21.918077Z",
     "start_time": "2025-06-24T08:59:21.857665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"A man told me once that all the bad people\n",
    "Were needed. Maybe not all, but your fingernails\n",
    "You need; they are really claws, and we know\n",
    "Claws. The sharks--what about them?\n",
    "They make other fish swim faster. The hard-faced men\n",
    "In black coats who chase you for hours\n",
    "In dreams--that's the only way to get you\n",
    "To the shore. Sometimes those hard women\n",
    "Who abandon you get you to say, \"You.\"\n",
    "A lazy part of us is like a tumbleweed.\n",
    "It doesn't move on its own. It takes sometimes\n",
    "A lot of Depression to get tumbleweeds moving.\n",
    "Then they blow across three or four States.\n",
    "This man told me that things work together.\n",
    "Bad handwriting sometimes leads to new ideas;\n",
    "And a careless God--who refuses to let you\n",
    "Eat from the Tree of Knowledge--can lead\n",
    "To books, and eventually to us. We write\n",
    "Poems with lies in them, but they help a little.\"\"\"\n",
    "\n",
    "tokens = text_to_token_ids(text, tokenizer, allowed_special=None)\n",
    "print(f'Shape of tokens: {tokens.shape}')\n",
    "print(f'Tokens:\\n {tokens}')\n",
    "\n",
    "B, T = 2, 4 #(batch_size, seq_len)\n",
    "data = tokens[0][:8+1]\n",
    "\n",
    "x = data[:-1].view(B,T) #input tensor\n",
    "y = data[1:].view(B,T) #target tensor for next token prediction\n",
    "\n",
    "print(f'Inputs:\\n {x}')\n",
    "print(f'Targets:\\n {y}')\n",
    "\n",
    "with torch.no_grad(): #we are not training yet, just an example\n",
    "    logits = model(x)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n"
   ],
   "id": "f5cd7dd14853827f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tokens: torch.Size([1, 212])\n",
      "Tokens:\n",
      " tensor([[   32,   582,  1297,   502,  1752,   326,   477,   262,  2089,   661,\n",
      "           198, 35653,  2622,    13,  6674,   407,   477,    11,   475,   534,\n",
      "          8038,  1142,  1768,   198,  1639,   761,    26,   484,   389,  1107,\n",
      "         28421,    11,   290,   356,   760,   198,  2601,  8356,    13,   383,\n",
      "         27476,   438, 10919,   546,   606,    30,   198,  2990,   787,   584,\n",
      "          5916,  9422,  5443,    13,   383,  1327,    12, 24903,  1450,   198,\n",
      "           818,  2042, 30720,   508, 15505,   345,   329,  2250,   198,   818,\n",
      "         10625,   438,  5562,   338,   262,   691,   835,   284,   651,   345,\n",
      "           198,  2514,   262, 15191,    13,  8975,   883,  1327,  1466,   198,\n",
      "          8241,  6871,   345,   651,   345,   284,   910,    11,   366,  1639,\n",
      "           526,   198,    32, 16931,   636,   286,   514,   318,   588,   257,\n",
      "         47978, 39054,    13,   198,  1026,  1595,   470,  1445,   319,   663,\n",
      "           898,    13,   632,  2753,  3360,   198,    32,  1256,   286, 22483,\n",
      "           284,   651, 47978,   732,  5379,  3867,    13,   198,  6423,   484,\n",
      "          6611,  1973,  1115,   393,  1440,  1829,    13,   198,  1212,   582,\n",
      "          1297,   502,   326,  1243,   670,  1978,    13,   198, 22069, 44396,\n",
      "          3360,  5983,   284,   649,  4213,    26,   198,  1870,   257, 36138,\n",
      "          1793,   438,  8727, 17567,   284,  1309,   345,   198, 47659,   422,\n",
      "           262, 12200,   286, 20414,   438,  5171,  1085,   198,  2514,  3835,\n",
      "            11,   290,  4191,   284,   514,    13,   775,  3551,   198, 18833,\n",
      "          5232,   351,  7363,   287,   606,    11,   475,   484,  1037,   257,\n",
      "          1310,    13]])\n",
      "Inputs:\n",
      " tensor([[  32,  582, 1297,  502],\n",
      "        [1752,  326,  477,  262]])\n",
      "Targets:\n",
      " tensor([[ 582, 1297,  502, 1752],\n",
      "        [ 326,  477,  262, 2089]])\n",
      "torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that the dimension of the probability tensor is [2, 4, 50257], the same as the logits output shape of our model (batch_size, seq_len, d_model).",
   "id": "96b993dceece8097"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:21.960450Z",
     "start_time": "2025-06-24T08:59:21.953068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(token_ids)"
   ],
   "id": "463a2df2778a4025",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[12434],\n",
      "         [22182],\n",
      "         [22418],\n",
      "         [24106]],\n",
      "\n",
      "        [[ 9099],\n",
      "         [30130],\n",
      "         [40937],\n",
      "         [34965]]])\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The output above yields two sets of outputs, one for each batch in the inputs. Each element in each set is the predicted token IDs of the next word, from each word. Perhaps this is better explained visually.",
   "id": "c675d8dfdc072456"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.018351Z",
     "start_time": "2025-06-24T08:59:22.010311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = token_ids.squeeze(-1)\n",
    "batch_size, seq_len = x.shape\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(seq_len):\n",
    "        inp_id = x[b,t].item()\n",
    "        pred_id = preds[b,t].item()\n",
    "\n",
    "        inp_tok = tokenizer.decode([inp_id])\n",
    "        pred_tok = tokenizer.decode([pred_id])\n",
    "\n",
    "        print(f\"'{inp_tok}' [{inp_id}] ---> '{pred_tok}' [{pred_id}]\")"
   ],
   "id": "3c49613868dca4ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A' [32] ---> ' Driver' [12434]\n",
      "' man' [582] ---> 'NP' [22182]\n",
      "' told' [1297] ---> ' Munich' [22418]\n",
      "' me' [502] ---> ' accumulation' [24106]\n",
      "' once' [1752] ---> 'don' [9099]\n",
      "' that' [326] ---> ' eagerly' [30130]\n",
      "' all' [477] ---> ' dogma' [40937]\n",
      "' the' [262] ---> ' ali' [34965]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.091245Z",
     "start_time": "2025-06-24T08:59:22.084896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Targets batch 1:\\n {token_ids_to_text(y[0], tokenizer)}')\n",
    "print(f'Outputs batch 1:\\n {token_ids_to_text(token_ids[0].flatten(), tokenizer)}')\n",
    "print(f'Targets batch 2: \\n {token_ids_to_text(y[1], tokenizer)}')\n",
    "print(f'Outputs batch 2:\\n {token_ids_to_text(token_ids[1].flatten(), tokenizer)}')"
   ],
   "id": "7966e6b75dfb0671",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:\n",
      "  man told me once\n",
      "Outputs batch 1:\n",
      "  DriverNP Munich accumulation\n",
      "Targets batch 2: \n",
      "  that all the bad\n",
      "Outputs batch 2:\n",
      " don eagerly dogma ali\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see, the model is producing very wrong, random texts that are vastly different from the target. We need to figure out a way to evaluate the performance of the model's generated text numerically through using some sort of loss metric. Using this loss, we can then implement a training function to robustly and iteratively update the model's weights and improve the generated text. But, in a context like language understanding and text generation, how do you build this loss? We want to measure how far, or how different the generated tokens are from the correct targets. But how do we embed this information in a function to optimize? How do you even begin to define inaccuracy or incorrectness in text generation, which might have no objectively correct next word?",
   "id": "23a583f93fa88df2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.135557Z",
     "start_time": "2025-06-24T08:59:22.126840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_1 = y[0].unsqueeze(1)\n",
    "y_2 = y[1].unsqueeze(1)# (T,1)\n",
    "target_probas_1 = probas[0].gather(dim=1, index=y_1).squeeze(1)\n",
    "target_probas_2 = probas[1].gather(dim=1, index=y_2).squeeze(1)\n",
    "print(f'The four target token ID probs for batch 1 are:\\n', target_probas_1)\n",
    "print(f'The four target token ID probs for batch 2 are:\\n', target_probas_2)"
   ],
   "id": "fa2ea6aa71da3915",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The four target token ID probs for batch 1 are:\n",
      " tensor([7.7823e-06, 1.6688e-05, 1.7775e-05, 1.2489e-05])\n",
      "The four target token ID probs for batch 2 are:\n",
      " tensor([1.1684e-05, 1.5996e-05, 8.7344e-06, 2.2723e-05])\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To summarize our process thus far:\n",
    "\n",
    "1. **Compute the raw mode outputs (logits).** These are the unnormalized scores that the GPT model assigns to every possible next token in its vocabulary. These reflect the model's relative confidence in each token before normalization.\n",
    "2. **Normalize via softmax to obtain a probability distribution.** We convert the raw scores into a proper probability distribution over all tokens.\n",
    "3. **Extract the probabilities of true next tokens.** For each position in every sequence of our batch, we index into the softmax output to retrieve the probability assigned to the actual (target) next token. This gives us a measure of how likely the model considers the correct continuation at each step.\n",
    "\n",
    "Next, we will calculate the loss for the probability scores (one possible method) of our two example sentences by applying the logarithm to the probability scores."
   ],
   "id": "e205dc74d39fa298"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.180850Z",
     "start_time": "2025-06-24T08:59:22.176260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_probas = torch.cat((target_probas_1, target_probas_2))\n",
    "log_probs = torch.log(target_probas)\n",
    "print(f'Log probs:\\n {log_probs}')"
   ],
   "id": "46718cfe3391927a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probs:\n",
      " tensor([-11.7637, -11.0008, -10.9377, -11.2907, -11.3573, -11.0432, -11.6482,\n",
      "        -10.6921])\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When we take the log of our model's predicted probabilities and use log-probabilities as the basis for our loss, we are constructing the (for relatively experienced readers) familiar negative-log-likelihood (or cross-entropy) objective that underpins many modern language models, and many other families of models as well. If our model assigns prob $p_{\\theta}(y_t | x_{\\lt t})$ to the correct next token $y_t$ given context $x_{\\lt t}$, then the joint likelihood of a full sequence $y_{1:T}$ is the product:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{t=1}^{T} p_{\\theta}(y_t | x_{\\lt t})\n",
    "$$\n",
    "\n",
    "and maximizing this product directly is equivalent to maximizing its logarithm (since log is a strictly increasing function:\n",
    "\n",
    "$$\n",
    "\\text{log}L(\\theta) = \\sum_{t=1}^{T} \\text{log}\\space p_{\\theta}(y_t | x_{\\lt t})\n",
    "$$\n",
    "\n",
    "So that minimizing $\\mathcal{L}$ is exactly the same as maximizing the original likelihood $L$, we define the loss as the negative of this log-likelihood. It is this loss that we want to bring down to zero:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -\\sum_{t=1}^{T} \\text{log}\\space p_{\\theta}(y_t | x_{\\lt t})\n",
    "$$\n",
    "\n",
    "We then average this quantity over batches and time-steps, but an essential insight remains: working with a sum of the logs of many small numbers is mathematically simpler to differentiate and numerically more stable than working with the product of these many small numbers. From a numerical standpoint, probabilities are bounded between 0 and 1, so when a model makes many predictions in a sequence the product of those probabilities can tend to really small numbers or underflow to zero. Taking the log of each probability allows us to work with numbers whose magnitudes grow linearly rather than exponentially, and floating-point addition is more stable than repeated multiplication of numbers less than one. Additionally, since log turns products into sums:\n",
    "\n",
    "$$\n",
    "\\log({p_1 \\times p_2 \\times \\dots \\times p_T}) = \\sum_{t=1}^{T}\\log{p_t}\n",
    "$$\n",
    "\n",
    "we can compute loss for each time-step independently, aggregating them without the fear of catastrophic underflow. But beyond this stability, the log-loss also has compelling statistical and informational interpretations. In maximum likelihood estimation, one chooses model parameters $\\theta$ to make the observed data as probable as possible; equivalently, one minimizes the negative log-likelihood. From an information theory, $-\\log p_{\\theta}(y)$ measures the 'surprise' of event $y$. When we minimize the expected $-\\log p$, we are minimizing the Shannon cross-entropy between the true data distribution and our model's approximation. The cross-entropy is then a measure of the difference between two probability distributions.\n",
    "\n",
    "On the optimizatin side, using a sum of log-probs yields gradients that emphasize mispredicted or low-probability events. If at time-step $t$ the model assigns probability $p_t$ to the correct token, then the derivative of $-\\log p_t$ with respect to the underlying score is $\\frac{-1}{p_t}$, so the smaller $p_t$, the larger the gradient magnitude.\n"
   ],
   "id": "52225c4e6376eacf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.502285Z",
     "start_time": "2025-06-24T08:59:22.212124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "p = np.linspace(0.01, 1.0, 1000)\n",
    "# Compute negative log-loss\n",
    "neg_log = -np.log(p)\n",
    "\n",
    "figure, axis = plt.subplots(1, 2)\n",
    "axis[0].plot(p, neg_log)\n",
    "axis[0].set_title('Negative Log-Likelihood vs Probability')\n",
    "axis[0].set_xlabel('Predicted Probability $p$')\n",
    "axis[0].set_ylabel('$-\\\\log(p)$')\n",
    "axis[0].grid(True)\n",
    "\n",
    "#-log(p): d(-log p)/dp = 1/p\n",
    "grad_mag = 1 / p\n",
    "\n",
    "axis[1].plot(p, grad_mag)\n",
    "axis[1].set_title('Gradient Magnitude vs Probability')\n",
    "axis[1].set_xlabel('Predicted Probability $p$')\n",
    "axis[1].set_ylabel('Gradient Magnitude $1/p$')\n",
    "axis[1].set_ylim(0, 100)  # limit y-axis for clarity\n",
    "axis[1].grid(True)\n",
    "\n",
    "figure.subplots_adjust(wspace=0.8)\n",
    "plt.show()\n"
   ],
   "id": "19e1854833936abb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAHLCAYAAABWP5U7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAeI9JREFUeJzt3Qd4U9X7B/C3e7fssvfeG5GpbJAfiFtURMQFKKIiOPAPoigqKooMFXDhBkVFhuwtW5C9Ny2U0kV3/s/3tDemaVo6Mm5yv5/nCUluQnpycu+57z3Ty2QymYSIiIiIPJ63qxNARERERM7BwI+IiIjIIBj4ERERERkEAz8iIiIig2DgR0RERGQQDPyIiIiIDIKBHxEREZFBMPAjIiIiMggGfkREREQGYcjA7//+7//Ey8vL1clwC127dlU3zZo1a1Te/fTTTw75/JMnT6rPnz9/vnnbww8/LKGhoaIn1atXV+kyCvxGjRs3ttvnab/zu+++W6Tj1Tr/tf0S91QwyD/koyXkIfKbigflF/IS+7kzGK08Kiit7Lh8+bJd8/q222674ftslUl6Oea8i7IzBwYGyrlz5xx+ciiOpKQklZl6OhE4YicsDqRl5MiRrk4GFTN40m4+Pj5StWpVuf3222X37t1idAsWLJAPPvhA9ObEiRPquKtbt64EBwerW8OGDWXEiBHyzz//iKcr7O+CEyX27+7du9t8/dNPPzUfA9u3bxe9+uSTT3Jc0BqZ9ptqt3LlykmnTp1k0aJFYnSbNm1SsUJsbKzD/oZvUf5TSkqKvPXWW/LRRx+JXiHwmzhxonpsWaMEr7zyiowbN85FKXMvy5cvd+rfq1atmly/fl38/Pyc+nfd2X333Sd9+/aVjIwMOXDggMycOVP+/PNP2bJlizRv3lzcXUGO186dO6v9xt/fP0eAsW/fPhk9erToxe+//y733HOP+Pr6yuDBg6VZs2bi7e0tBw8elIULF6rfDoEhjgNXQB4ibY5UlN8FlQ2rV6+WixcvSvny5XO89s0336jXk5OTRS8efPBBuffeeyUgICBH4FemTBnWzGVD2fTcc8+px+fPn5fZs2fLoEGD1DHwxBNPiLvrbKNMKsgxh8APsQv2kxIlSjgkbb5F/cFwlTV+/HipWLGiuBtksqMLN09xo53W3rQaZSq4li1bygMPPGB+3qFDB/nf//6nClAUprYkJiZKSEiIeMrxiuBJ7/vNsWPHVDCAoG7lypVSoUKFHK+//fbbKjjAd8mPI387veYh9ult27bJ999/L88884x5+9mzZ2X9+vWqlvvnn38WvUDtO26Ut0qVKuUotx566CGpXbu2vP/++3kGfunp6ZKZmen081JRFLRMcsUxV6Q+fi+99JKqXUCtX0F8/fXX0qpVKwkKCpJSpUqpwu/MmTO53jdjxgypWbOmel/btm3VAW3dByw1NVUmTJigPi8iIkIVgKgixtWgZRNY2bJl1WNEzlp1staObt1nCM3Tt9xyS670YAfDznnnnXfm2IZmikaNGqkfLDIyUh5//HG5evWq2MuqVavUd8J3Q8Q/YMAAVZNjDc3YrVu3VumoVauWOsnbu/+idf7nVQOMPg/4PXC1Upx8stXHT4PuBQMHDlT9/fD7Pv/882o/tD4p4iqySpUq6mq7Xr16qh+ZyWTKVYC8/vrrKt/wPjQ9YL/Gd7GE/zd58mSpXLmyapLDfvLvv//eMN/S0tLUvj506NBcr8XFxak8Qfo1qD1HXuFvlCxZUv2uqBkpiltvvVXdo+bIsovG2rVr5amnnlLNKvg+GgQb+NvIB1zIockxr2aGHTt2yM0336yO0Ro1asisWbNyvF6Q49MaCnoEQ/jMLl26qNogSwXZp63702Cf/eOPP+TUqVPm4x+/cUJCgkqTZfBgGUTgZD1lyhRxhKlTp6r9c968ebmCPkBw+/TTT6t917p/K4JG1OqGhYWpmkJA+XjXXXep5n38dvh/zz77rKpBsPbLL7+ocg77He7zalKz1d8Ix90jjzyijmH8Hewrc+fOtZn/P/zwg7zxxhtq/8Lf6tatmxw9etT8vrx+lxvBZ6E2yPqY+Pbbb9Xx0qtXr1z/B83myD+cU/D/UVOI73HlypUil6Va9xgtP7X8WLp0ab59/PAdUW7gGNS+t1au5rV/2+onWJjyCMcwalW1shBBFS4uUDbnB2U58syW9u3bq3zSrFixQjp27KjOU9hPUd6iHC0K/D4NGjQwl1uW/YBxLtHK6v379xfqPAnoXnX33XdLeHi4lC5dWh3/1jXEOC5RdqJ8xN9B9wtcPOfXGoZKMOwzeC9q7C0VtN+xdWzywgsvqMcoX7V9BXmBshEtBLYg320dA3kpUrUXEoToHLV+aILJr9YPhcCrr76qMv3RRx+V6OhodZJDNeiuXbvMVZnIYBxQ+CFReOGL4iSPg9ryJIWT5meffaaat4YPHy7x8fHy+eefqy/9999/qx8CQQE+78knn1RXgigwoGnTpjbTiKYXZLh1M8KGDRtUFTQCVQ2CFxyQOKGjkMZO+vHHH6vvsnHjxmI3Uf7111/Sp08fdeAhTSjEkV+44t25c6e5kMTf6927tzqBILhFADRp0iRzwOssSB8OOPStQdrbtGnjkHzC98Nv3K5dO1UQ4G+99957qjDA76wViqjpQpAxbNgwtS8sW7ZMHUg4eSHA0GBf/OKLL1RQj0Bx69at6oSPgsPypIggBgUtTrq44Tfo2bOnCnDyg++HfQ+FAU4illeoOGkgwNT2KxxHyCOkRSuQcNJCmu6//34pLAQJgALOEoI+7B/4TghAAPsY9h/0n0I+Hjp0SB07qF2x/p0QtCMPcCzj+MNJHv8H3w0n1IIen5a+/PJL9R4Em/jeH374oSp89+7dqwKNonr55Zfl2rVrKpjTfnecmHDD74Kao2nTpuWolUEQgX1IC6wc0cyLky/24cLARQryDydY7Ps44cOPP/6ourTgN8BvjfxFWYHvjNcsT1B33HGHOjlhH0fgg+PSslzNy6VLl+Smm24yBzzYf9CNAMcXfmvr5lpUBqCmAxc1yH8Eu8hP7Mv5/S4FgWMBxx72bxz3gEAQx42t8gRByfHjx9V3RbmOAGnOnDnqHt0gtGCrsGUpzgs4rnE8IRCfPn26yt/Tp0/nOuY0CFxGjRqlvivyAIqyfxe0PMJ+gUAB5R7KYlwc4KIcrXQXLlzIt48lzoc4v6MM0MpzQLCOfHvnnXfUc+QjgkScV5FfCJYQ5KPcKApcLKNCyDoPEZChbHjsscfU38AFdUHPkxqUWdiG/X/Lli3qN0N5hvJHg3IPQTzOIbgI++2339RvjEAZ5ZOlI0eOqHxCzeSQIUNUGnERhguAHj16SFEhVjl8+LAqi3B8oGsAYF9E9wGUqbgwthxLgd8J/wddYgrMVAjz5s1DtYlp27ZtpmPHjpl8fX1NTz/9tPn1Ll26mBo1amR+fvLkSZOPj4/pjTfeyPE5e/fuVf9X256SkmIqXbq0qU2bNqa0tDTz++bPn6/+Hj5Xk56ert5v6erVq6bIyEjTI488Yt4WHR2t/u9rr72W63tgm+VXP3TokHr+0Ucf5XjfU089ZQoNDTUlJSWp5+vXr1fv++abb3K8b+nSpTa35/V3kba8NG/e3FSuXDnTlStXzNv27Nlj8vb2Nj300EPmbf379zcFBwebzp07Z9525MgRla8F/VnxvhEjRuT7HuS9Zf6vXr1a/b8ff/zRFB8fr14rU6aMadeuXeb3FCafrD//xIkT6j3Y1zRDhgxR2yZNmpTj81q0aGFq1aqV+fkvv/yi3jd58uQc77vzzjtNXl5epqNHj6rnu3fvVu979NFHc7zv+eefV9tXrVqlnkdFRZn8/f1N/fr1M2VmZprf99JLL6n3IV35WbZsmXrfb7/9lmN73759TTVr1jQ/HzBgQI7jpqC0vJo4caLapy5evGhas2aNyhds//nnn3Mctx07dlTHj0b7fj179jRlZGSYt3/88cfq/XPnzjVvw2+Ebe+99555G45DbX9NTU0t1PGppT0oKMh09uxZ8/atW7eq7c8++2yexytUq1YtR/5r+yXuNfjd8L68fpc///wzx/amTZvm2Bft6dq1a+pvDhw4MNdryB/8ftpNK28s9/1x48bl+n+W79NMmTJF7eunTp0yb8NvVKFCBVNsbKx52/Lly9XnWuePdZk5bNgw9X8vX76c43333nuvKSIiwpwGLf8bNGiQ4/f/8MMP1XaU+Tf6XfKC9+L/YN8qX7686fXXX1fb9+/frz577dq1Oc5N+eXPt99+q963bt26IpWleI5jRitLtPLZ+vyhpQf7uQbHuK39y9b+beszClMeIY9CQkJMhw8fzvGZ2I9wTj59+rQpv301ICDA9Nxzz+XYPnXq1Bz71vvvv3/D81l+vynKHW2fRx5in8LnjRo1KkcZER4err57Uc6TWt7+73//y3VuFxH1f/LbX3r16pWjrNbSblm+anmG4wRlb35lEn6jGx1z77zzTq59B3D8BgYGml588cUc2xGD4bdOSEgwFVSRp3NBpI0IFFdQuIKwBVdFiJYRbaOqVbvh6qtOnTrm5h/UFuEqFNGsZV8eXCmixs8SrtC12hN8dkxMjLoiRvUzIv2iwOg61ESgFkCDqz5MWdK/f3/VBAW4ikbzFSJ6y++DZi1cyeXXnFUQyEeMxkTzBK5qNLiiwt9csmSJOW244kGNqGVtK2oTcBXkDLhqx5UmOqWjKtuyJsdR+WTd7wO1w7ii1yB/sH+g9swSavRwfKGmQnsfjBkzJtf7AE1RgDzGlTSu1C2bYgraKR01V7his9yvcJWJmghcLWpQ640aEFy5FcVrr72mrghxXKH5CDUiaNLRaro1OL4sa7i074fvY9mvDO9Dk4iWDxocm6g90OA4xPOoqCjVBFyU4xP7MLpTaNDFAzVi2m/kCKjdxHGDQQEaXEWjltWyz5E9oXYsr9ot/Gb4/bQburxY02q1LWnlEqAGF8cYmuGxr6MWy7JMQa0EjkkNjk3UAOYHn4N+cygD8djyWEYNJMoA698UtWuWtds4RsHyOC0q7Fs4l6A2BPD7oRlT+xv55Q9qjJBu1F6Clu6ilKXYf7QaR618xvFij++Yn8KURyiDkS84f1r+bkg7vvO6devy/Dv4LvjuqNG37CKDcgz5h9pD0Frrfv311xs2H9uCmmhtn0cTJtKMmAJllyXUplrWvhb0PGnJusZu1KhR6t7yvZb7C/Zt5BdqTfG74rkl7CtoObDMM9SS4rhDy6Ej4PhF65rWMgH4LfG7YP8tTL/fYs3jh6pFFOp59fVDdSgSiCDPsmDDDU1qOGFoVcjawWZ9orHV/wNNdPiR0baOamF8Hk5S1j9OYeBEjCpqbZoaBDNIn+UJGt8HfwN9AKy/D/oOad+nqLR8QHu9NfR9wI6IAh5/B1Xb1vkF1ttw4sWOqN2Kk0eWUNggUEFhhOpxS47IJ/zW1k0vKNQs+wwi/3BAovnFOu+017V7BDrWeYXACYWZ5fsA+68lpMP6gsQW7L8otFAwan0HcTGEJg3L/erFF19UAQGCHvwtFFKFaS5BEwiCSQwYQACG/B07dqzNLhoF2d9w4saFnfa6BnlrXbjgogks+yEV5vi0zlvtMx05/xl+e1xUoskdTWKWI0PRXOMI2j6J/d8augLg90Nf6Lz2I1vNsmha1E5+Wr9XnKhAy+u89uG8yhlL6JaDfmK4uLc+jrW+q9bHshYUaLTjxF59oNHciz5ee/bsUc286C6RV/9PlH3oOoEmVZzUkW7tGNDypzBlaV7f0VZZ5AiFKY9QBqPZ0fp306bEuVEZjPIJza6bN29Wz3ExibLFstzCYzStotsM8hi/BYLFggaBuMDDfo9zCJqhcX5D06tlAFaYcsv6PGnJOs9q1aqlygHLcgZlLvJH6zOI/NL6K1qXXdg3rPc7W2WhvSG4xHGP/r2AvEN3DATMhVGsoa04OeAKGQWDrekWsAMgc1DTYmuEU1Em5UXhiMIOES76biG40Dpka32bigI7Mfo/4KoDQQ12YETY6Pth+X3w9yxrCiw5u39dQaDWBx2KNbjyt8dcUrjy+O6771TQj4PVssbIEfnkiBFyzpjEG4UhTuw4BrDPYr+qX79+jk66KKzQtw59wFBYo5YFAy7Qn0ebkig/KNTymuPMknWB6giOOj4dUYCirxKCP/RHRBChDVByBHwu+pBZD1wBrc9fXicM9GuyHumLK33UbiC4wYUD9imcsHDhivwvSg2MNe0zUMaj3LDFut90Xsep9eCqokJe4aSNMhr9hvPrA4vaQQQU2A/RIoHzDb4TyvTi5I+9v2Ne5ZD1wLXCwPfD/mHrAtAySMkLannRlxTlFWqRcY990PLCCOUJag7RgoMLO5RdqH1CSwdq825UZqM1xFXllpdVnqNswkAkHEfo+4uaZFwAo0YQfe3scTzZA2raEWSjnMU4CdyjwqIg+Wip2HOaoNYPf9y6ehZwgOJgQMSe346mzVmFjqGWo2tRm4jC0LJwQfMrAk7UnFj+eGjuKs5JHWlEjQt2XHRixufj5GU5DxO+DyJsXOU4YmfU8gFBgDU0qeJAQeGOmgncLEfLaay3YQCE5ZWovabfQd6gqRcnGdRmWI5+cnQ+5Zd/+LsYLGBZ64e8017X7nEg46pYqw0EXDmhhsPyfYD3WY5yQ01IQa/ucXDihI/9Cp3zMRJN69xtCb8rLj5wQ3MOAnYMjMLFiKOG+1vub5bfD38fJ1XrwgQDnaynEkGnYtBq5gt6fGqQt9bwmQUZ6Xkj+ZUB6BzdokULdXGC2jRcRTt6XtJ+/fqpgS8YhIGypjgw+AX5hNpVBLEa1KBYstyHrdkqZ6wv0HAcIQAp7InFkRdcCNQxwAHHbl7zVOL4RA04LpxwAaWxzgdcmBS0LHXU99Zq61D2WM7bZl3jXpjyCGUwapeL+rvhGMeFECpCEAih/ELTsfX5A8EgAibc8L4333xTlW8IBu25zxTlPGkJeWZZc3j06FF1DtDKGQzkQKvM4sWLc9To5tUtCf8fsY3lb2pdFjri+EAwjYsdVN4g5sKFq3UXHqcs2YYdDFeEqNWwbtvGyQsJwsFnfTWE59qwevT/QZMQRjci2NOgULbeobUvaPl5GDGmVUlrtJFvhZn9GiddjPjBVAWoLras1tauIFEIYhoQa0h3cWfaRoCAggyFueVnoZYAV1AYxaXlAQ4q/Og4GVvujFo/Ng361eG92u1G/XoKAyccjI7ClB6odXBWPuVFm8QYo4ct4YoNB5PWZ0fLR+uRbSi4tBM0IL8wWhABgeX+VphVB1AwYtQhCpavvvpKfX/r/cp6eglcaeJ3wt9Es7Cj4Pvhb+E3tPx+GIWLpg0tHzRIu+W8gAgQ8RwBAvazwhyfGuzDlqsAISjC++3RVxWFf35dG9A8guMKvyfKH0f3j0XtC8oljIDGRUZxaoxs5TMeY1R0XmWKZV4gQNSmxcjvb6CrAmqgbdVUIuBwxO9yI2haxIUELmoLkz+2jt3ClKXFhe9tq+zT+gta9rvDBRZ+M0uFKY9QBuOYw6wG1pAGy/NsXlBOIU9wsYKmdetyC7XN1rRA3HpaLHsq6HnSknW/2Y+yL/K0Y97W/oJ9FKN1bUG+WM7+gD68aPlCuqwnGC8sLWjN6zyJcgtxEfpXI7gvSr9ku8xijAgfJzVE4Jb9vbBD48oMtRba9Cy4gkRtAjINfZMw7B8nHwzJRodLVBNjp8X7EdXiMywjYFyFoDYBHStxYsJnIfDAidKy/wxqmrANVyqobUQ/GFzl57ekHP4u0oMb3m99xYL+M8hsNFuhcylqvHAg4moCV0YodC3n/MsLAgwtMLUMENCfAM1P2BkxXxKmTNCGqaOpyHJ+LTzGTo5aNXT81gIefL/CLNeFgTX4jWx1OEcN1Y2gdhQ7PfYBpBHfwV75VFhonkCNMdKC/QfNqcgj9LFD05BWwGI7mq7QRQEHF9KLgAMFCfZRrdZZmysQ3wP7HQoUdN7FCUEbZl8QKDDxG+Jk1aRJkxy1jID8QWGB3xLV+Oj/it8S+7d1f0V7wvfDsYkLMzR/YRoDHMNoZsY0DtYFCq72cZWJvMUxhWMLvy/yUZtOo6DHp2VfGexn2IdxstCCsLyaqAoDwSjSiEE8+D5o6sM+osGVM/4OyiL8fUevFoMmeTQpo8YK/ZO0lTtwskE+4TWUAwWZZgVNUtifsX8icEbncgRotmqisf/it0A+I+jECVubN9LWb2IJXTlQ64EmVtQs4HfE/8fgCNSu2zr5F/d3KUiNz43WNkV+oLYd08ng4gkDiFAWaHPEWbJXWVqQ742WEZS32O9R24jzHY5/1DKhvEezNIIQVD7g+ERNtKYw5RE+B7VXeB9aZfC3EUyiphi18jiGb1SGafNG4m9qFwGWMIULglXsW/hN0G8QZQf234KcO4qjoOdJDX53lG8o5zZv3qxaKXH8a11u8BsgDsF+qAVUqIjCb2Rr8CrKP/xd9HNHmY3fCxdzeQWKhaFdROM8hq5CKJeQLi0gREsF9k2cS3EuwQT+hVbU6VysadMO2JqWAsOeMZUEhhzjVr9+fTWNCKZRsTR9+nQ11BlDydu2bWvauHGjmq6jd+/e5vdgGPubb75pfh+GT//+++82h0lv2rRJ/X8MgbccMp3X8Hno0KGDzak+LM2ZM0d9LqaiCAsLMzVp0sQ0duxY0/nz5/PNP+3v2rphiL3mr7/+UunA52MoO6YbwNQF1lauXKm+P75frVq1TJ999pkago8h3wWRV1pw06ZMyG86F0v4/tiOqUAKk08Fnc4F+01e+WkJU8xgKpCKFSua/Pz8THXq1FHD4y2nPwBMG4RpUGrUqKHeV6VKFdP48eNNycnJOd6HaU7wPgzVx/fo2rWrad++fbmmE8kP/jY+39ZUMzB79mxT586d1ZRG2KfxW77wwgtqioD8aHmF71fU4xbwm+GYRD5g2pUnn3xSTTFiSZuqafv27ab27durfQx5YPl7F+b4tEw7pohB/uD9nTp1yjHFQnGmc8H0Bvfff7+pRIkSNqcu0abWwWsoK5wFU4Egj2vXrq3yEfsV8v+JJ55QUw1ZymvfB5QJ3bt3V1NOYUql4cOHm6cWsTx+tDIYU60gjxs2bGhauHBhgaaWgEuXLqnyGr8R9hFMqdKtWzd1fN+oXLB1PBfkd7E1nUth93FME3T77berv4OpZ+666y5V9tj6jgUtS/OaAst6f7Q1nQumW8L3QFloPU3Zjh07TO3atVN/v2rVqqZp06bZ/IzClEcoC1GmYT/D52Ifufnmm03vvvuuefqlGxk8eLBKA/Yza8gzTEWFshafj/v77rsv1xQyRf1Nb1S+FeQ8qZUd2I5pvZD3JUuWNI0cOdJ0/fr1HO9dvHixmtIJv3n16tVNb7/9tprSyvo30NKOaaHwfhxTOH6t9/2iTucCOP9WqlRJTU9ja2oXTK2D7Shri8Ir+w/rEtrgcZWDJmNE33RjqLHCxJq2+vQQUU6omUQtiL37c5H7Y1lKeoVWM22hC1ujzB3ex89eMM+SdQyKNnM0JdxoyTCjsl6aCQUURiExv4huDE04GI1Y2KkQyPOwLCV3gTgJ/bDRRakoQZ/d+vjZAwZVIILFcHH08UEfEnw5tGU7am4td4eRXdpalBgBhv4j6Kdgj/5RRJ4K/X0wZxc6raP/jOWk1GRMLEtJ79BHE/020ecWrRTou15Uugn8MAQac+dghCFq+TC4AqNG0bnYciZ4+g86qmIWb4ymxrQz6OiK4fS2JmsloiyY1xITEONqGQN6ijsKj9wfy1LSO4yix4AUTPmDQZQYrFJUuu7jR0RE/8EoSoxoxCoKaKrGiGT0RdOgOMfocfSJxoh1jFRF7ZVlAIMLa8yggCmGMIoYozXRZ6goE+oTkfvRTR8/IiK6cXMPpqCwtZ4vYPoSbW5NzIeIKSAw2z/6UGswjQwGLWAuP6wWg2ASU2sRkTGwxo+IyA1hflPLGj8U5Zhr8bnnnlNzr2mT0GKeMcyJijnBMEck5uLD/GOYOB+w1BbmbDt79qzdVvYhIv3STR8/d4OpZjB7Nya4dMaar0SOgGABS9zhhG+9Hiy536AV9FGznHgeE9pi8mVMWovAD/foI6QFfYD347dHDSGmt7GGibUtV2JA2YfmYgzCY9lH7shk8HKPgV8RIejDYBQiT3DmzJkCrRhB+qUtmYkaPkt4rr2Ge6xGYMnX11cNprNeclODlSKwuguRpzlj0HKPgV8RaUtpYcfB8kCWsEQQlgDSliqjwmMeOicfsdweLmAcuTQcuTcs64fl1TRoPsaIaNQwWu832N8e/2yt7LriLc92ry0P3VS0ecaMDHmIKTuwdCTLPsfkYXx8vNSoUcOw5R4DvyLSmjgQ9NkK/LAWL7bzwC0a5qFz85FNdu5Pm5YGa4ZiIXsNnmPxeO09WFPVUnp6umq6zWtaG0xvgps11BLaKvv8g4LFO8BbQsLCVXMwFe2YRd6x7HNMHvplbzNquWe8xm0iIg+EGgwEbytXrsxRo4u+e5iXDnCPaV4wHYxm1apVqt8e+gLag3YqzeSwQSJdYo0fEZGbSEhIyLGuMJpbd+/erWrf0Pw6evRomTx5spq3D4Hgq6++qjqwayN/GzRooCYrHj58uJryBTUjI0eOVAM/7DWiVwv8OF8EkT4x8CMichPbt29X/ZY0Wt+7IUOGqClbsMQY5vrDvHyo2evYsaOariUwMND8f7755hsV7HXr1s08gTPm/rO3TEZ+RLrEwI+IyE107dpVTUWRF/RZmjRpkrrlBbWDCxYscFAKRbyN2W2KyG2wjx8REdldJjv5EekSAz8iIrIbbaAkwz4ifWLgR0REdvPfqF6GfkR6xMCPiIjshqN6ifSNgR8RETkg8GPkR6RHDPyIiMhu2MePSN8Y+BERkd2xjx+RPjHwIyIiu2EfPyJ9Y+DnIMnpIudir8uVhBRXJ4WIyGnY1Eukbwz8HGTleW/p+t56mb7yiKuTQkTkdGzqJdInBn4O4uudVeilZmS6OilERM4/qTDuI9IlBn4O4pvd3JGSzsCPiAwku+xjjR+RPjHwcxCf7JxNZeBHRAbCwR1E+sbAz8E1fmls6iUiQy7Z5uKEEJFNDPwcxJc1fkRk6FG9jPyI9IiBn4Nr/Di4g4iMhE29RPrGwM9BWONHREbEtXqJ9I2Bn8Nr/Fj4EZERR/W6OiFEZAsDPwfhqF4iMiKv7L597ONHpE8M/Bxd45ee4eqkEBE5DUf1EukbAz8H4codRGToUb0M/Ih0iYGfw2v8GPgRkfFq/LhmG5E+MfBz8KjeNA7uICIDyuQ1L5EuMfBzEB/W+BGRAXECZyJ9Y+DnIJzHj4iMiIM7iPSNgZ8TVu7gRKZEZBRcuYNI3xj4ObjGD9jPj4iMN6qX5R6RHjHwc3CNH3BKFyIyXI2fi9NBRLYx8HNCjR/7+RGR0WSyxo9Ilxj4OYi3F5Zty7r2ZeBHREbBCZyJ9I2BnwP5Z8/pksamXiIy3KheRn5EesTAz4H8s9t7U1jjR0QGwT5+RPrGwM+B/H2yspdNvURkFBzVS6RvDPycUOPHUb1EZDSM+4j0iYGfA7HGj4iMhhM4E+kbAz8HCvDzUffJaRmuTgoRkVObejm4g0ifGPg5UKBfVvZeZ+BHRAbBwR1E+sbAz4GCWONHRIZt6mXoR6RHDPwcKECbziWNffyIyBg4gTORvjHwc6DA7Bo/NvUSkdGwjx+RPjHwc6Cg7D5+bOolIqOdVBj2EekTAz+njOplUy8RGYR5VK+rE0JEtjDwc6DA7D5+bOolIqPg4A4ifWPg54Q+fmzqJSKj4ATORPrGwM8JgV9KOgM/IjLYqF728iPSJQZ+TpjAmX38iMhoNX6ZLPaIdImBnzP6+KWyxo+IjIU1fkT6xMDPGX382NRLRAbBCZyJ9I2BnwNxcAcRGQ0HdxDpGwM/p0znws4uRGSwwI9NvUS6xMAv21tvvSVeXl4yevRou31moH/2qF7W+BGRwXACZyJ9YuAnItu2bZPZs2dL06ZNHVLjx6ZeIjIKb3MfP0Z+RHpk+MAvISFBBg8eLJ9++qmULFnSIX38uHIHERkNa/yI9MlXDG7EiBHSr18/6d69u0yePDnP96WkpKibJi4uTt2npaWpmyXtuY9kmmv8rN9D+dPyi/nm2Hxk/pLjJnAmIj0ydOD33Xffyc6dO1VT741MmTJFJk6cmGv78uXLJTg42Ob/2b51k8ripOQ0WbJkiV3SbDQrVqxwdRI8Oh+TkpKcnhbybFyrl0jfDBv4nTlzRp555hl1QgwMDLzh+8ePHy9jxozJUeNXpUoV6dmzp4SHh+eqRcHndr+li0zcuVHSTF7Su3cf8dY6v9ANaXnYo0cP8fPzc3VyPDYftZprInvhdC5E+mbYwG/Hjh0SFRUlLVu2NG/LyMiQdevWyccff6yadX18svroQUBAgLpZw8k0r8AkLOi/92d4eUuAn2Gzu8jyy18qfj4yb8lhS7Yx8iPSJcNGIt26dZO9e/fm2DZ06FCpX7++vPjiizmCvqIKyh7cAUmpGRLsb9jsJiKD4ModRPpm2EgkLCxMGjdunGNbSEiIlC5dOtf2okLTbrC/jwr6ElPSpUxo7hpDIiJPxBo/In0y/HQujhYSkBVbJ6ZwShci8nzsyUykb4at8bNlzZo1dv/MEH8fiUbgl5pu988mItIbNvUS6Rtr/JxW48fAj4g8Hwd3EOkbAz8HC8ke0IF+fkREns4re+pmhn1E+sTAz8GCA7JG9iawxo+IHAxTUr366qtSo0YNCQoKklq1asnrr7+eYzJlPJ4wYYJUqFBBvQerFh05csTuVX6s8SPSJwZ+TmrqTWLgR0QO9vbbb8vMmTPVXKQHDhxQz6dOnSofffSR+T14Pn36dJk1a5Zs3bpVzWbQq1cvSU5Otu/gDsZ9RLrEwR0OhsEdkMimXiJysE2bNsmAAQPU+uNQvXp1+fbbb+Xvv/821/Z98MEH8sorr6j3wZdffimRkZHyyy+/yL333lvsNLCPH5G+MfBzMA7uICJnufnmm2XOnDly+PBhqVu3ruzZs0c2bNgg06ZNU6+fOHFCLl68qJp3NREREdKuXTvZvHmzzcAPqxjhZr3MH5YDxM0SnmujehH4Wb9ON6blGfPOcXmYZvC8ZeDnYCEc3EFETjJu3DgVmGEFIqw+hD5/b7zxhgwePFi9jqAPUMNnCc+116xNmTJFJk6cmGv78uXLJTg4OM8av8TEJFmyZIkdvpUxYY1tckweJiUliZEx8HNSjR8HdxCRo/3www/yzTffyIIFC6RRo0aye/duGT16tFSsWFGGDBlSpM8cP368jBkzxvwcgWWVKlWkZ8+eEh4enqsm5bOFWSdbDBzp27dzMb+R8SAPEbD06NGDa2k7KA/jsmutjYqBn4OFZI/qTeIEzkTkYC+88IKq9dOabJs0aSKnTp1StXYI/MqXL6+2X7p0SY3q1eB58+bNbX5mQECAulnDCdVmYKJN4CxeDFyKIc/8pWLnoZ/B85Wjeh0sOLupN4FLthGRg6EJy9s7Z7GOJt/MzEz1GNO8IPhbuXJljtoPjO5t3769XdKg/XXLKWSISD9Y4+dgoVqNH5t6icjB+vfvr/r0Va1aVTX17tq1Sw3seOSRR9TrXl5equl38uTJUqdOHRUIYt4/NAUPHDjQrmnJZNxHpEsM/JxU48fpXIjI0TBfHwK5p556SqKiolRA9/jjj6sJmzVjx46VxMREeeyxxyQ2NlY6duwoS5culcDAQPuu1cuJ/Ih0iYGfg3E6FyJylrCwMDVPH255Qa3fpEmT1M0RtFG9bOkl0if28XMwDu4gIiNiUy+RPjHwc7AQramXgzuIyAC0pl6u2UakTwz8nNTUez0tQ9IzskbWERF5qv+WbHNxQojIJgZ+DhYW+F83Sk7iTESejmv1EukbAz8H8/PxlmD/rH5+cdcZ+BGRZzOP6mXcR6RLDPycIDwwa5bwuGRjLwxNRAaq8WNbL5EuMfBzgvCgrObeuOsM/IjIs3lnR35s6iXSJwZ+TsAaPyIyCg7uINI3Bn5OHODBPn5EZJQ+fhms8SPSJQZ+ThAexBo/IjLWScXEwI9Ilxj4ObWplzV+RGSMGj829RLpEwM/J+DgDiIyWh+/DEZ+RLrEwM8JOLiDiIw2qhfY3EukPwz8nNnHj4M7iMjDWcR9bO4l0iEGfs4c1csaPyIySB8/YHMvkf4w8HNmUy/7+BGRgU4qnMSZSH8Y+DmxqTeeo3qJyEA1foz7iPSHgZ8ThJsncGaNHxEZp48fJ3Em0h8Gfk4QodX4paRLekamq5NDROSUUb1s6iXSHwZ+Tgr8tOaPWNb6EZFRmnp5nUukOwz8nMDXx9s8wCM2KdXVySEichg29RLpGwM/JykV4q/uYxJZ40dERpnHj4Efkd4w8HOSEsFZNX5XWeNHZCjnzp1TNyM19Wr9/Bj4EekPAz8nKRWcVeN3NZGBH5ERbNy4UWrUqCFVq1ZVt8jISHnxxRclLi5OPJ13dke/TPbxI9IdBn5OUkIL/JLY1EtkBI8//rg0aNBAtm3bJocOHZJ33nlH/vrrL2nZsqXH1wBqAzxY40ekPwz8nKRUCJt6iYzk2LFj8sEHH6hAr3bt2vLQQw/J9u3bpUWLFjJ69GjxZD7Zbb0M/Ij0h4Gfs2v82NRLZAio7YuKisqxzcvLSyZNmiRLly4VT8amXiL9YuDnJCXNTb0M/IiM4OGHH5ZRo0bJmTNncmy/du2ahIeHiydjUy+RfmWtJUZObOplHz8iI9Cac+vUqSODBg2S5s2bS0ZGhnz99dcydepUMUSNHwM/It1h4Of0wR2s8SMyggsXLsju3btlz5496n7+/Ply5MgR1dyLwO/PP/+Upk2bqlvv3r3Fk/gw8CPSLQZ+Tp7AmX38iIwB07f06tVL3TTJycmyd+9ec0C4ePFiefPNNyU2NlY8s6nX1SkhImsM/Jw8gfO162mSkWkyj3ojIs8yYcIEGTBggLRq1SrXa4GBgdKmTRt182Rs6iXSLw7ucPLgDlwBx11nPz8iT3X27Fnp06ePVK5cWZ588knVpJuaaqyafu3CFhe5RKQvDPycxM/HWyKCsmr9riSmuDo5ROQgc+fOlYsXL8q3334rYWFhapBHmTJl5I477pAvv/xSYmJixNNpTb2s8CPSHwZ+TlQ2LEDdR8Uz8CPyZN7e3tKpUyc1iAOrdmzdulXatWsns2fPlooVK0rnzp3l3Xff9dgVPNjUS6RfDPycqExoVnNvNAM/IsNN5jx27Fi1fi/m9RsyZIisX79e1Qp6Ip/sGj829RLpDwd3OFHZsEB1z8CPyLjKli0rw4YNUzdPhSlrgHEfkf6wxs+JyoZmNfVeTjBWR28i+g9q/B555BHxZFpTr4lNvUS6w8DPicqEsamXyOgwuOOLL74QT+aTfWZhUy+R/rCp1wU1ftEJDPyIPBUmZc7P8ePHxdOxqZdIvxj4uWBUL2v8iDzXwIEDVeCTXzOnFhh5Km1+ejb1EukPm3qdqIy5jx8DPyJPVaFCBVm4cKFkZmbavO3cuVM8nbZWbwYDPyLdYeDnROWya/yuJKSw7wuRh8JSbTt27Mjz9RvVBnoCNvUS6Rebep2oVIi/mtEehWFMYqq56ZeIPMcLL7wgiYmJeb5eu3ZtWb16tXgy7+wqBU7gTKQ/DPycyNfHW0qH+KvpXNDPj4EfkefBih35CQkJkS5duogRmnozWeVHpDts6nUy9vMjIk/Hpl4i/WLg52Rcr5eIPJ02qpdNvUT6w8DPySLDs5ZtuxSX7OqkEBE5dOUONvUS6Q8DPyerEJEV+J2Pve7qpBAROYR3dpUf4z4i/TFs4Ddz5kxp2rSphIeHq1v79u3lzz//dPjfrRARpO4vXmONHxF5Jjb1EumXYQO/ypUry1tvvaXm29q+fbvceuutMmDAAPn333+dU+PHwI/I461fv14eeOABdWF57tw5te2rr76SDRs2iCGaehn4EemOYQO//v37S9++faVOnTpSt25deeONNyQ0NFS2bNni0L9boURW4HfxGpt6iTzZzz//LL169ZKgoCDZtWuXpKRkDei6du2avPnmm+LJGPgR6Rfn8cOyQhkZ8uOPP6pJV3FlbgsKba3ghri4OHWflpambpa059bboUxwVpZfTUqTuMRkCfL3set38RT55SHZLx+Zv44zefJkmTVrljz00EPy3Xffmbd36NBBvWaIpt5MV6eEiKwZOvDbu3evCvSSk5NVbd+iRYukYcOGNt87ZcoUmThxYq7ty5cvl+DgYJv/Z8WKFbm24QLY39tHUjO95Pvflkm5rC5/lAdbeUj2y8ekpCSnp8UoDh06JJ07d861PSIiQmJjY8UINX5cq5dIfwwd+NWrV092796tml5++uknGTJkiKxdu9Zm8Dd+/HgZM2ZMjhq/KlWqSM+ePdXgEOtaFJxoe/ToIX5+frk+a/rRDXL8cpLUa9FO2tcs7aBv595ulIdkn3zUaq7J/sqXLy9Hjx6V6tWr59iO/n01a9YUIyzZ5ulrEhO5I0MHfv7+/mrdTG1h9W3btsmHH34os2fPzvXegIAAdbOGk2legUler1UsEawCv6iEdAY1N5Bf/lLx85F56zjDhw+XZ555RubOnatWsjh//rxs3rxZnn/+eXn11VfFGH38XJ0SIrJm6MDPWmZmZo5+fI5SPntkLwd4EHmucePGqTKlW7duqkkdzb64eETgN2rUKDFEUy8jPyLdMWzgh6bbPn36SNWqVSU+Pl4WLFgga9askWXLljn8b1fklC5EHg+1fC+//LK88MILqsk3ISFBdSNBf2JPx3n8iPTLsIFfVFSUGm134cIF1dkakzkj6ENfKEerUIKTOBMZqUtJXoPGPJVvdic/1vgR6Y9hA7/PP//cZX9ba+rlsm1EnsVyANiNTJs2TTx9cAcDPyL9MWzg50pVSmbV+J29el2NekOTEBG5P0zUbGnnzp2Snp6uZhCAw4cPi4+PjxpM5sl8s9t6GfgR6Q8DPxeoXDJr3r+ElHSJTUqTkiH+rk4SEdnB6tWrc9TohYWFyRdffCElS5ZU265evSpDhw6VTp06iSfzya7yS2fgR6Q7hl2yzZUC/XykXFjW1DCnYziBLpEneu+999TE71rQB3iMVTvwmifzYVMvkW4x8HORqqWyav3OXGXgR+SJMDl2dHR0ru3YhpkEHOXcuXPywAMPSOnSpdU6wU2aNJHt27ebX0f3kgkTJkiFChXU6927d5cjR47YNQ0+bOol0i0Gfi5SJTvwY40fkWe6/fbbVbPuwoUL5ezZs+r2888/y7Bhw2TQoEEO+ZtoSsZawJiY+88//5T9+/er2kXLWsepU6fK9OnT1TrCW7dulZCQEOnVq5dautJefDiPH5FusY+fiwO/Mwz8iDwSAitM1nz//ferpfNQ04aADIHfO++845C/+fbbb6ulJOfNm2feVqNGDfNjpOGDDz6QV155RQYMGKC2ffnllxIZGSm//PKL3Hvvvfat8eM8fkS6w8DP1U29MZzShcgTBQcHyyeffKKCvGPHjqlttWrVUjVsjrJ48WJVe3fXXXepdccrVaokTz31lFo+Dk6cOCEXL15UzbsazGParl07tZycrcAPqxlZrmikre+MYBY3S+bn2QFfalp6rvdQ/rT8Yr45Lg/TDJ63DPxcPKULm3qJPNOkSZPyfR397Ozt+PHjMnPmTDWf4EsvvaTWH3/66afVJNJDhgxRQR+ghs8SnmuvWcMAlYkTJ+bavnz5chXc2nLm9CnVk+jo8ROyZElW0EuFs2LFClcnwWPzMCnJ2OddBn4uUrV0sHkS5/SMTPHVhsERkUdYtGhRrloG1Lj5+vqqmj9HBH5YG7h169by5ptvquctWrSQffv2qWZnBH5FXd7ScmJq1PihOblnz54SHh6e6zviZFu7Zg1Zef6UVK1WXfr2rV/Mb2UsWh5iFSl0DSD752Fcdq21UTHwc5HIsEDx9/GW1IxMuXAt2dznj4g8czJn7YTz8MMPq4EfjoCRutbLwzVo0EANKoHy5cur+0uXLqn3avC8efPmNj8zICBA3azhhJpXYOLn66Pu0eDL4KVo8stfKl4e+hk8X1nN5CLe3l5SObu5lwM8iIwBNWRoNn311Vcd8vkY0Xvo0KEc27BaSLVq1cwDPRD8rVy5MkcwitG97du3d8B0Lnb7SCKyEwZ+LlS9TFYn7+OXE12dFCJykmvXrqmbIzz77LOyZcsW1dR79OhRWbBggcyZM0dGjBihXsfykKNHj1aTSGMgyN69e+Whhx6SihUrysCBAx0Q+DHyI9IbNvW6UM0yIbIKgV80Az8iT4O58ixhKpULFy7IV199JX369HHI32zTpo3qW4h+eRhcgho+TN8yePBg83vGjh0riYmJ8thjj0lsbKx07NhRli5dKoGBgXZLB2v8iPSLgZ8L1Swbqu6PX05wdVKIyM7ef//9HM+9vb2lbNmyapAFAjNHue2229QtL6j1Q1B4o1HHxcEaPyL9YuDnQjXLZjf1ssaPyONgBK9RaYFfOlfuINId9vHTQeB39mqSpKRnuDo5RGRHp0+fVs27eb3myXyzA79MrtxBpDsM/FyobGiAhAX4Ci6KT13hyF4iT4L+ddHR0bm2X7lyJccyap7IO3ut3vQMBn5EesPAz4XQ1+a/5l728yPyJKjtwzFuLSEhwa4DKfSINX5E+sU+fjoY4LHn7DU5xn5+RB5BW+UCQR/m67Nc1iwjI0PNmZfXZMmeNE8psI8fkf4w8NPBlC7AAR5EnrViB2r8ME8e1snV4HGzZs3k+eefFyPU+GUw8CPSHV93WnsPi4hjcWVMiVCqVCnxBJzShcizrF69Wt0PHTpUPvzww1zr2RqB1sePgR+R/ui6j198fLzMnDlTunTpogrP6tWrq3UnEfhhCaLhw4fLtm3bxJ3VKpdV43c0KiHPEYBE5H7mzZtnyKDPssaPTb1E+qPbGr9p06bJG2+8IbVq1ZL+/fvLSy+9pJYVCgoKkpiYGNm3b5+sX79eevbsKe3atZOPPvpI6tSpI+6mZplQVUjGJ6fLhWvJUrFE1vq9ROSe/ftef/11CQkJMff1y6+M8/R5/DIZ+BHpjm4DP9TkrVu3Tho1amTz9bZt28ojjzwis2bNUlfWCALdMfDz9/VWI3sPX0qQQxfjGfgRuXn/PnRL0R4bFSdwJtIv3QZ+3377ba5t586dU/eVKlUybwsICJAnnnhC3Fm98uEq8Dt4MV5uqV/O1ckhomL277N+bDTmGj92XyHSHd0GfpY2btwoDzzwgHm2+zJlysjDDz8sL7/8skf0oalfPkx+2yNy6GKcq5NCRHa0cuVKdYuKipJMi3VrMdXL559/Lh5f48cJnIl0R9eDOzSPP/64GtSB5t9Dhw7JO++8I3/99Ze0bNnSXAvozupGhql71PgRkWeYOHGi6oOMwO/y5cty9epV8w39lD0Za/yI9MstavyOHTsmCxculLp166rntWvXlgcffFDuvvtuGT16tPz444/i7jV+cCw6QdIyMsXPxy3icSLKB/ofz58/X5VVRuOjLdnGPn5EuuMWEQZq+9BUYglNJZMmTZKlS5eKu6tUIkhC/H0kLcMkJy5zImciT5Camio333yzGJFW48d5/Ij0xy0CP/TnGzVqlJw5cybH9mvXrnlEHz8sb1Q3u9aPzb1EnuHRRx+VBQsWiBFx5Q4i/XKLpl405wKmaxk0aJBa5xJrXn799dcydepU8QRo7t11OjZrgEeziq5ODhEVU3JyssyZM0f1R27atKn4+fkZZh4/ba1eBn5E+uMWgd+FCxdk9+7dsmfPHnWPfjNHjhxRzb0I/P78809VsOLWu3dvcUf1y2fVXB68wBo/Ik/wzz//qItUwITzllB2eTLW+BHpl1sEfpGRkdKrVy91s7yaxgLoWkC4ePFiefPNNyU2NlbcUaOKWYHf3nPXXJ0UIrIDI8/jp63Vy8EdRPrjFoGfLYGBgdKmTRt18wQNK4YLLpKj4lMkKi5ZyoUHujpJRETFrPH7b+5CItIH3QZ+mKy5atWqBX4/5vOzXNHD3QT7+0rtcqFqBQ/U+nVj4Efk1vJaqxfNvLhwxbRUAwYMkFKlSomn4aheIv3S7ahe1ORh4mZM2pwXjOr99NNPpXHjxvLzzz+Lu2tcKULd/3OWzb1E7g5r9WJ1DgzwWLt2rbqhvMI2TOqMwBDB3/79+8XTMPAj0i/d1vihMHzjjTekR48e6uq4VatWUrFiRfUYM9/j9X///Vet3oEBHn379hV316RShCzceU72sZ8fkdvTavPmzZtnnnYKF6uY5qVjx44yfPhwuf/+++XZZ5+VZcuWiUcGfly5g0h3dFvjV7p0aTXdAUb0fvzxx2oqFyx7hNG8MHjwYNmxY4ds3rzZI4I+LfADDvAgcn9YWvL111/PMddoRESE/N///Z+6WA0ODpYJEyaocszTsMaPSL90W+OnCQoKkjvvvFPdPB0HeBB5DtTuYcWhhg0b5tgeHR0tcXFx6nGJEiXUCh+ehoEfkX7ptsbPiDDAo1bZUPWYtX5E7t/U+8gjj8iiRYvk7Nmz6obHw4YNk4EDB6r3/P333+Y1yD2JT/Y0hYj7Mhn8EemK7mv8jDY6rknlCDkSlSB7zsRKtwaRrk4OERXR7NmzVf+9e++9V9LT09U2X19fGTJkiLz//vvqef369eWzzz4TT+Pj/V+dAvr5eYtnT1hN5E583WV03M6dO9UybfXq1VPbDh8+LD4+Pqrg/OSTT+S5556TDRs25GpWcTctq5ZUAzx2nnbPiaiJKEtoaKgaxYsg7/jx42pbzZo11XaNtrKHpzb1as29fj4uTQ4RuVtTL2rzunfvLufPn1cdoXFDswlG/N53331qDr/OnTurq2t316paSXW/6/RV9o8h8gAI9LQlJS2DPk/mY3FmYTlGpC++7jI6bsWKFTZHx/Xs2VOeeeYZNToOj91d3cgwCQ3wlYSUdDl0MV4N+CAi94WppzAhvfUgjv/973/iqSyberlsG5G+uEXgZ6TRcWgiaV6lhGw4ell2nr7KwI/ITaF59/bbb1driqM/sil7Tjs8BnRd8VR+Fk296Rlcto1IT9ymqddIo+NaZjf37jx11dVJIaIiQktEjRo11EUr5uzDhPPr1q2T1q1by5o1a8STeXt7mfv5pWWwxo9IT3zdcXQcrpz9/Pw8dnSc1s9vx2kGfkTuCpPLr1q1SsqUKSPe3t7qhhU7pkyZIk8//bQatObJfL29VP++NNb4EemKWwR+Rhsdh6ZeOHUlSS4npEiZ0ABXJ4mICglNuWFhYeoxgj8MTsOsBNWqVZNDhw6Jp/P38ZaU9EwGfkQ64xaBH8TGxqrFzQ8cOKCeN2rUSDX/YpCHp4kI8pO6kaFy+FKC7Dh1VXo1Ku/qJBFRITVu3Fj27NmjmnvbtWunlmnz9/eXOXPmqAtXT+ebPYszB3cQ6Ytb9PHbvn271KpVS9X4xcTEqBvW8cU2zO/niVpXz5qMeuvxGFcnhYiK4JVXXpHMzKzarkmTJsmJEyekU6dOsmTJEpk+fbp4Or/sOV1Y40ekL25R44f+fZj6AM29mPke0Nfv0UcfldGjR6sO056mfc3SsmDradly/Iqrk0JERdCrVy/zY6wudPDgQXXRWrJkSfPIXmMEfqzxI9ITX3ep8bMM+gCPx44dq0bIeaJ2NbNq/A5cjJPYpFQpEezv6iQRUTF5wrKShW7qZY0fka64ReCHiZsxASpG7lo6c+aMufO0pykXFii1y4XK0agE2XI8Rno3Zj8/IneAvscFMXfuXPFkrPEj0ie3CPzuueceNWffu+++KzfffLPatnHjRnnhhRfUkm2eCs29WYHfFQZ+RG5i/vz5auRuixYtzJM2GxGmcwH28SPSF7cI/BDwoU/MQw89pPr2Aebxe/LJJ+Wtt94ST3VTzdLy1ZZT7OdH5EZQLn377bdqMMfQoUPlgQceMFQTr8bfN6vGLz17gAsR6YNbjOrFFAgffvihXL16VXbv3q1u6CSNUb4BAZ47x91N2f38Dl6MlysJKa5ODhEVwIwZM+TChQuqD/Jvv/0mVapUkbvvvluWLVtmqBrA/2r8jPOdidyBWwR+Gix71KRJE3XDY09XOjRA6kVm9WHceoLTuhC5C1yQohvKihUrZP/+/Wre0aeeekqqV68uCQkJYgS+nM6FSJd029Q7ZsyYAr8Xc/p5qva1SsuhS/Gy4ehl6dukgquTQ0SFhKXa0FUFtX1YzcMosHIHpLPGj0hXdBv4FXQdS0+fD6tL3bIyf9NJWXsoWp04PP37EnmClJQUWbhwoRq5u2HDBrntttvk448/lt69e6tA0EjTubDGj0hfdBv4rV692tVJ0M0AD3SSPhd7XY5FJ0jtcp45fQ2Rp0CT7nfffaf69mFqFwz0wFq9RuObHeCyjx+Rvug28MvL4cOH1TqXlpM5e7Igfx9pV6OUrD9yWdYcimbgR6Rzs2bNkqpVq6pyau3atepmC2oEPZm/r7ZWL2v8iPTE7aKnBg0ayIEDB6Ru3bpiFGjuReC39nC0PNrJ8xd3J3JnmHaKXTL+q/FLTWfgR6Qnbhf42Ws6hClTpqgrbqyfGRQUpCaGfvvtt6VevXqiN13rlZPJfxyQrcdjJCk1XYL93e5nIzLUBM7038od6Zls6iXSE2P0MrYBzS8jRoyQLVu2qCkX0tLSpGfPnpKYmCh6U6tsiFQqESSpGZmczJmI3IIf1+ol0iXDVh0tXbo011V6uXLlZMeOHdK5c2fREzQbda1XVr7Zelr187u1fqSrk0REVKBRvakc3EGkK4YN/Kxdu3ZN3ee1tBKmZ8BNExcXp+5RU4ibJe259fbi6FSrlAr8Vh64JK/0qevxfYgckYdGdKN8ZP6Sw5t6WeNHpCsM/EQkMzNTRo8eLR06dJDGjRvn2Sdw4sSJubYvX748z1VE0IRsL6kZIn7ePnIuNlk+/elPqRwihmDPPDSyvPIxKSnJ6WkhY2AfPyJ9YuAnovr67du3T020mpfx48fnWE0ENX6Ypwv9AsPDw3PVouBE26NHD/Hz87NbOpfH75YVB6IkuXRd6XtrbfFkjspDo7lRPmo112R/p0+fVmWEde08BqidOXNGTflihD5+HNVLpC+GD/xGjhwpv//+u6xbt04qV66c79qbuFnDyTSvwCS/14qid+MKKvBbcSBanuvVQIzA3nloVHnlI/PWcWrUqCEXLlxQfYctxcTEqNc8ffk2bToXzuNHpC9uN6r3xRdflNKlSxf7c3DVjaBv0aJFsmrVKlUQ6123BuXEx9tLDl6Ml9NX2ERHpGd5LbGYkJAggYGBYpxRvWzqJdITt6vxQ187ezXvLliwQH799VcJCwuTixcvqu0RERFqXj89KhHsr1bx2HTsiizff5GTORPpkNYlBEHfq6++mqMPMGr5tm7dKs2bNxej9PHDNFREpB9uF/jZy8yZM9V9165dc2yfN2+ePPzww6JXPRtGZgV+/15i4EekQ7t27TLX+O3du1f8/f3Nr+Fxs2bN5PnnnxdP52se1csaPyI9MWzgZ68VQJytR6Py8n+/7Zdtp2IkKi5ZyoV7fpMRkTtZvXq1uh86dKhMnz5dtSgYkbmpl338iHTFsIGfu8IKHi2rlpCdp2Plj70XZGgH/fdNJDIitB6sXLlS3aKiotS0UZbmzp0rhmjqTXfPi2wiT+V2gztIpH+ziup+8Z7zrk4KEeVh0qRJaronBH6XL1+Wq1ev5rh5Ov/swC+NffyIdIU1fm6oX9MK8vrv+2XX6Vg5E5MkVUrZnkCaiFzbjxhLQT744INiRP6+WYFfSrpnT1tD5G5Y4+eGyoUFyk01s6a0+e0f1voR6VFqaqrcfPPNYlQB5sCPNX5EesLAz82be3/bc8HVSSEiGx599FE1ZZQrvfXWW2paGSxJqUlOTlbTWWE+1NDQULnjjjvk0qVLdv/bAX4+6j4ljYEfkZ6wqddN9WlcXl79ZZ8cuBAnR6PipXY5Y44cJNIrBFhz5syRv/76S5o2bZprlZRp06Y59O9v27ZNZs+erf62pWeffVb++OMP+fHHH9W8pZjIftCgQbJx40aH1PhxHj8ifWHg56YwmXPnumVl1cEoWbjznIztXd/VSSIiC//88495omasBW7J1ooe9oTVQQYPHiyffvqpTJ482bz92rVr8vnnn6uayFtvvdU8+rhBgwayZcsWuemmm+yWBvbxI9InBn5u7I6Wlc2B33M966nl3IhIX/P5uQKacvv16yfdu3fPEfjt2LFD0tLS1HZN/fr1pWrVqrJ582abgV9KSoq6aeLi4tQ9Pgc3S9pz3PtIprmp1/p9lDfLPCTH5GGawfOWgZ8b696wnJQI9pOLccmy/ki0dK2XczF4IjKe7777Tnbu3Kmaeq1haUqsHlKiRIkc2yMjI83LVtpaJnPixIm5ti9fvjzHcnSWVqxYIZeu45GvJCQly5IlS4r6dQwLeUiOycOkJGOvdc/Az40F+PrIwOaVZP6mk/LjjrMM/Ih0Zv369aqf3bFjx+Snn36SSpUqyVdffSU1atSQjh072v3vnTlzRp555hl1wgsMtM+qPuPHjzevP6zV+FWpUkXNURgeHp6rJgV/u0ePHnIpIV3e3L1eTN4+0rdvL7ukxQgs89C6XyjZJw/jsmutjYqBn5u7s1VlFfit+PeSxCalqr5/ROR6P//8s5rDD33tsH6v1lyKfnZvvvmmQ2rB0JSLVUJatmxp3paRkSHr1q2Tjz/+WJYtW6ammYmNjc1R64dRveXLl7f5mQEBAepmDSfUvAITbA8J/G86F19fX4f3a/Q0+eUvFS8P/Qyer5zOxc01rhQhDSuEq5Fzv+7mnH5EeoG+dbNmzVIDLCxPNB06dFBNsY7QrVs32bt3r+zevdt8a926tQo+tcdIC1YT0Rw6dEhOnz4t7du3t3uLBGSasF4vl20j0gvW+HmAu1pXlom/7Zcfd5yRITdXd3VyiCg7oOrcuXOu7ZhCBTVujhAWFiaNGzfOsS0kJETN2adtHzZsmGq6LVWqlGqqHTVqlAr67DmiFwL8/qtXQK2ftnYvEbkWj0QPgH5+WBdz37k42XPGMScUIiocNJ0ePXo01/YNGzZIzZo1xVXef/99ue2229TEzQhMkc6FCxc6bK1eSOXqHUS6wRo/D1AyxF+t37to1zn5asspaVYl54g9InK+4cOHq4EWc+fOVf3bzp8/r6ZMef755+XVV191WjrWrFmT4zkGfcyYMUPdHMnb20v8fLwkLcPEufyIdISBn4d4sH01Ffj9tue8vNy3gQoGich1xo0bJ5mZmarfHaaPQO0aBkkg8EPzqhGgn19aRjqXbSPSETb1eogWVUpIo4rhqi/ND9vPuDo5RIaHWr6XX35ZYmJi1ModWBkjOjpaXn/9dTEKbdk2lEtEpA8M/DzoJPNQ+2rq8ddbT0kmR9ER6QImTG7YsKG0bdtWQkNDxUjM6/Uy8CPSDTb1epD/Naskb/xxQM7EXJe1h6Pllvqc0JnImTBaFjV6GElrOemxLdOmTRNPx/V6ifSHgZ8HCfL3kbtaV5HPN5xQkzoz8CNyLkzUrK0Disd5McpkxtpcfmzqJdIPBn4eBs29czeeUDV+hy7GS73yYa5OEpFhrF692uZjo9Lm8mONH5F+sI+fh6lWOkR6N8paeunT9cddnRwiMjD28SPSH9b4eaDhnWvKn/suyq+7z8nzPetJ+Qj7LNZORPm7Ub8+4/bxY+BHpBcM/DxQy6olpU31krLt5FXV129cn/quThKRIVj368OavOnp6VKvXj31/PDhw+Lj4yOtWrUSQ/Xx4zx+RLrBwM9DPda5lmw7uV2+2XpKRt5aW0ID+FMTOZplvz7U6GHt3C+++EJKliyptl29elWGDh0qnTp1EmPN48c+fkR6wT5+Hqpb/XJSs2yIxCeny3d/n3Z1cogM57333pMpU6aYgz7A48mTJ6vXjIBNvUT6w8DPQ2GdzMc6ZS0EP2fdcUlO4xU3kTPFxcWplTqsYVt8fLwYAVfuINIfBn4ebFDLylKpRJBExaew1o/IyW6//XbVrLtw4UI5e/asuv38888ybNgwGTRokBirjx8vPIn0goGfhzezPNm1lno8c+0x1voROdGsWbOkT58+cv/990u1atWkatWq6nHv3r3lk08+EaNMKg/XWfYQ6QYDPw93V+vKUiEiUC7FpcgP28+4OjlEhhEcHKwCvCtXrqjRvrt375aYmBi1DUu6GUGQX1bgl5TKwI9ILxj4GaCpxVzrt+YYR9cROdmpU6fk/PnzcvLkSVm5cqUsXrxY3YwgWKvxY+BHpBuc48MA7m5dRWasPioXriXLD9vPyoM3VXN1kog83vHjx1U/v71796q1eU0mU451ejMyMgwT+LHGj0g/WONnAIF+PvJU19rq8Ucrj/Dqm8gJnnnmGalRo4ZERUWpZt99+/bJunXrpHXr1rJmzRoxgiD/rLqFJPbxI9INBn4GcW/bKlK5ZNYI37kbT7g6OUQeb/PmzTJp0iQpU6aMeHt7qxU7OnbsqOb2e/rpp8VYTb3prk4KEWVj4Gegvn5YtxdmrTkmVxNTXZ0kIo+Gplys3AEI/tDPDzDC99ChQ2KkUb1s6iXSDwZ+BvK/ZhWlQYVwiU9JV33+iMhxGjduLHv27FGP27VrJ1OnTpWNGzeqWsCaNbMmV/d0wdmjetm9hEg/GPgZbDWPcX3qq8dfbj4lZ68muTpJRB7rlVdekczMrBUrEOydOHFCrdG7ZMkSmT59uhhBsNbHj4EfkW5wVK/BdK5TRm6uVVo2Hbsi05Yflmn3NHd1kog8Uq9evcyPa9euLQcPHlTz+GG9Xm1kr3GaetnHj0gvWONnMDjhaLV+C3edk91nYl2dJCKPk5aWJt26dZMjR47k2F6qVCnDBH05BndwVC+RbjDwM6CmlUvIoJaV1OP/W/yvZGZmzS9GRPbh5+cn//zzjxidFvilZZgkLSOr2ZuIXIuBn0GN611fQvx9VI3fol3nXJ0cIo/zwAMPyOeffy5GpjX1Avv5EekD+/gZVLnwQBl5ax15e+lBeWvpQenVuLyEBnB3ILKX9PR0mTt3rvz111/SqlWrXOvzTps2TTydv4+3+Hh7SUamSY3sjQjyc3WSiAyPZ3oDe6Rjdfl+22k5eSVJPlp1RMb3aeDqJBF5DKzU0bJlS/X48OHDOV4zSj8/fE9M6YIppDjAg0gfGPgZfFLnV29rKMO+2C5zN5xQa/rWKhvq6mQReYTVq1e7Ogm6ae7NCvzY1EukBwz8DO7W+uXklnplZfWhaHl50V75dvhNhqmNIHKE69evy8qVK+W2225Tz8ePHy8pKSnm1319fdW8foGBgWIEHNlLpC8c3GFwCPImDWgsgX7esuV4jPy446yrk0Tk1r744guZPXu2+fnHH38smzZtkl27dqnbV199JTNnzhSjCOIkzkS6wsCPpEqpYBnTo656/MYfB+Rywn+1E0RUON9884089thjObYtWLBANf3i9s4778gPP/wgRoHZAyAphX38iPSAgR8pj3SoIQ0rhMu162ny+u/7XZ0cIrd19OhRadKkifk5mnS9vf8ratu2bSv79xvnGAsLzKrxQz8/InI9Bn6k+Pp4y1t3NBFvL5Ffd5+XNYeiXJ0kIrcUGxubo09fdHS0VK9e3fwc6/davu7pQgOzpnCJT2bgR6QHDPwox4oeQzvUUI9fXrRP4pPTXJ0kIrdTuXJlNZVLXrCiB95jtBq/BAZ+RLrAwI9yQF+/KqWC5FzsdZn8+wFXJ4fI7fTt21cmTJggycnJNkf8Tpw4Ufr16yeGa+rlhSSRLjDwoxxCAnzl3TubCWZ0+X77GVl18JKrk0TkVl566SWJiYmRevXqqYEcv/76q7pNnTpVbbt69ap6j1GEs6mXSFc4jx/l0q5maRnWoYZ8tuGEvPjzXlk+uqSUDPF3dbKI3EJkZKSavuXJJ5+UcePGiclkMk+d1KNHD/nkk0/Ue4xCWwoyPoU1fkR6wMCPbHq+Vz1ZfShKjkUnyoTF/8pH97VwdZKI3EaNGjVk6dKlquYPo3yhdu3aUqpUKTGa/5p6WeNHpAds6iWbAv18ZNrdzdUC67/tOS+L95x3dZKI3A4CPUzfgpsRgz4IY1Mvka4w8KM8NatSQkZ0raUev7xwr5yJSXJ1kojIXZt6ObiDSBcY+FG+RnWrIy2rllCTr476dpekZWS6OklE5EbY1EukLwz8KF9+Pt7y4b0tJDzQV3afiZX3lh92dZKIyA1H9SZw5Q4iXWDgRwVay/ftO5qqx7PWHpN1h6NdnSQichOh2TV+SakZks4WAyKXY+BHBdKnSQUZ3K6qejzmh90SFZ97cloioryaeoG1fkSux8CPCuzV2xpKvcgwuZyQKiMXsL8fERWsu0iQn496HHedgR+RqzHwo0JN8fLJAy3VKL2/T8TIlCUHXZ0kInIDJYOz+vldTUp1dVKIDM+wgd+6deukf//+UrFiRTWj/i+//OLqJLmFWmVD5d27mqnHczeekF93n3N1kohI57SVf2IY+BG5nGEDv8TERGnWrJnMmDHD1UlxO70bl5ensuf3e/Hnf+TAhThXJ4mIdKxkcFbgF8vAj8jlDLtkW58+fdSNiua5nvVk77lrsv7IZXni6x2yeERHichuziEislnjl8hJnIlczbCBX2GlpKSomyYuLquWKy0tTd0sac+tt3ua9+5sLLfP3CKnriTJU9/skE8fbKE6ctuDUfLQ0W6Uj8xfcmYfP9b4EbkeA78CmjJlikycODHX9uXLl0twcLDN/7NixQrxdPdXFfkwzkc2Hrsiw2cul7tqZIqXl/0+3wh56Ax55WNSEpfhI+c19cYkMvAjcjUGfgU0fvx4GTNmTI4avypVqkjPnj0lPDw8Vy0KTrQ9evQQPz/Pb/6s2ThKnvp2t2y85C23tGogQ9pXK/ZnGi0PHeVG+ajVXBM5p8aPNcxErsbAr4ACAgLUzRpOpnkFJvm95kn6NK0k42OT5c0lB+XNPw9JrXLhckv9cnb5bKPkoaPllY/MW3JuHz/W+BG5mmFH9ZJ9De9UU+5pXUUyTSKjvt0lBy+yJomIcjb1ch4/ItczbOCXkJAgu3fvVjc4ceKEenz69GlXJ80tYS7E1wc2lptqllLLMj08d5uci73u6mQRkQ6Uyq7xY+BH5HqGDfy2b98uLVq0UDdA/z08njBhgquT5rb8fb1l1gOtpE65ULkYlyxD5v7NUXxEJCXMK3ekiclkcnVyiAzNsIFf165dVQFkfZs/f76rk+bWSgT7yxePtJUKEYFyNCpBHpm/Ta6nZrg6WUSkgxq/1PRMSWJ5QORShg38yHEqlghSwV94oK/sPB0rIxfslPSMTFcni4hcJMjPRwL9sk43lxP+mw+ViJyPgR85RN3IMJn7cBsJ8PWWlQej5KVFe9nEQ2TgPsCR4YHqcVQ8Az8iV2LgRw7Tunop+fj+luLtJfLD9rMy6ff9DP6IDKpcWNZ0WJfikl2dFCJDY+BHDtWjYaRMvbOZejxv40l5e+khBn9EBlROq/GLY40fkSsx8COHu7NVZZk8sLF6PGvtMflw5RFXJ4mIXFXjF88aPyJXYuBHTvHATdXk1dsaqscf/HVEZq455uokEXnkmuJt2rSRsLAwKVeunAwcOFAOHTqU4z3JyckyYsQIKV26tISGhsodd9whly5dcnjatD5+0azxI3IpBn7kNMM61pCxveupx28vPSifbzjh6iQReZS1a9eqoG7Lli1qjWas1Yz1xBMTE83vefbZZ+W3336TH3/8Ub3//PnzMmjQIIenjTV+RPrAtXrJqZ7qWluS0zJl+soj8vrv+9U0L493qeXqZBF5hKVLl+Z4jnlJUfO3Y8cO6dy5s1y7dk0+//xzWbBggdx6663qPfPmzZMGDRqoYPGmm25yWNrMo3pZ40fkUgz8yOme7V5HxGSS6auOypQ/D0pKeqY83a2Oq5NF5HEQ6EGpUqXUPQJA1AJ2797d/J769etL1apVZfPmzTYDv5SUFHXTxMVlrcONz8HNkvbcejuUDPIxj+q19TrdOA/JPnmYZvC8ZeBHLpnTa0zPemqJt3eXH5ZpKw6rGf2f61lXvUZExZeZmSmjR4+WDh06SOPGWYOrLl68KP7+/lKiRIkc742MjFSv5dVvcOLEibm2L1++XIKDg23+HzQzW0tKx7++EpecLr/8tkT8s+JAyoOtPCT75GFSUpIYGQM/cpmRt9aRAF8feWPJAfl49VFJSc+Ql/o2YPBHZAfo67dv3z7ZsGFDsT5n/Pjxai1zyxq/KlWqqL6D4eHhuWpScLLt0aOH+Pllrc+rwTROk/9ZJYkpGdLkpi5Sq2xIsdLlqfLLQ7JPHsZl11obFQM/cqnhnWtKgJ+3TPj1X/l0/Qm1juekAVm1E0RUNCNHjpTff/9d1q1bJ5UrVzZvL1++vKSmpkpsbGyOWj+M6sVrtgQEBKibNZxQ8wpM8nqtSslgOXgxXi7Gp0r9ijlrHang+UvFy0M/g+crR/WSyz3Uvrq8NaiJoKLvm62n1dq+KWlcyJ2osFCrhqBv0aJFsmrVKqlRo0aO11u1aqVOeitXrjRvw3Qvp0+flvbt2zs8fZVLBqn7s1evO/xvEZFtrPEjXbi3bVUJC/STZ7/fLX/uuygxiSlyexlXp4rI/Zp3MWL3119/VXP5af32IiIiJCgoSN0PGzZMNd1iwAeaakeNGqWCPkeO6NVULpnVJ5CBH5HrMPAj3ejXtIKUDPaTx77aIVtPXJWzl3yk8y0pUrGUsavliQpq5syZ6r5r1645tmPKlocfflg9fv/998Xb21tN3IzRur169ZJPPvnEKenTavzOXDV253oiV2JTL+nKzbXLyHeP3SSlQ/zlXJKX3PPp33Ly8n+TzxJR/k29tm5a0AeBgYEyY8YMiYmJURM7L1y4MM/+ffbGGj8i12PgR7rTuFKEfD+8rZQOMMmZq9fljpmbZMepGFcni4iKqUqprBq/c6zxI3IZBn6kS9VKB8voxhnSqGKYXElMlfs+3SqL95x3dbKIqBiqlMqq8buckCoJKWpiPyJyMgZ+pFvh/iILhrWR7g0i1QTPT3+7Sy31hqYrInI/4YF+UiY0a2qY49EJrk4OkSEx8CNdC/b3ldkPtpJHO2ZNS4FVPp77YY+a7JmI3I82cfPRKAZ+RK7AwI90z8fbS165raG8cXtj9XjhrnPy4Gd/y+UELvZO5G5qlwtV98dY40fkEgz8yG0MbldN5j3cRsICfOXvkzHyv482yN6zWYvQE5F7qFU2K/BjjR+RazDwI7fSuW5ZWTTiZqlZJkTOX0uWO2dtkoU7z7o6WURU6Bo/TtNE5AoM/Mjt1C4XJr+M7CC31i8nKemZMuaHPTLxt38lLSPT1UkjohuolR34nbqSyGOWyAUY+JHbjg787KHWMurW2ur5vI0n5cHPt8oV9vsj0rWKEYES7O8jaRkmFfwRkXMx8CO35e3tJc/1rCezHmgpIf4+suV4jNz20QZO9kykY15eXtKgQrh6vO9cnKuTQ2Q4DPzI7fVuXEEWjeig+v1duJYs98zeInPWHeN8f0Q61aRShLrfd46Ds4icjYEfeYS6kWGyeFRH6d+soqRnmuTNJQdl+JfbJTYp1dVJIyIrjSpm1fjtZeBH5HQM/MhjhAb4yvR7m8vkgY3F39db/joQJf2mb5Bdp6+6OmlEZLUeN+w/HyeZmayZJ3ImBn7kcf2HHripmix88ma13u+52Oty9+zN8tn64zzBEOlEnXKhEuDrLfEp6XIqJsnVySEyFAZ+5LE1Cr+N6ih9m5RXowcn/3FAHpr7t1yKS3Z10ogMz9fHWxpmN/eyRp7IuRj4kUdP+TLj/paq6TfQz1s2HL0svT5YJ0v3XXR10ogMr031Uup+20mOwidyJgZ+ZIim399HdZLGlcIlNilNnvh6h4z7+R9JTEl3dfKIxOiB398nGPgRORMDPzLMMlELn+wgT3SpJV5eIt9tOyP9pq+X3WdiXZ00IkNqU72keem2y5x4nchpGPiRYWCk77g+9WXBozdJhYhAOXklSe6YuUneWXZQUtIzXJ08IkMpEewv9SLD1ONtrPUjchoGfmQ47WuVlqXPdFZz/mVkmmTG6mPyv482yj9nWftH5OxjEdYdiXZ1UogMg4EfGVJEsJ98dF8LmTm4pZQO8ZdDl+Ll9k9Y+0fkTLfUL6fuVx+M5ko7RE7CwI8MrU+TCrJiTBe5rWmFHLV/e89yRQEiR2tXo5QE+fnIxbhkOXAh3tXJITIEBn5keKVC/OXj+1vmqP0b+MlGeevPg3I9lbV/RI4S6OcjHWpnNfeuPhTl6uQQGQIDPyKL2r/lz3aWftm1f7PWHlPz/q07zP5HRI5u7l32L+fXJHIGBn5EFkqHBqhJn+c82EqN/D0dk6RW/Hjmu12ccoLIAXo1Ki8+3l7yz9lrcuJyoquTQ+TxGPgR2dCzUXnV929oh+ri7SXy6+7z0u29tfL9ttNc85fIjsqEBkiH2mXU49/2nHd1cog8HgM/ojyEBvjKa/0byS8jOkijiuFy7XqavPjzXrl3zhY5fIkd0YnsZUCziur+l93nOLqXyMEY+BHdQNPKJeTXER3klX4N1AjEv0/GSN8P18vrv++XuOQ0VyePyO31bBSpjq3j0YmylZM5EzkUAz+iAvD18ZZHO9WUFWM6S8+GkZKeaZLPN5yQW99dKz/tOMvmX6JiCAv0k4EtKqnHX20+5erkEHk0Bn5EhVC5ZLDMeai1fPFIW6lZJkQN+Hj+xz1y56xNsu8c5/4jKqqH2lczj+69eC3Z1ckh8lgM/IiKoEvdsrJ0dGe19m+wv4/sPB0r/T/eIC8t2isxiamuTh6R22lQIVzaVi+latPnbTrh6uQQeSwGfkRF5O/rLU90qSWrnusqA5pXFPRJX7D1tHR5Z7XMWXeMS78RFdLjXWqam3uvcPokIodg4EdUTOUjAuXDe1vI94/dpGot4pPT5c0lB6X7tLXyxz8XOEqRqIBurV9OmlSKkKTUDJmz/rirk0PkkRj4EdlJu5ql5fdRHWXqnU2lXFiAnIm5LiMW7JQ7Zm6SHaeuujp5RLrn5eUlz3Srox7P33hSzsQkuTpJRB6HgR+RHWEFgrtbV5E1L3SV0d3rqCkq0P8PwR+CQJ7IiPLXrUE5aVejlKSkZ8obfxxwdXKIPA4DPyIHCPb3ldHd66oA8O7WlcXLS1SzL1b/mPTbfvZfIsqn1m/igEbqImrpvxdlLdfKJrIrBn5EDhQZHihT72wmf4zqJB1rl5HUjEyZu/GEdJ66WqatOCzxnACaKJf65cPN07uM+/kfuZbE44TIXhj4ETlBw4rh8tWwtvLlI21V5/XE1AyZvvKICgA/XXdcktM4ApjI0gu96kn10sFy4VqyvPrrPg6SIrITBn5ETmzC6ly3rCwe2UE+GdxSapYNkatJafLGkgPS9Z01aiqYtIxMVyeTSDfdJd6/p7lq8l2857x8yRU9iOyCgR+RCwLAvk0qyPLRndUI4EolguRiXLKa/LnHtLWyaNdZSWcASCQtqpaUsb3qqceTft8vm45ednWSiNweAz8iF67/ixHAq57vIhNuayilQ/zl5JUkefb7PdLj/XWycCcDQKLHOteU21tUkoxMkzz+1Q4ujUhUTAz8iFwswNdHHulYQ9aOvUX1ayoR7CcnLifKmB/2qEmgf9rBAJCMXUM+ZVATtZxbfEq6PPj5Vjl0Md7VySJyWwz8iHQiNMBXRtxSWza8eKuM7V1PSgb7qRrA53/cI92mrZUftp9hH0AypEA/H/n84dbSrEoJ1S/2njmbZcepGFcni8gtMfAj0mEA+FTXrABwXJ/6UirEX05dSZKxP/0jt763Rr77+7SkpjMAJGMJC/STL4a2UcFfbFKa3P/pVlm674Krk0Xkdhj4EelUSICvPNGllqwfe4uM71Nf9QHEMnDjFu5V08B8tv64JKSkuzqZRE5TIthfvh3eTq3pi5U9nvh6p0xZcoA14USFwMCPyA0CwMcRAL54i7zct4FaBxijgCf/cUA6vLVKpi0/xJVAyFDTvMx5sJU80qGGej573XG5d84WOR6d4OqkEbkFwwd+M2bMkOrVq0tgYKC0a9dO/v77b1cniSjPE97wzjVVAPjWoCZSo0yIXLueJtNXHZUOb6+S/1v8r5y9yrWAyRgj4if0byizHmgpYYG+suPUVen94XqZsfooa/+IbsDQgd/3338vY8aMkddee0127twpzZo1k169eklUVJSrk0aU7yjge9tWlb/GdFETQWMlkOS0TJm/6aR0eWeNjPl+N0c9kiH0blxB/nymk5oYHf1e31l2SHq+v071/eNKH0S2GTrwmzZtmgwfPlyGDh0qDRs2lFmzZklwcLDMnTvX1UkjuiGsaICJoLESyNfD2kmH2qXVXGcLd52TXh+sk4fn/S2bjl0Rnv/Ik1UuGawGfUy7u5nqB4upkND3785Zm2X1oSgGgERWfMWgUlNTZceOHTJ+/HjzNm9vb+nevbts3rw51/tTUlLUTRMXF6fu09LS1M2S9tx6OxUc87Bw2lWPkHbVW8nec9dk9roTsvxAlKw5FK1uDUt4S8+etvOR+UueMtffoJaVpUfDSLX29afrT6jm36Hztkn98mFqEuh+TSuo2nIiozNs4Hf58mXJyMiQyMjIHNvx/ODBg7neP2XKFJk4cWKu7cuXL1e1hLasWLHCjik2JuZh4fWNEGnTTGTtBW/ZGu0ltcNNeeZjUhL7BJJnTfkypmc9GXxTNTXqHetfH7wYryZDx5Jvg1pUlnvaVJF65cNcnVQilzFs4FdYqBlEf0DLGr8qVapIz549JTw8PFctCk60PXr0ED8/Pxek1v0xD4tviIhEX0uS9evW5JmPWs01kSeJDA+Ul/s1lJG31JGvt56SrzafUiPh5248oW6NKoarbhJ9GpeXmmVDXZ1cIqcybOBXpkwZ8fHxkUuXLuXYjufly5fP9f6AgAB1s4aTaV6BSX6vUcEwD4unbESwBPrknY/MW/JkEcF+ajUczIe57nC0fLfttKw8ECX/no9TNwwGQVPwLfXLSac6ZaRVtZJsDiaPZ9jAz9/fX1q1aiUrV66UgQMHqm2ZmZnq+ciRI12dPCIisuNAKAR3uMUkpsqK/Rdlyd6LsvHoZdUUjNvMNcckyM9HbqpZSm6uVUZaVispjSuFMxAkj2PYwA/QdDtkyBBp3bq1tG3bVj744ANJTExUo3yJiMjzYAnEe9pUVbdrSWmy6tAlWX/4sqw7clkuJ6TI6kPR6gb+Pt7SpHKEtKxaQi0V17BCuFQrHaICSSJ3ZejA75577pHo6GiZMGGCXLx4UZo3by5Lly7NNeCDiIg8syn49haV1Q3TvqDmb/2RaNl28qrsPHVVriSmqtHBuGlQK4jBIQ0rhkuDCuFSp1yo1CwbImVDA9ToYiK9M3TgB2jWZdMuEZGxIWhDIIfbY51FBYKnY5LMgd++83Fy6GKcXE/LkN1nYtXNUliAr9QoG6JW1KlZJlQ9rlwySCqXCJIyoQHizVpC0gnDB35ERES2AkE06+KGOQIBE6RjgugDF+LUbf+FODkenaiWSoxPSZd/zl5TN2toMq5YIlAqlgiSSriVzLovFx6oagrLhQdIqWB/BofkFAz8iIiICgB9+2qXC1W3/s0qmrenpGfI6StJcvxyogoMj0cnyMnLSXIu9rpcuHZdUjMy5eSVJHXL77PLhPqrQDAzyVs2pv4rkRFBqk8ibiWC/aVksJ+UxH2Iv4T4+7BpmYqEgR8REVExYORvncgwdbOWnpGp5hA8d/W6CgS1+/PXkiUqLlmi41MkJilV1SZeiktRN6ymun/HuXz/pp+PlwoGUVNYIjsgjAjyk7BAXzWRNe5DA30l3OL5f/e+HK1sYAz8iIiIHMTXx1utJ4xbXtIyMuVKQqoKAs/HJsrqTdslsnpduZKUJlcT0+RqUqpcVY9xnyop6ZmSlmFS78etKND8rAWBwf64+UiQv4+EWD4O8FWDWfA8OMBXgi0f4z1+/70nwNdbArPv2WStbwz8iIiIXMjPx1vKRwSqW/3IYEk+ZpK+t9TKc4L166kZKgDEnISxSVpgmCpx19MkPjld4pLTJT4563FCyn+PteeA5meMWsbN/t/HSwJ9fSTAz1vVLGr3gere8vF/95aBI+7xGf6+2r23ClTVva+3yi/LbdpzvDfAx0fElC4ZpqwBOpQbAz8iIgOaMWOGvPPOO2oqq2bNmslHH32k5jMl/UNtXJB/kBosUlhoUrYMBvE4KTVDkrT7tP8eYwRzYkq6CjTxPDH1v8dJqdnvyX5feuZ/QRZqI9My0qWIlZF24isng4/LmJ71XZkIXWLgR0RkMN9//72awH7WrFnSrl07NXl9r1695NChQ1KuXDlXJ48cCINI0BcQN3tCX0Y0QeOWnJaR4z4lLUOS87jXXrf+fwges5q0MyVVu7d6nJZuyr7PlJTs1yyhRpByY+BHRGQw06ZNk+HDh5tXKUIA+Mcff8jcuXNl3Lhxrk4euWlfRtxCci9p7zRo2kXNY1Jyivzx53Lpd1MV1yVGxxgOExEZSGpqquzYsUO6d+9u3ubt7a2eb9682aVpIyoOTG+D/n4YrBLiJ+qecmOuFJHWaTQuLi7Xa2lpaZKUlKRey6tzLuWPeeicfNT2X3aCNo7Lly9LRkZGrqUp8fzgwYO53p+SkqJummvXsiYojomJUfuXrf3typUrPG6LiHno+DyMj483dLnHwK+ItB2nShVWJZNn7M8RERGuTgbp0JQpU2TixIm5tteoUcMl6SGyl3iDlnsM/IqoYsWKcubMGQkLC8s1ezpqURAQ4vXw8HCXpdGdMQ+dk4+44kXhh/2ZjKFMmTLi4+Mjly5dyrEdz8uXL5/r/ePHj1cDQTSZmZmqtq906dIs+xyAeVh8LPfyx8CviNAnpnLlrPUb84Idjgdu8TAPHZ+PRrziNTJ/f39p1aqVrFy5UgYOHGgO5vB85MiRud4fEBCgbpZKlCiR79/gcVt8zMPiY7lnGwM/IiKDQQ3ekCFDpHXr1mruPkznkpiYaB7lS0Sei4EfEZHB3HPPPRIdHS0TJkxQEzg3b95cli5dmmvABxF5HgZ+DoBmkddeey1X8wgVHPPQPpiPlBc069pq2i0O7m/FxzwsPuZh/rxMRh3PTERERGQwnMCZiIiIyCAY+BEREREZBAM/IiIiIoNg4EdERERkEAz8imjGjBlSvXp1CQwMlHbt2snff/+d7/t//PFHqV+/vnp/kyZNZMmSJWJ0hcnD+fPnq1UCLG/4f0a2bt066d+/v5p9Hvnxyy+/3PD/rFmzRlq2bKlGu9WuXVvlK1FhsOwrPpZ9xcOyr3gY+BXB999/ryZAxXDxnTt3SrNmzaRXr14SFRVl8/2bNm2S++67T4YNGya7du1Ss+Xjtm/fPjGqwuYhYAb2CxcumG+nTp0SI8OEu8g3nEQK4sSJE9KvXz+55ZZbZPfu3TJ69Gh59NFHZdmyZQ5PK3kGln3Fx7Kv+Fj2FROmc6HCadu2rWnEiBHm5xkZGaaKFSuapkyZYvP9d999t6lfv345trVr1870+OOPm4yqsHk4b948U0REhBNT6F5wKC9atCjf94wdO9bUqFGjHNvuueceU69evRycOvIULPuKj2WffbHsKzzW+BVSamqq7NixQ7p3755j3V4837x5s83/g+2W7wdc4eX1fk9XlDyEhIQEqVatmlp8e8CAAfLvv/86KcWegfshFQfLvuJj2eca3A9zYuBXSJcvX5aMjIxcSxvhOZY+sgXbC/N+T1eUPKxXr57MnTtXfv31V/n666/VovI333yznD171kmpdn957YdxcXFy/fp1l6WL3APLvuJj2ecaLPty4pJt5Bbat2+vbhoUfA0aNJDZs2fL66+/7tK0ERE5Css+sjfW+BVSmTJlxMfHRy5dupRjO56XL1/e5v/B9sK839MVJQ+t+fn5SYsWLeTo0aMOSqXnyWs/RMfxoKAgl6WL3APLvuJj2ecaLPtyYuBXSP7+/tKqVStZuXKleRuq3vHc8qrMErZbvh9WrFiR5/s9XVHy0BqaS/bu3SsVKlRwYEo9C/dDKg6WfcXHss81uB9aKcKAEMP77rvvTAEBAab58+eb9u/fb3rsscdMJUqUMF28eFG9/uCDD5rGjRtnfv/GjRtNvr6+pnfffdd04MAB02uvvWby8/Mz7d2712RUhc3DiRMnmpYtW2Y6duyYaceOHaZ7773XFBgYaPr3339NRhUfH2/atWuXuuFQnjZtmnp86tQp9TryD/moOX78uCk4ONj0wgsvqP1wxowZJh8fH9PSpUtd+C3InbDsKz6WfcXHsq94GPgV0UcffWSqWrWqyd/fXw3P37Jli/m1Ll26mIYMGZLj/T/88IOpbt266v0YVv7HH3+YjK4weTh69GjzeyMjI019+/Y17dy502Rkq1evVoWe9U3LN9wjH63/T/PmzVU+1qxZU00VQVQYLPuKj2Vf8bDsKx4v/GNdC0hEREREnod9/IiIiIgMgoEfERERkUEw8CMiIiIyCAZ+RERERAbBwI+IiIjIIBj4ERERERkEAz8iIiIig2DgR0RERGQQDPyIiIiIDIKBn4fq2rWrjB49Os/nrkqHu/3tgnzGjfLalXlAZDR6Of5Y9rHs0ysGfk708MMPi5eXl7r5+/tL7dq1ZdKkSZKenu7wv71w4UJ5/fXXC/ReZx+srswXZ+St9essDMloWPbZxrKPXMHXJX/VwHr37i3z5s2TlJQUWbJkiYwYMUL8/Pxk/Pjxud6bmpqqCgN7KFWqlOiZq/LFGXmr97wncgaWfbax7CNnY42fkwUEBEj58uWlWrVq8uSTT0r37t1l8eLF5quhkSNHqiuiMmXKSK9evdT2zMxMmTJlitSoUUOCgoKkWbNm8tNPP5k/MzExUR566CEJDQ2VChUqyHvvvZfr71pfaeEzp06dqq4wkaaqVavKG2+8oa5A165dKx9++KH5SvTkyZN2S4c98wUF5dNPPy3lypWTwMBA6dixo2zbti3H5+LKGf83IiJC/d9XX31VTCaT+fWlS5eq/1eiRAkpXbq03HbbbXLs2LFCfcaNrmItX7eVv7jCx9/G97E0cOBAefDBB/P83IsXL6r/j89q0aKFyoNGjRrJhg0bCpjrRM7Dss9++cKyj2VfcTDwczEUIriK03zxxRfqim7jxo0ya9YstQ0Fzpdffqme//vvv/Lss8/KAw88oA4ieOGFF9TjX3/9VZYvXy5r1qyRnTt35vt3cTX51ltvqQN5//79smDBAomMjFQHUvv27WX48OFy4cIFdatSpYrD0lGcfBk7dqz8/PPP6jX8HRTkKBhjYmJy/D9fX1/5+++/1XebNm2afPbZZzkK7DFjxsj27dtl5cqV4u3tLbfffrsq6Av6GYVhK3+fe+45ycjIMBf2EBUVJX/88Yc88sgjeX7W7t271f3cuXPlgw8+UM9xEhs8eHCO9BPpEcu+oucLyz6WfcViIqcZMmSIacCAAepxZmamacWKFaaAgADT888/r7Z16dLF1KJFixz/Jzk52RQcHGzatGlTju3Dhg0z3Xfffab4+HiTv7+/6YcffjC/duXKFVNQUJDpmWeeMW/DZ2vP4+Li1N/99NNPbabT8r32Toe98iUhIcHk5+dn+uabb8zbUlNTTRUrVjRNnTrV/P8aNGigPlPz4osvqm15iY6OxuWsae/evQX+DOv8KuxzePLJJ019+vQxP3/vvfdMNWvWzPF3rb311lsqD06cOGHetn37dpX+06dP5/n/iJyNZZ/98oVlH8u+4mIfPyf7/fffVXNAWlqaujK5//775f/+7//Mr7dq1SrH+48ePSpJSUnSo0ePHNtxRYgqblTN43G7du1y9KuoV69enmk4cOCAqlrv1q1bgdPtiHQUJ1/w9/DeDh06mLehX0zbtm3V99PcdNNNqklAgytONMPgKtPHx0eOHDkiEyZMkK1bt8rly5fNV4unT5+Wxo0bF+gz7AFXwW3atJFz585JpUqVZP78+eaO33nBVe6gQYOkevXq5m3h4eF2SQ+RvbHss41lH8s+Z2Pg52S33HKLzJw5U1XdV6xYUVWjWwoJCcnxPCEhQd2j6hsHhXXfEMuq/cI0JRSWI9JRnHyxl/79+6u+NZ9++qn6uyj8UOhZNrU4A04g6DeE5qSePXuq5iTkdX5Q+A0ZMiTHts2bN6u+ONa/EZGrseyzjWUfyz5nY+DnZDiI0R+joBo2bKgKF1yFdenSJdfrJUuWVFd7uGpDHwe4evWqHD582Ob7oU6dOqoARL+ORx99NNfrKIBwRefodBQnX2rVqmXu94LCC3AVjA7Olp2NkR5LW7ZsUd8fV6tXrlyRQ4cOqYKvU6dO6nVbnYPz+4yisJW/gN8C/VVw5YsO3lr/IluuX7+urtgtPwcFN/4/CkT01yHSE5Z9trHsY9nnbAz8dC4sLEyef/551ZkYOzdGYV27dk0d9Kjaxo4+bNgw1bkYo6Mwyuvll1/Od+fHCKgXX3xRdRDGgYgmg+joaHWlhc9C9TkOeIxoQxMEmi0ckY7iQGGJEXD4e0gfClyM1EOTDNKhQWGNDsyPP/646gT90UcfmUfcocBGWufMmaNG4uG948aNy/W38vuMorCVv8gnNPEgj1EY4+o3P3v37lVNIV9//bXceuutamQemm1iY2PllVdeKXLaiPSCZZ9tLPtY9hUXAz83gAkwy5Ytq0aWHT9+XO3oLVu2lJdeekm9/s4776jmCFTdo5DCSCkUTPnBiDY0KeCAOX/+vDr4n3jiCfUaDkAUZrjSxdXViRMn1AHriHQUB0bmoSDGsP/4+Hhp3bq1LFu2TBVqGkyxgO+A/i+4Sn3mmWfkscceU6+hwPnuu+/UtAho4kCfnOnTp6spCCzl9xlFkVf+YsqEO+64QzVzYDqDGzV11K9fX53A8H+QzxjVh5GF+F2IPAHLPttY9rHsKw4vjPAo1icQkd2g0znmo0IhnB9M8ormJExFQUTk7lj2OQ8bw4l0AAXZokWL1PxfKNhuBFe9TZs2dUraiIgchWWf87Gpl0gHMLINBeDbb799w2kgUEmPfi7oR0RE5M5Y9jkfm3qJiIiIDIJNvUREREQGwcCPiIiIyCAY+BEREREZBAM/IiIiIoNg4EdERERkEAz8iIiIiAyCgR8RERGRQTDwIyIiIjIIBn5EREREBsHAj4iIiMggGPgRERERiTH8PymJU1dQcyyMAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's continue with our loss calculation by taking the average of the log probability scores, and then multiplying by -1.",
   "id": "613e03073098b828"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.541425Z",
     "start_time": "2025-06-24T08:59:22.534506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "avg_log_probas = torch.mean(log_probs)\n",
    "print(avg_log_probas)\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(neg_avg_log_probas)"
   ],
   "id": "81126e0d3f4cbb49",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.2167)\n",
      "tensor(11.2167)\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.584272Z",
     "start_time": "2025-06-24T08:59:22.578634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_flat = logits.flatten(0, 1) #(batch_size, seq_len, d_model) --> (batch_size * seq_len, d_model)\n",
    "y_flat = y.flatten() #(batch_size, seq_len) --> (batch_size * seq_len)\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, y_flat)\n",
    "print(f'Loss: {loss}')"
   ],
   "id": "df997a174571b5e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.216712951660156\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> As we can see above, PyTorch's built in `cross_entropy` function applies softmax on raw logits , selects the probabilites corresponding to target IDs for each token, and computes the negative average log probabilities. In other words, it does all the work for us.\n",
    "\n",
    "#### Perplexity\n",
    "Perplexity is, at its heart, a re-expression of cross-entropy in the original token domain rather than in log space. It essentially answers the question, *'On average, how many equally likely tokens would the model be as uncertain about as it is in reality?'*. When we train a language model we minimize the average negative log-likelihood per token, which is measures in natural logarithms, or bits (if we use base-2 logs). While this is the correct objective for maximum-likelihood estimation, a loss of, say, 10 natural logarithms per token can feel a bit too abstract. What does '10 units of suprise' mean, exactly? Perplexity is used to bridge that gap by exponentiating the average loss so that our metric lives back in the token domain:\n",
    "\n",
    "$$\n",
    "\\text{Perplexity} = \\text{exp}(\\mathcal{L})\n",
    "$$\n",
    "\n",
    "If our model has perplexity of 50, we can say that, on average, it is as uncertain as if it had to choose uniformly among 50 tokens. A perfectly certain model (one that assigns a prob. of 1 to the correct next token) would have a cross-entropy loss of 0, and a perplexity of 1, reflecting zero uncertainty, exactly one choice. Exponentiating turns sums of logs (our loss) back into products of probabiliites. If cross-entropy is the arithmetic mean of 'surprise' ($-\\log p$), then exponentiating this computes the geometric mean of $\\frac{1}{p}$, which quantifies how 'wide' the model's distribution really is. In a way, it is telling us the model's effective vocabulary size given its actual uncertainty, and it therefore directly comparable across different datasets and tokenizations, as long as the vocabulary size is fixed.\n",
    "\n",
    "\n"
   ],
   "id": "79a50f6e7e93a9ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.640088Z",
     "start_time": "2025-06-24T08:59:22.633703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ],
   "id": "f20222b5e6d0c850",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(74362.9375)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "bd0c47fde477d7d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " To compute the loss on a training and validation set, we will use \"Pride and Prejudice\" by Jane Austen (1813). The full-book was obtained from [Project Gutenberg](https://www.gutenberg.org/), and then converted to a .txt file via the epub2txt library.\n",
    " > Important: *This eBook is for the use of anyone anywhere in the United States and most\n",
    "other parts of the world at no cost and with almost no restrictions\n",
    "whatsoever. You may copy it, give it away or re-use it under the terms\n",
    "of the Project Gutenberg License included with this eBook or online\n",
    "at www.gutenberg.org. If you\n",
    "are not located in the United States, you will have to check the laws\n",
    "of the country where you are located before using this eBook.*"
   ],
   "id": "534568309e2dc03e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:59:22.872893Z",
     "start_time": "2025-06-24T08:59:22.699286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pandp = '../../../data/pride_and_prejudice.txt'\n",
    "with open(pandp, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "character_num = len(text)\n",
    "tokens_num = len(tokenizer.encode(text))\n",
    "print(f'Number of characters in text: {character_num}')\n",
    "print(f'Number of tokens in text: {tokens_num}')"
   ],
   "id": "48e53b9ca2e443d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in text: 704415\n",
      "Number of tokens in text: 177123\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's split the dataset to create a training set, and a separate validation set. We will then divide the tokenized text into pieces of a pre-defined length (`context_length` parameter). Note that, in practice, it is often beneficial to allow variable-length inputs to make our LLM generalize better across inputs of variable types and lengths.\n",
    "\n",
    "We will use 85% of the data for training, and the remaining 15% as a validation set."
   ],
   "id": "d61e45eaf311356a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T09:01:40.391855Z",
     "start_time": "2025-06-24T09:01:40.208642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.load_data import create_dataloader\n",
    "\n",
    "def split_text(text, ratio):\n",
    "    \"\"\"split raw text into training/val sets by char index\"\"\"\n",
    "    split_point = int(ratio * len(text))\n",
    "    train_data, val_data = text[:split_point], text[split_point:]\n",
    "    return train_data, val_data\n",
    "\n",
    "def build_loaders(text, cfg, batch_size=4, split_ratio=0.85, seed=123, num_workers=0):\n",
    "    train_data, val_data = split_text(text, split_ratio)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    common_pars = dict(\n",
    "        batch_size=batch_size,\n",
    "        max_length=cfg.context_length,\n",
    "        stride=cfg.context_length,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    train_loader = create_dataloader(\n",
    "        train_data, shuffle=True, drop_last=True, **common_pars\n",
    "    )\n",
    "    val_loader = create_dataloader(\n",
    "        val_data, shuffle=False, drop_last=False, **common_pars\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def print_loader_shapes(loaders):\n",
    "    for name, loader in loaders.items():\n",
    "        print(f'{name.capitalize()} loader:')\n",
    "        for i, (x, y) in enumerate(loader, start=1):\n",
    "            print(f'Batch #{i}: x.shape={x.shape}, y.shape={y.shape}')\n",
    "        print()\n",
    "\n",
    "train_loader, val_loader = build_loaders(text, cfg_pt)\n",
    "print_loader_shapes({'train':train_loader,\n",
    "                    'validation':val_loader})"
   ],
   "id": "c4606df9fbc6668d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Batch #1: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #2: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #3: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #4: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #5: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #6: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #7: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #8: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #9: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #10: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #11: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #12: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #13: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #14: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #15: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #16: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #17: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #18: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #19: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #20: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #21: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #22: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #23: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #24: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #25: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #26: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #27: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #28: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #29: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #30: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #31: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #32: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #33: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #34: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #35: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #36: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #37: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #38: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #39: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #40: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #41: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #42: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #43: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #44: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #45: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #46: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #47: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #48: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #49: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #50: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #51: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #52: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #53: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #54: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #55: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #56: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #57: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #58: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #59: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #60: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #61: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #62: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #63: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #64: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #65: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #66: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #67: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #68: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #69: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #70: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #71: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #72: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #73: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #74: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #75: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #76: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #77: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #78: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #79: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #80: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #81: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #82: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #83: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #84: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #85: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #86: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #87: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #88: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #89: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #90: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #91: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #92: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #93: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #94: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #95: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #96: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #97: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #98: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #99: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #100: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #101: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #102: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #103: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #104: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #105: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #106: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #107: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #108: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #109: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #110: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #111: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #112: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #113: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #114: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #115: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #116: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #117: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #118: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #119: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #120: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #121: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #122: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #123: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #124: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #125: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #126: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #127: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #128: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #129: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #130: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #131: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #132: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #133: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #134: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #135: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #136: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #137: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #138: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #139: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #140: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #141: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #142: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #143: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #144: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #145: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #146: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "\n",
      "Validation loader:\n",
      "Batch #1: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #2: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #3: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #4: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #5: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #6: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #7: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #8: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #9: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #10: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #11: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #12: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #13: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #14: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #15: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #16: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #17: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #18: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #19: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #20: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #21: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #22: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #23: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #24: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #25: x.shape=torch.Size([4, 256]), y.shape=torch.Size([4, 256])\n",
      "Batch #26: x.shape=torch.Size([2, 256]), y.shape=torch.Size([2, 256])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As can be seen in the output above, a 85/15 training/validation split yields 146 training batches, with 4 samples and 256 tokens each. We also have 26 validation batches, also consisting of 4 examples and 256 tokens each. Note also that the input x and target y are of the same shape (since the targets are just the inputs shifted by a single position). Let's now calculate the cross-entropy loss for a given batch.",
   "id": "32eef47e4f0e0db1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T09:19:35.236480Z",
     "start_time": "2025-06-24T09:16:14.387767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_cross_entropy(logits, target):\n",
    "    \"\"\"\n",
    "    logits.shape == (batch_size, sequence_length, vocab_size)\n",
    "    targets.shape == (batch_size, sequence_length)\n",
    "    \"\"\"\n",
    "    flat_logits = logits.flatten(0, 1)\n",
    "    flat_targets = target.flatten(0)\n",
    "    return torch.nn.functional.cross_entropy(flat_logits, flat_targets)\n",
    "\n",
    "\n",
    "def eval_loss(data_loader, model, device, max_batches=None):\n",
    "    model.eval()\n",
    "    total, count = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "            if max_batches is not None and i >= max_batches:\n",
    "                break\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            total += calc_loss_cross_entropy(logits, y).item()\n",
    "            count += 1\n",
    "    return float('nan') if count == 0 else total / count\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "train_loss = eval_loss(train_loader, model, device)\n",
    "val_loss = eval_loss(val_loader, model, device)\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "print(f\"Valid loss: {val_loss}\")"
   ],
   "id": "2a34e096dc01deaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.972495980458717\n",
      "Valid loss: 10.97874982540424\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T09:23:55.528670Z",
     "start_time": "2025-06-24T09:23:55.524376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Training perplexity: {torch.exp(torch.tensor(train_loss))}')\n",
    "print(f'Validation perplexity: {torch.exp(torch.tensor(val_loss))}')"
   ],
   "id": "a5df813d6002d5a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perplexity: 58249.8046875\n",
      "Validation perplexity: 58615.25390625\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As shown above, the loss values are very high, reflecting the fact that the model has not been trained. At least we now have a way to measure the quality of the text that is generated, and can now proceed to methodologicaly train the LLM to reduce this loss and improve our model!",
   "id": "d2a9e276ee7f5375"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
